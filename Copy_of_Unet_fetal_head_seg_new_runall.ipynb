{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayush111111/unet-fet/blob/main/Copy_of_Unet_fetal_head_seg_new_runall.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp32hM6WEUNs",
        "outputId": "46e9c5e8-1d5b-48fd-d048-f9663ff679c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and augmentation\n"
      ],
      "metadata": {
        "id": "UR90rKp_FGhL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6eTx5yn5Ra2",
        "outputId": "98a0ee98-c56e-46a9-bc8f-594bcc721b59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Semester Project /dataset_filled\n",
            " best_model_224_res_64epoch_1e-4_val_coef_98.h5\n",
            " best_model_224_res_reduce_lr.h5\n",
            " best_model_224_res_retraining_1e-4.h5\n",
            " best_model_224_res_unk.h5\n",
            " best_model_224_res_VUNET.h5\n",
            "'Copy of best_model_224_res_64epoch_1e-4_val_coef_98.h5'\n",
            "'Copy of best_model_224_res.h5'\n",
            " model.png\n",
            " \u001b[0m\u001b[01;34mtest_set\u001b[0m/\n",
            " \u001b[01;34mtraining_set\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/'Semester Project '/dataset_filled/\n",
        "%ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6Vk9L1275Cc-"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QSq3dL1Q2eXP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J1QwM9f5Ez7",
        "outputId": "0061568c-c2d8-4599-a038-9856d5f3d597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultrasound training images in dataset 999\n",
            "Ultrasound training masks in dataset  999\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "trainPath = \"training_set/\"\n",
        "testPath = \"test_set/\"\n",
        "trainList = sorted(os.listdir(trainPath))\n",
        "testList = sorted(os.listdir(testPath))\n",
        "\n",
        "\n",
        "train_image = []\n",
        "train_mask = []\n",
        "for i, item in enumerate(trainList):\n",
        "    if i % 2 == 0:\n",
        "        train_image.append(item)\n",
        "    else:\n",
        "        train_mask.append(item)\n",
        "print(\"Ultrasound training images in dataset {}\".format(len(train_image)))\n",
        "print(\"Ultrasound training masks in dataset  {}\".format(len(train_mask)))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "1vFdSvhz6rR6",
        "outputId": "bd7f46cc-0749-4a3a-d98f-76aa19e0d6fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f34c5abc2b0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x864 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "img = np.array(Image.open(trainPath+\"000_HC.png\"))\n",
        "img_mask = np.array(Image.open(trainPath+\"000_HC_Annotation.png\"))\n",
        "img_mask = np.ma.masked_where(img_mask == 0, img_mask)\n",
        "print(len(img[0]))\n",
        "#display images with mask\n",
        "fig, ax = plt.subplots(1,3,figsize = (16,12))\n",
        "ax[0].imshow(img, cmap = 'gray')\n",
        "ax[1].imshow(img_mask, cmap = 'gray')\n",
        "ax[2].imshow(img, cmap = 'gray', interpolation = 'none')\n",
        "ax[2].imshow(img_mask, cmap = 'gray', interpolation = 'none', alpha = 0.7)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZJPv1oIC3YQ",
        "outputId": "06db8021-2132-4f45-adba-cb35436cf5f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_shape :  (999,)\n",
            "y_shape :  (999,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-5829c98f866b>:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.array(X)\n",
            "<ipython-input-7-5829c98f866b>:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  y = np.array(y)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#\n",
        "X = []\n",
        "y = []\n",
        "for image, mask in zip(train_image, train_mask):\n",
        "    X.append(np.array(Image.open(trainPath+image)))\n",
        "    y.append(np.array(Image.open(trainPath+mask)))\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"X_shape : \", X.shape)\n",
        "print(\"y_shape : \", y.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RyP7JKn6HxA8"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "K.set_image_data_format('channels_last')\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Add\n",
        "from tensorflow.keras.layers import Dropout, Lambda\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NoO29_XaKv-e"
      },
      "outputs": [],
      "source": [
        "def Generator(X_list, y_list, batch_size = 16):\n",
        "    c = 0\n",
        "\n",
        "    while(True):\n",
        "        X = np.empty((batch_size, IMG_HEIGHT, IMG_WIDTH), dtype = 'float32')\n",
        "        y = np.empty((batch_size, IMG_HEIGHT, IMG_WIDTH), dtype = 'float32')\n",
        "        \n",
        "        for i in range(c,c+batch_size):\n",
        "            image = X_list[i]\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            mask =  y_list[i]\n",
        "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "            image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_AREA)\n",
        "            mask = cv2.resize(mask, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_AREA)\n",
        "    \n",
        "            X[i - c] = image\n",
        "            y[i - c] = mask\n",
        "        \n",
        "        X = X[:,:,:,np.newaxis] / 255\n",
        "        y = y[:,:,:,np.newaxis] / 255\n",
        "        \n",
        "        c += batch_size\n",
        "        if(c+batch_size >= len(X_list)):\n",
        "            c = 0\n",
        "        yield X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJA9TkleMTzJ",
        "outputId": "c4f5217b-77ac-466b-97be-36ba05d648ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "999\n",
            "4995\n"
          ]
        }
      ],
      "source": [
        "train_img_aug = []\n",
        "train_mask_aug = []\n",
        "\n",
        "\n",
        "for img, mask in zip(train_image, train_mask):\n",
        "    img = cv2.imread(trainPath + img)\n",
        "    mask = cv2.imread(trainPath + mask)\n",
        "    train_img_aug.append(img)\n",
        "    \n",
        "    train_mask_aug.append(mask)\n",
        "    img_lr = np.fliplr(img)\n",
        "    mask_lr = np.fliplr(mask)\n",
        "\n",
        "    img_up = np.flipud(img)\n",
        "    mask_up = np.flipud(mask)\n",
        "\n",
        "    img_lr_up = np.flipud(img_lr)\n",
        "    mask_lr_up = np.flipud(mask_lr)\n",
        "\n",
        "    img_up_lr = np.fliplr(img_up)\n",
        "    mask_up_lr = np.fliplr(mask_up)\n",
        "\n",
        "    train_img_aug.append(img_lr)\n",
        "    train_mask_aug.append(mask_lr)\n",
        "\n",
        "    train_img_aug.append(img_up)\n",
        "    train_mask_aug.append(mask_up)\n",
        "\n",
        "    train_img_aug.append(img_lr_up)\n",
        "    train_mask_aug.append(mask_lr_up)\n",
        "\n",
        "    train_img_aug.append(img_up_lr)\n",
        "    train_mask_aug.append(mask_up_lr)\n",
        "\n",
        "print(len(train_image))\n",
        "print(len(train_img_aug))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "_lGdIsL9E-5L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "W6MVgkwxKGEI"
      },
      "outputs": [],
      "source": [
        "smooth=1.\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection +smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    return true_positives / (predicted_positives + K.epsilon())\n",
        "\n",
        "def specificity(y_true, y_pred):\n",
        "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
        "    possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n",
        "    return true_negatives / (possible_negatives + K.epsilon())\n",
        "\n",
        "def sensitivity(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KH_kJN9tKMAM"
      },
      "outputs": [],
      "source": [
        "# define building blocks\n",
        "def BatchnormActivate(x):\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def conv_block(x, filters, size, strides=(1,1), padding=\"same\", activation=True):\n",
        "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
        "    if activation == True:\n",
        "        x = BatchnormActivate(x)\n",
        "    return x\n",
        "\n",
        "def residual_block(blockInput, num_filters=16, batch_activate=False):\n",
        "    x = BatchnormActivate(blockInput)\n",
        "    x = conv_block(x, num_filters, (3,3))\n",
        "    x = conv_block(x, num_filters, (3,3), activation=False)\n",
        "    x = Add()([x, blockInput])\n",
        "    if batch_activate:\n",
        "        x = BatchnormActivate(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZYohZmgXKi-h"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_Unet(input_layer, start_neurons, DropoutRatio = 0.5):\n",
        "    \n",
        "\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
        "    conv1 = residual_block(conv1,start_neurons * 1)\n",
        "    conv1 = residual_block(conv1,start_neurons * 1, True)\n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "    #pool1 = Dropout(DropoutRatio/2)(pool1)\n",
        "\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
        "    conv2 = residual_block(conv2,start_neurons * 2)\n",
        "    conv2 = residual_block(conv2,start_neurons * 2, True)\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "    #pool2 = Dropout(DropoutRatio)(pool2)\n",
        "\n",
        "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
        "    conv3 = residual_block(conv3,start_neurons * 4)\n",
        "    conv3 = residual_block(conv3,start_neurons * 4, True)\n",
        "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
        "    #pool3 = Dropout(DropoutRatio)(pool3)\n",
        "\n",
        "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
        "    conv4 = residual_block(conv4,start_neurons * 8)\n",
        "    conv4 = residual_block(conv4,start_neurons * 8, True)\n",
        "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
        "    #pool4 = Dropout(DropoutRatio)(pool4)\n",
        "\n",
        "\n",
        "    \"\"\" Bridge \"\"\"\n",
        "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
        "    convm = residual_block(convm,start_neurons * 16)\n",
        "    convm = residual_block(convm,start_neurons * 16, True)\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
        "    uconv4 = concatenate([deconv4, conv4])\n",
        "    #uconv4 = Dropout(DropoutRatio)(uconv4)\n",
        "    \n",
        "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
        "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
        "    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n",
        "    \n",
        "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
        "    uconv3 = concatenate([deconv3, conv3])    \n",
        "    #uconv3 = Dropout(DropoutRatio)(uconv3)\n",
        "    \n",
        "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
        "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
        "    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n",
        "\n",
        "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
        "    uconv2 = concatenate([deconv2, conv2])\n",
        "        \n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
        "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
        "    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n",
        "    \n",
        "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    uconv1 = concatenate([deconv1, conv1])\n",
        "    \n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
        "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
        "    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n",
        "    \n",
        "    \"\"\" Output \"\"\"\n",
        "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
        "    \n",
        "    return output_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Its5vw-UOLk",
        "outputId": "8fbe7c2b-13ac-4136-c8e4-9f947d03b229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 224, 224, 16  160         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 224, 224, 16  64         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 224, 224, 16  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 224, 224, 16  2320        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 224, 224, 16  64         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 224, 224, 16  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 224, 224, 16  2320        ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 224, 224, 16  0           ['conv2d_2[0][0]',               \n",
            "                                )                                 'conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 224, 224, 16  64         ['add[0][0]']                    \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 224, 224, 16  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 224, 224, 16  2320        ['activation_2[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 224, 224, 16  64         ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 224, 224, 16  0           ['batch_normalization_3[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 224, 224, 16  2320        ['activation_3[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 224, 224, 16  0           ['conv2d_4[0][0]',               \n",
            "                                )                                 'add[0][0]']                    \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 224, 224, 16  64         ['add_1[0][0]']                  \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 224, 224, 16  0           ['batch_normalization_4[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 112, 112, 16  0           ['activation_4[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 112, 112, 32  4640        ['max_pooling2d[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 112, 112, 32  128        ['conv2d_5[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_5[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 112, 112, 32  9248        ['activation_5[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 112, 112, 32  128        ['conv2d_6[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_6[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 112, 112, 32  9248        ['activation_6[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 112, 112, 32  0           ['conv2d_7[0][0]',               \n",
            "                                )                                 'conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 112, 112, 32  128        ['add_2[0][0]']                  \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_7[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 112, 112, 32  9248        ['activation_7[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 112, 112, 32  128        ['conv2d_8[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 112, 112, 32  9248        ['activation_8[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 112, 112, 32  0           ['conv2d_9[0][0]',               \n",
            "                                )                                 'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 112, 112, 32  128        ['add_3[0][0]']                  \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 32)  0           ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 56, 56, 64)   18496       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 56, 56, 64)  256         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 56, 56, 64)  256         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 56, 56, 64)   0           ['conv2d_12[0][0]',              \n",
            "                                                                  'conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 56, 56, 64)  256         ['add_4[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 56, 56, 64)  256         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 56, 56, 64)   0           ['conv2d_14[0][0]',              \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 56, 56, 64)  256         ['add_5[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 64)  0           ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 28, 28, 128)  73856       ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 28, 28, 128)  512        ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_15[0][0]'] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 28, 28, 128)  512        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 28, 28, 128)  0           ['conv2d_17[0][0]',              \n",
            "                                                                  'conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 28, 28, 128)  512        ['add_6[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 28, 28, 128)  512        ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 28, 28, 128)  0           ['conv2d_19[0][0]',              \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 28, 28, 128)  512        ['add_7[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 128)  0          ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 14, 14, 256)  295168      ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 14, 14, 256)  0           ['conv2d_22[0][0]',              \n",
            "                                                                  'conv2d_20[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 14, 14, 256)  1024       ['add_8[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 14, 14, 256)  0           ['conv2d_24[0][0]',              \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 14, 14, 256)  1024       ['add_9[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 28, 28, 128)  295040     ['activation_24[0][0]']          \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 28, 28, 256)  0           ['conv2d_transpose[0][0]',       \n",
            "                                                                  'activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 28, 28, 128)  295040      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 28, 28, 128)  512        ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 28, 28, 128)  512        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 28, 28, 128)  0           ['conv2d_27[0][0]',              \n",
            "                                                                  'conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 28, 28, 128)  512        ['add_10[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 28, 28, 128)  512        ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 28, 28, 128)  0           ['conv2d_29[0][0]',              \n",
            "                                                                  'add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 28, 28, 128)  512        ['add_11[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 56, 56, 64)  73792       ['activation_29[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 56, 56, 128)  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                                                  'activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 56, 56, 64)   73792       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 56, 56, 64)  256         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 56, 56, 64)  256         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 56, 56, 64)   0           ['conv2d_32[0][0]',              \n",
            "                                                                  'conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 56, 56, 64)  256         ['add_12[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 56, 56, 64)  256         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 56, 56, 64)   0           ['conv2d_34[0][0]',              \n",
            "                                                                  'add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 56, 56, 64)  256         ['add_13[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 56, 56, 64)   0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 112, 112, 32  18464      ['activation_34[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 112, 112, 64  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                )                                 'activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 112, 112, 32  18464       ['concatenate_2[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 112, 112, 32  128        ['conv2d_35[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_35[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 112, 112, 32  9248        ['activation_35[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 112, 112, 32  128        ['conv2d_36[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_36[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 112, 112, 32  9248        ['activation_36[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 112, 112, 32  0           ['conv2d_37[0][0]',              \n",
            "                                )                                 'conv2d_35[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 112, 112, 32  128        ['add_14[0][0]']                 \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_37[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 112, 112, 32  9248        ['activation_37[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 112, 112, 32  128        ['conv2d_38[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_38[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 112, 112, 32  9248        ['activation_38[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 112, 112, 32  0           ['conv2d_39[0][0]',              \n",
            "                                )                                 'add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 112, 112, 32  128        ['add_15[0][0]']                 \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_39[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 224, 224, 16  4624       ['activation_39[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 224, 224, 32  0           ['conv2d_transpose_3[0][0]',     \n",
            "                                )                                 'activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 224, 224, 16  4624        ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 224, 224, 16  64         ['conv2d_40[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_40[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 224, 224, 16  2320        ['activation_40[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 224, 224, 16  64         ['conv2d_41[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_41[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 224, 224, 16  2320        ['activation_41[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 224, 224, 16  0           ['conv2d_42[0][0]',              \n",
            "                                )                                 'conv2d_40[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 224, 224, 16  64         ['add_16[0][0]']                 \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_42[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 224, 224, 16  2320        ['activation_42[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 224, 224, 16  64         ['conv2d_43[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_43[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 224, 224, 16  2320        ['activation_43[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 224, 224, 16  0           ['conv2d_44[0][0]',              \n",
            "                                )                                 'add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 224, 224, 16  64         ['add_17[0][0]']                 \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_44[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 224, 224, 1)  17          ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,119,857\n",
            "Trainable params: 5,112,497\n",
            "Non-trainable params: 7,360\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "#split training data\n",
        "\n",
        "#test_size changed from 0.3 t0 0.2 \n",
        "X_train, X_val, y_train, y_val = train_test_split(train_img_aug, train_mask_aug, test_size = 0.2, random_state = 1)\n",
        "\n",
        "# set training parameters\n",
        "epochs = 100\n",
        "batch_size = 16\n",
        "steps_per_epoch = int(len(X_train) / batch_size)\n",
        "validation_steps = int(len(X_val) / batch_size)\n",
        "\n",
        "train_gen = Generator(X_train, y_train, batch_size = batch_size)\n",
        "val_gen = Generator(X_val, y_val, batch_size = batch_size)\n",
        "\n",
        "# initialize our model\n",
        "inputs = Input((IMG_HEIGHT, IMG_WIDTH, 1))\n",
        "output_layer = build_Unet(inputs, 16, 0.5)\n",
        "\n",
        "# Define callbacks to save model with best val_dice_coef\n",
        "checkpointer = ModelCheckpoint(filepath = 'best_model_224_res_reduce_lr.h5', monitor='val_dice_coef', verbose=1, save_best_only=True, mode='max')\n",
        "model = Model(inputs=[inputs], outputs=[output_layer])\n",
        "model.compile(optimizer=Adam(lr = 1e-4), loss=dice_coef_loss, metrics=['accuracy',dice_coef,specificity,sensitivity,precision,])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=5)\n",
        "\n"
      ],
      "metadata": {
        "id": "Hppw1-K1Fm51"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fit model"
      ],
      "metadata": {
        "id": "k7BR8b6UFn0O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDkWg1huU_2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28383b33-b654-46ca-e16d-1416920e376a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-97ab44bd4fe9>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  results = model.fit_generator(train_gen, steps_per_epoch=steps_per_epoch, epochs = epochs, validation_data = val_gen, validation_steps = validation_steps,callbacks=[checkpointer,reduce_lr])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.6853 - accuracy: 0.8868 - dice_coef: 0.6853 - specificity: 0.8698 - sensitivity: 0.9431 - precision: 0.7899\n",
            "Epoch 1: val_dice_coef improved from -inf to 0.64407, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 107s 370ms/step - loss: -0.6853 - accuracy: 0.8868 - dice_coef: 0.6853 - specificity: 0.8698 - sensitivity: 0.9431 - precision: 0.7899 - val_loss: -0.6441 - val_accuracy: 0.8838 - val_dice_coef: 0.6441 - val_specificity: 0.9691 - val_sensitivity: 0.6950 - val_precision: 0.9050 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.7782 - accuracy: 0.9677 - dice_coef: 0.7782 - specificity: 0.9663 - sensitivity: 0.9870 - precision: 0.9226\n",
            "Epoch 2: val_dice_coef improved from 0.64407 to 0.78333, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 366ms/step - loss: -0.7782 - accuracy: 0.9677 - dice_coef: 0.7782 - specificity: 0.9663 - sensitivity: 0.9870 - precision: 0.9226 - val_loss: -0.7833 - val_accuracy: 0.9581 - val_dice_coef: 0.7833 - val_specificity: 0.9518 - val_sensitivity: 0.9886 - val_precision: 0.8941 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.8071 - accuracy: 0.9738 - dice_coef: 0.8071 - specificity: 0.9743 - sensitivity: 0.9879 - precision: 0.9406\n",
            "Epoch 3: val_dice_coef improved from 0.78333 to 0.81274, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 93s 374ms/step - loss: -0.8071 - accuracy: 0.9738 - dice_coef: 0.8071 - specificity: 0.9743 - sensitivity: 0.9879 - precision: 0.9406 - val_loss: -0.8127 - val_accuracy: 0.9726 - val_dice_coef: 0.8127 - val_specificity: 0.9709 - val_sensitivity: 0.9920 - val_precision: 0.9339 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.8311 - accuracy: 0.9777 - dice_coef: 0.8311 - specificity: 0.9799 - sensitivity: 0.9877 - precision: 0.9540\n",
            "Epoch 4: val_dice_coef improved from 0.81274 to 0.83516, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 92s 370ms/step - loss: -0.8311 - accuracy: 0.9777 - dice_coef: 0.8311 - specificity: 0.9799 - sensitivity: 0.9877 - precision: 0.9540 - val_loss: -0.8352 - val_accuracy: 0.9776 - val_dice_coef: 0.8352 - val_specificity: 0.9797 - val_sensitivity: 0.9877 - val_precision: 0.9536 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.8521 - accuracy: 0.9797 - dice_coef: 0.8521 - specificity: 0.9830 - sensitivity: 0.9878 - precision: 0.9610\n",
            "Epoch 5: val_dice_coef improved from 0.83516 to 0.85437, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 90s 363ms/step - loss: -0.8521 - accuracy: 0.9797 - dice_coef: 0.8521 - specificity: 0.9830 - sensitivity: 0.9878 - precision: 0.9610 - val_loss: -0.8544 - val_accuracy: 0.9781 - val_dice_coef: 0.8544 - val_specificity: 0.9808 - val_sensitivity: 0.9875 - val_precision: 0.9559 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.8708 - accuracy: 0.9813 - dice_coef: 0.8708 - specificity: 0.9854 - sensitivity: 0.9880 - precision: 0.9665\n",
            "Epoch 6: val_dice_coef improved from 0.85437 to 0.87205, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 92s 369ms/step - loss: -0.8708 - accuracy: 0.9813 - dice_coef: 0.8708 - specificity: 0.9854 - sensitivity: 0.9880 - precision: 0.9665 - val_loss: -0.8721 - val_accuracy: 0.9788 - val_dice_coef: 0.8721 - val_specificity: 0.9831 - val_sensitivity: 0.9847 - val_precision: 0.9612 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.8867 - accuracy: 0.9819 - dice_coef: 0.8867 - specificity: 0.9867 - sensitivity: 0.9875 - precision: 0.9695\n",
            "Epoch 7: val_dice_coef improved from 0.87205 to 0.88044, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 367ms/step - loss: -0.8867 - accuracy: 0.9819 - dice_coef: 0.8867 - specificity: 0.9867 - sensitivity: 0.9875 - precision: 0.9695 - val_loss: -0.8804 - val_accuracy: 0.9737 - val_dice_coef: 0.8804 - val_specificity: 0.9753 - val_sensitivity: 0.9871 - val_precision: 0.9432 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.8983 - accuracy: 0.9806 - dice_coef: 0.8983 - specificity: 0.9861 - sensitivity: 0.9849 - precision: 0.9681\n",
            "Epoch 8: val_dice_coef improved from 0.88044 to 0.89998, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 366ms/step - loss: -0.8983 - accuracy: 0.9806 - dice_coef: 0.8983 - specificity: 0.9861 - sensitivity: 0.9849 - precision: 0.9681 - val_loss: -0.9000 - val_accuracy: 0.9788 - val_dice_coef: 0.9000 - val_specificity: 0.9826 - val_sensitivity: 0.9871 - val_precision: 0.9598 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9125 - accuracy: 0.9828 - dice_coef: 0.9125 - specificity: 0.9887 - sensitivity: 0.9868 - precision: 0.9740\n",
            "Epoch 9: val_dice_coef improved from 0.89998 to 0.91230, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 93s 373ms/step - loss: -0.9125 - accuracy: 0.9828 - dice_coef: 0.9125 - specificity: 0.9887 - sensitivity: 0.9868 - precision: 0.9740 - val_loss: -0.9123 - val_accuracy: 0.9799 - val_dice_coef: 0.9123 - val_specificity: 0.9852 - val_sensitivity: 0.9850 - val_precision: 0.9656 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9238 - accuracy: 0.9838 - dice_coef: 0.9238 - specificity: 0.9900 - sensitivity: 0.9875 - precision: 0.9769\n",
            "Epoch 10: val_dice_coef improved from 0.91230 to 0.92226, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 90s 363ms/step - loss: -0.9238 - accuracy: 0.9838 - dice_coef: 0.9238 - specificity: 0.9900 - sensitivity: 0.9875 - precision: 0.9769 - val_loss: -0.9223 - val_accuracy: 0.9804 - val_dice_coef: 0.9223 - val_specificity: 0.9881 - val_sensitivity: 0.9799 - val_precision: 0.9722 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9320 - accuracy: 0.9837 - dice_coef: 0.9320 - specificity: 0.9901 - sensitivity: 0.9869 - precision: 0.9772\n",
            "Epoch 11: val_dice_coef improved from 0.92226 to 0.92969, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 364ms/step - loss: -0.9320 - accuracy: 0.9837 - dice_coef: 0.9320 - specificity: 0.9901 - sensitivity: 0.9869 - precision: 0.9772 - val_loss: -0.9297 - val_accuracy: 0.9802 - val_dice_coef: 0.9297 - val_specificity: 0.9898 - val_sensitivity: 0.9755 - val_precision: 0.9759 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9397 - accuracy: 0.9840 - dice_coef: 0.9397 - specificity: 0.9907 - sensitivity: 0.9868 - precision: 0.9785\n",
            "Epoch 12: val_dice_coef improved from 0.92969 to 0.93724, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 366ms/step - loss: -0.9397 - accuracy: 0.9840 - dice_coef: 0.9397 - specificity: 0.9907 - sensitivity: 0.9868 - precision: 0.9785 - val_loss: -0.9372 - val_accuracy: 0.9805 - val_dice_coef: 0.9372 - val_specificity: 0.9879 - val_sensitivity: 0.9815 - val_precision: 0.9714 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9463 - accuracy: 0.9843 - dice_coef: 0.9463 - specificity: 0.9912 - sensitivity: 0.9869 - precision: 0.9797\n",
            "Epoch 13: val_dice_coef improved from 0.93724 to 0.94089, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 367ms/step - loss: -0.9463 - accuracy: 0.9843 - dice_coef: 0.9463 - specificity: 0.9912 - sensitivity: 0.9869 - precision: 0.9797 - val_loss: -0.9409 - val_accuracy: 0.9795 - val_dice_coef: 0.9409 - val_specificity: 0.9884 - val_sensitivity: 0.9767 - val_precision: 0.9724 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9525 - accuracy: 0.9849 - dice_coef: 0.9525 - specificity: 0.9920 - sensitivity: 0.9875 - precision: 0.9814\n",
            "Epoch 14: val_dice_coef improved from 0.94089 to 0.94713, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 90s 363ms/step - loss: -0.9525 - accuracy: 0.9849 - dice_coef: 0.9525 - specificity: 0.9920 - sensitivity: 0.9875 - precision: 0.9814 - val_loss: -0.9471 - val_accuracy: 0.9804 - val_dice_coef: 0.9471 - val_specificity: 0.9880 - val_sensitivity: 0.9810 - val_precision: 0.9715 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9564 - accuracy: 0.9845 - dice_coef: 0.9564 - specificity: 0.9919 - sensitivity: 0.9866 - precision: 0.9811\n",
            "Epoch 15: val_dice_coef did not improve from 0.94713\n",
            "249/249 [==============================] - 90s 363ms/step - loss: -0.9564 - accuracy: 0.9845 - dice_coef: 0.9564 - specificity: 0.9919 - sensitivity: 0.9866 - precision: 0.9811 - val_loss: -0.9367 - val_accuracy: 0.9709 - val_dice_coef: 0.9367 - val_specificity: 0.9697 - val_sensitivity: 0.9926 - val_precision: 0.9311 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9588 - accuracy: 0.9837 - dice_coef: 0.9588 - specificity: 0.9914 - sensitivity: 0.9850 - precision: 0.9798\n",
            "Epoch 16: val_dice_coef improved from 0.94713 to 0.95454, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 367ms/step - loss: -0.9588 - accuracy: 0.9837 - dice_coef: 0.9588 - specificity: 0.9914 - sensitivity: 0.9850 - precision: 0.9798 - val_loss: -0.9545 - val_accuracy: 0.9804 - val_dice_coef: 0.9545 - val_specificity: 0.9878 - val_sensitivity: 0.9819 - val_precision: 0.9711 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9658 - accuracy: 0.9859 - dice_coef: 0.9658 - specificity: 0.9934 - sensitivity: 0.9885 - precision: 0.9847\n",
            "Epoch 17: val_dice_coef improved from 0.95454 to 0.95733, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 367ms/step - loss: -0.9658 - accuracy: 0.9859 - dice_coef: 0.9658 - specificity: 0.9934 - sensitivity: 0.9885 - precision: 0.9847 - val_loss: -0.9573 - val_accuracy: 0.9802 - val_dice_coef: 0.9573 - val_specificity: 0.9844 - val_sensitivity: 0.9891 - val_precision: 0.9633 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9671 - accuracy: 0.9851 - dice_coef: 0.9671 - specificity: 0.9928 - sensitivity: 0.9871 - precision: 0.9830\n",
            "Epoch 18: val_dice_coef improved from 0.95733 to 0.96095, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 92s 368ms/step - loss: -0.9671 - accuracy: 0.9851 - dice_coef: 0.9671 - specificity: 0.9928 - sensitivity: 0.9871 - precision: 0.9830 - val_loss: -0.9610 - val_accuracy: 0.9808 - val_dice_coef: 0.9610 - val_specificity: 0.9902 - val_sensitivity: 0.9776 - val_precision: 0.9765 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9704 - accuracy: 0.9856 - dice_coef: 0.9704 - specificity: 0.9933 - sensitivity: 0.9877 - precision: 0.9843\n",
            "Epoch 19: val_dice_coef improved from 0.96095 to 0.96181, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 364ms/step - loss: -0.9704 - accuracy: 0.9856 - dice_coef: 0.9704 - specificity: 0.9933 - sensitivity: 0.9877 - precision: 0.9843 - val_loss: -0.9618 - val_accuracy: 0.9799 - val_dice_coef: 0.9618 - val_specificity: 0.9863 - val_sensitivity: 0.9844 - val_precision: 0.9674 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9748 - accuracy: 0.9869 - dice_coef: 0.9748 - specificity: 0.9946 - sensitivity: 0.9897 - precision: 0.9873\n",
            "Epoch 20: val_dice_coef improved from 0.96181 to 0.96653, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 92s 372ms/step - loss: -0.9748 - accuracy: 0.9869 - dice_coef: 0.9748 - specificity: 0.9946 - sensitivity: 0.9897 - precision: 0.9873 - val_loss: -0.9665 - val_accuracy: 0.9818 - val_dice_coef: 0.9665 - val_specificity: 0.9905 - val_sensitivity: 0.9803 - val_precision: 0.9773 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9772 - accuracy: 0.9872 - dice_coef: 0.9772 - specificity: 0.9949 - sensitivity: 0.9903 - precision: 0.9882\n",
            "Epoch 21: val_dice_coef did not improve from 0.96653\n",
            "249/249 [==============================] - 89s 357ms/step - loss: -0.9772 - accuracy: 0.9872 - dice_coef: 0.9772 - specificity: 0.9949 - sensitivity: 0.9903 - precision: 0.9882 - val_loss: -0.9660 - val_accuracy: 0.9807 - val_dice_coef: 0.9660 - val_specificity: 0.9940 - val_sensitivity: 0.9684 - val_precision: 0.9853 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9782 - accuracy: 0.9870 - dice_coef: 0.9782 - specificity: 0.9948 - sensitivity: 0.9897 - precision: 0.9877\n",
            "Epoch 22: val_dice_coef improved from 0.96653 to 0.96799, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 93s 374ms/step - loss: -0.9782 - accuracy: 0.9870 - dice_coef: 0.9782 - specificity: 0.9948 - sensitivity: 0.9897 - precision: 0.9877 - val_loss: -0.9680 - val_accuracy: 0.9809 - val_dice_coef: 0.9680 - val_specificity: 0.9900 - val_sensitivity: 0.9788 - val_precision: 0.9759 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9788 - accuracy: 0.9866 - dice_coef: 0.9788 - specificity: 0.9945 - sensitivity: 0.9888 - precision: 0.9871\n",
            "Epoch 23: val_dice_coef improved from 0.96799 to 0.97050, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 365ms/step - loss: -0.9788 - accuracy: 0.9866 - dice_coef: 0.9788 - specificity: 0.9945 - sensitivity: 0.9888 - precision: 0.9871 - val_loss: -0.9705 - val_accuracy: 0.9817 - val_dice_coef: 0.9705 - val_specificity: 0.9897 - val_sensitivity: 0.9823 - val_precision: 0.9752 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9799 - accuracy: 0.9866 - dice_coef: 0.9799 - specificity: 0.9945 - sensitivity: 0.9888 - precision: 0.9871\n",
            "Epoch 24: val_dice_coef did not improve from 0.97050\n",
            "249/249 [==============================] - 90s 361ms/step - loss: -0.9799 - accuracy: 0.9866 - dice_coef: 0.9799 - specificity: 0.9945 - sensitivity: 0.9888 - precision: 0.9871 - val_loss: -0.9702 - val_accuracy: 0.9810 - val_dice_coef: 0.9702 - val_specificity: 0.9910 - val_sensitivity: 0.9767 - val_precision: 0.9781 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9810 - accuracy: 0.9866 - dice_coef: 0.9810 - specificity: 0.9947 - sensitivity: 0.9888 - precision: 0.9874\n",
            "Epoch 25: val_dice_coef did not improve from 0.97050\n",
            "249/249 [==============================] - 90s 362ms/step - loss: -0.9810 - accuracy: 0.9866 - dice_coef: 0.9810 - specificity: 0.9947 - sensitivity: 0.9888 - precision: 0.9874 - val_loss: -0.9688 - val_accuracy: 0.9795 - val_dice_coef: 0.9688 - val_specificity: 0.9861 - val_sensitivity: 0.9831 - val_precision: 0.9671 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9818 - accuracy: 0.9866 - dice_coef: 0.9818 - specificity: 0.9946 - sensitivity: 0.9888 - precision: 0.9874\n",
            "Epoch 26: val_dice_coef improved from 0.97050 to 0.97098, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 92s 368ms/step - loss: -0.9818 - accuracy: 0.9866 - dice_coef: 0.9818 - specificity: 0.9946 - sensitivity: 0.9888 - precision: 0.9874 - val_loss: -0.9710 - val_accuracy: 0.9804 - val_dice_coef: 0.9710 - val_specificity: 0.9886 - val_sensitivity: 0.9804 - val_precision: 0.9726 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9838 - accuracy: 0.9872 - dice_coef: 0.9838 - specificity: 0.9952 - sensitivity: 0.9900 - precision: 0.9887\n",
            "Epoch 27: val_dice_coef improved from 0.97098 to 0.97164, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 90s 363ms/step - loss: -0.9838 - accuracy: 0.9872 - dice_coef: 0.9838 - specificity: 0.9952 - sensitivity: 0.9900 - precision: 0.9887 - val_loss: -0.9716 - val_accuracy: 0.9805 - val_dice_coef: 0.9716 - val_specificity: 0.9921 - val_sensitivity: 0.9724 - val_precision: 0.9807 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9849 - accuracy: 0.9874 - dice_coef: 0.9849 - specificity: 0.9954 - sensitivity: 0.9903 - precision: 0.9892\n",
            "Epoch 28: val_dice_coef improved from 0.97164 to 0.97345, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 92s 369ms/step - loss: -0.9849 - accuracy: 0.9874 - dice_coef: 0.9849 - specificity: 0.9954 - sensitivity: 0.9903 - precision: 0.9892 - val_loss: -0.9735 - val_accuracy: 0.9812 - val_dice_coef: 0.9735 - val_specificity: 0.9933 - val_sensitivity: 0.9720 - val_precision: 0.9836 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9854 - accuracy: 0.9874 - dice_coef: 0.9854 - specificity: 0.9955 - sensitivity: 0.9902 - precision: 0.9893\n",
            "Epoch 29: val_dice_coef improved from 0.97345 to 0.97357, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 90s 363ms/step - loss: -0.9854 - accuracy: 0.9874 - dice_coef: 0.9854 - specificity: 0.9955 - sensitivity: 0.9902 - precision: 0.9893 - val_loss: -0.9736 - val_accuracy: 0.9810 - val_dice_coef: 0.9736 - val_specificity: 0.9922 - val_sensitivity: 0.9738 - val_precision: 0.9810 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9858 - accuracy: 0.9874 - dice_coef: 0.9858 - specificity: 0.9954 - sensitivity: 0.9901 - precision: 0.9892\n",
            "Epoch 30: val_dice_coef did not improve from 0.97357\n",
            "249/249 [==============================] - 91s 364ms/step - loss: -0.9858 - accuracy: 0.9874 - dice_coef: 0.9858 - specificity: 0.9954 - sensitivity: 0.9901 - precision: 0.9892 - val_loss: -0.9713 - val_accuracy: 0.9794 - val_dice_coef: 0.9713 - val_specificity: 0.9917 - val_sensitivity: 0.9696 - val_precision: 0.9797 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9863 - accuracy: 0.9874 - dice_coef: 0.9863 - specificity: 0.9955 - sensitivity: 0.9900 - precision: 0.9895\n",
            "Epoch 31: val_dice_coef improved from 0.97357 to 0.97554, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 365ms/step - loss: -0.9863 - accuracy: 0.9874 - dice_coef: 0.9863 - specificity: 0.9955 - sensitivity: 0.9900 - precision: 0.9895 - val_loss: -0.9755 - val_accuracy: 0.9815 - val_dice_coef: 0.9755 - val_specificity: 0.9909 - val_sensitivity: 0.9789 - val_precision: 0.9781 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9854 - accuracy: 0.9867 - dice_coef: 0.9854 - specificity: 0.9950 - sensitivity: 0.9889 - precision: 0.9881\n",
            "Epoch 32: val_dice_coef improved from 0.97554 to 0.97564, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 92s 368ms/step - loss: -0.9854 - accuracy: 0.9867 - dice_coef: 0.9854 - specificity: 0.9950 - sensitivity: 0.9889 - precision: 0.9881 - val_loss: -0.9756 - val_accuracy: 0.9813 - val_dice_coef: 0.9756 - val_specificity: 0.9895 - val_sensitivity: 0.9817 - val_precision: 0.9749 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9892 - accuracy: 0.9884 - dice_coef: 0.9892 - specificity: 0.9965 - sensitivity: 0.9922 - precision: 0.9918\n",
            "Epoch 33: val_dice_coef improved from 0.97564 to 0.97653, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 367ms/step - loss: -0.9892 - accuracy: 0.9884 - dice_coef: 0.9892 - specificity: 0.9965 - sensitivity: 0.9922 - precision: 0.9918 - val_loss: -0.9765 - val_accuracy: 0.9817 - val_dice_coef: 0.9765 - val_specificity: 0.9920 - val_sensitivity: 0.9773 - val_precision: 0.9805 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9896 - accuracy: 0.9884 - dice_coef: 0.9896 - specificity: 0.9966 - sensitivity: 0.9924 - precision: 0.9920\n",
            "Epoch 34: val_dice_coef improved from 0.97653 to 0.97739, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 367ms/step - loss: -0.9896 - accuracy: 0.9884 - dice_coef: 0.9896 - specificity: 0.9966 - sensitivity: 0.9924 - precision: 0.9920 - val_loss: -0.9774 - val_accuracy: 0.9820 - val_dice_coef: 0.9774 - val_specificity: 0.9923 - val_sensitivity: 0.9776 - val_precision: 0.9814 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9882 - accuracy: 0.9877 - dice_coef: 0.9882 - specificity: 0.9959 - sensitivity: 0.9907 - precision: 0.9902\n",
            "Epoch 35: val_dice_coef did not improve from 0.97739\n",
            "249/249 [==============================] - 90s 363ms/step - loss: -0.9882 - accuracy: 0.9877 - dice_coef: 0.9882 - specificity: 0.9959 - sensitivity: 0.9907 - precision: 0.9902 - val_loss: -0.9728 - val_accuracy: 0.9795 - val_dice_coef: 0.9728 - val_specificity: 0.9923 - val_sensitivity: 0.9682 - val_precision: 0.9812 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9880 - accuracy: 0.9875 - dice_coef: 0.9880 - specificity: 0.9957 - sensitivity: 0.9903 - precision: 0.9898\n",
            "Epoch 36: val_dice_coef did not improve from 0.97739\n",
            "249/249 [==============================] - 90s 362ms/step - loss: -0.9880 - accuracy: 0.9875 - dice_coef: 0.9880 - specificity: 0.9957 - sensitivity: 0.9903 - precision: 0.9898 - val_loss: -0.9758 - val_accuracy: 0.9810 - val_dice_coef: 0.9758 - val_specificity: 0.9918 - val_sensitivity: 0.9749 - val_precision: 0.9800 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9889 - accuracy: 0.9878 - dice_coef: 0.9889 - specificity: 0.9960 - sensitivity: 0.9909 - precision: 0.9906\n",
            "Epoch 37: val_dice_coef did not improve from 0.97739\n",
            "249/249 [==============================] - 89s 356ms/step - loss: -0.9889 - accuracy: 0.9878 - dice_coef: 0.9889 - specificity: 0.9960 - sensitivity: 0.9909 - precision: 0.9906 - val_loss: -0.9759 - val_accuracy: 0.9809 - val_dice_coef: 0.9759 - val_specificity: 0.9903 - val_sensitivity: 0.9782 - val_precision: 0.9766 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9892 - accuracy: 0.9879 - dice_coef: 0.9892 - specificity: 0.9961 - sensitivity: 0.9910 - precision: 0.9907\n",
            "Epoch 38: val_dice_coef did not improve from 0.97739\n",
            "249/249 [==============================] - 90s 363ms/step - loss: -0.9892 - accuracy: 0.9879 - dice_coef: 0.9892 - specificity: 0.9961 - sensitivity: 0.9910 - precision: 0.9907 - val_loss: -0.9768 - val_accuracy: 0.9813 - val_dice_coef: 0.9768 - val_specificity: 0.9897 - val_sensitivity: 0.9813 - val_precision: 0.9751 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9894 - accuracy: 0.9879 - dice_coef: 0.9894 - specificity: 0.9961 - sensitivity: 0.9912 - precision: 0.9907\n",
            "Epoch 39: val_dice_coef did not improve from 0.97739\n",
            "249/249 [==============================] - 89s 357ms/step - loss: -0.9894 - accuracy: 0.9879 - dice_coef: 0.9894 - specificity: 0.9961 - sensitivity: 0.9912 - precision: 0.9907 - val_loss: -0.9771 - val_accuracy: 0.9813 - val_dice_coef: 0.9771 - val_specificity: 0.9909 - val_sensitivity: 0.9786 - val_precision: 0.9780 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9910 - accuracy: 0.9885 - dice_coef: 0.9910 - specificity: 0.9968 - sensitivity: 0.9927 - precision: 0.9924\n",
            "Epoch 40: val_dice_coef improved from 0.97739 to 0.98047, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 364ms/step - loss: -0.9910 - accuracy: 0.9885 - dice_coef: 0.9910 - specificity: 0.9968 - sensitivity: 0.9927 - precision: 0.9924 - val_loss: -0.9805 - val_accuracy: 0.9832 - val_dice_coef: 0.9805 - val_specificity: 0.9936 - val_sensitivity: 0.9792 - val_precision: 0.9843 - lr: 2.0000e-05\n",
            "Epoch 41/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9924 - accuracy: 0.9890 - dice_coef: 0.9924 - specificity: 0.9974 - sensitivity: 0.9941 - precision: 0.9940\n",
            "Epoch 41: val_dice_coef improved from 0.98047 to 0.98067, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 366ms/step - loss: -0.9924 - accuracy: 0.9890 - dice_coef: 0.9924 - specificity: 0.9974 - sensitivity: 0.9941 - precision: 0.9940 - val_loss: -0.9807 - val_accuracy: 0.9832 - val_dice_coef: 0.9807 - val_specificity: 0.9937 - val_sensitivity: 0.9793 - val_precision: 0.9845 - lr: 2.0000e-05\n",
            "Epoch 42/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9931 - accuracy: 0.9892 - dice_coef: 0.9931 - specificity: 0.9978 - sensitivity: 0.9949 - precision: 0.9948\n",
            "Epoch 42: val_dice_coef improved from 0.98067 to 0.98091, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 367ms/step - loss: -0.9931 - accuracy: 0.9892 - dice_coef: 0.9931 - specificity: 0.9978 - sensitivity: 0.9949 - precision: 0.9948 - val_loss: -0.9809 - val_accuracy: 0.9833 - val_dice_coef: 0.9809 - val_specificity: 0.9936 - val_sensitivity: 0.9798 - val_precision: 0.9845 - lr: 2.0000e-05\n",
            "Epoch 43/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9936 - accuracy: 0.9893 - dice_coef: 0.9936 - specificity: 0.9980 - sensitivity: 0.9955 - precision: 0.9954\n",
            "Epoch 43: val_dice_coef improved from 0.98091 to 0.98105, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 368ms/step - loss: -0.9936 - accuracy: 0.9893 - dice_coef: 0.9936 - specificity: 0.9980 - sensitivity: 0.9955 - precision: 0.9954 - val_loss: -0.9810 - val_accuracy: 0.9834 - val_dice_coef: 0.9810 - val_specificity: 0.9936 - val_sensitivity: 0.9802 - val_precision: 0.9844 - lr: 2.0000e-05\n",
            "Epoch 44/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9940 - accuracy: 0.9894 - dice_coef: 0.9940 - specificity: 0.9982 - sensitivity: 0.9960 - precision: 0.9959\n",
            "Epoch 44: val_dice_coef improved from 0.98105 to 0.98114, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 366ms/step - loss: -0.9940 - accuracy: 0.9894 - dice_coef: 0.9940 - specificity: 0.9982 - sensitivity: 0.9960 - precision: 0.9959 - val_loss: -0.9811 - val_accuracy: 0.9834 - val_dice_coef: 0.9811 - val_specificity: 0.9936 - val_sensitivity: 0.9803 - val_precision: 0.9844 - lr: 2.0000e-05\n",
            "Epoch 45/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9943 - accuracy: 0.9894 - dice_coef: 0.9943 - specificity: 0.9984 - sensitivity: 0.9963 - precision: 0.9962\n",
            "Epoch 45: val_dice_coef improved from 0.98114 to 0.98121, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 366ms/step - loss: -0.9943 - accuracy: 0.9894 - dice_coef: 0.9943 - specificity: 0.9984 - sensitivity: 0.9963 - precision: 0.9962 - val_loss: -0.9812 - val_accuracy: 0.9834 - val_dice_coef: 0.9812 - val_specificity: 0.9936 - val_sensitivity: 0.9803 - val_precision: 0.9845 - lr: 2.0000e-05\n",
            "Epoch 46/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9945 - accuracy: 0.9895 - dice_coef: 0.9945 - specificity: 0.9985 - sensitivity: 0.9966 - precision: 0.9965\n",
            "Epoch 46: val_dice_coef improved from 0.98121 to 0.98130, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 367ms/step - loss: -0.9945 - accuracy: 0.9895 - dice_coef: 0.9945 - specificity: 0.9985 - sensitivity: 0.9966 - precision: 0.9965 - val_loss: -0.9813 - val_accuracy: 0.9834 - val_dice_coef: 0.9813 - val_specificity: 0.9937 - val_sensitivity: 0.9803 - val_precision: 0.9846 - lr: 2.0000e-05\n",
            "Epoch 47/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9947 - accuracy: 0.9895 - dice_coef: 0.9947 - specificity: 0.9986 - sensitivity: 0.9968 - precision: 0.9968\n",
            "Epoch 47: val_dice_coef improved from 0.98130 to 0.98138, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 365ms/step - loss: -0.9947 - accuracy: 0.9895 - dice_coef: 0.9947 - specificity: 0.9986 - sensitivity: 0.9968 - precision: 0.9968 - val_loss: -0.9814 - val_accuracy: 0.9834 - val_dice_coef: 0.9814 - val_specificity: 0.9937 - val_sensitivity: 0.9804 - val_precision: 0.9847 - lr: 2.0000e-05\n",
            "Epoch 48/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9949 - accuracy: 0.9895 - dice_coef: 0.9949 - specificity: 0.9987 - sensitivity: 0.9970 - precision: 0.9969\n",
            "Epoch 48: val_dice_coef improved from 0.98138 to 0.98142, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 90s 363ms/step - loss: -0.9949 - accuracy: 0.9895 - dice_coef: 0.9949 - specificity: 0.9987 - sensitivity: 0.9970 - precision: 0.9969 - val_loss: -0.9814 - val_accuracy: 0.9834 - val_dice_coef: 0.9814 - val_specificity: 0.9938 - val_sensitivity: 0.9803 - val_precision: 0.9848 - lr: 2.0000e-05\n",
            "Epoch 49/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9950 - accuracy: 0.9895 - dice_coef: 0.9950 - specificity: 0.9987 - sensitivity: 0.9971 - precision: 0.9971\n",
            "Epoch 49: val_dice_coef improved from 0.98142 to 0.98148, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 368ms/step - loss: -0.9950 - accuracy: 0.9895 - dice_coef: 0.9950 - specificity: 0.9987 - sensitivity: 0.9971 - precision: 0.9971 - val_loss: -0.9815 - val_accuracy: 0.9834 - val_dice_coef: 0.9815 - val_specificity: 0.9938 - val_sensitivity: 0.9802 - val_precision: 0.9850 - lr: 2.0000e-05\n",
            "Epoch 50/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9951 - accuracy: 0.9895 - dice_coef: 0.9951 - specificity: 0.9988 - sensitivity: 0.9972 - precision: 0.9972\n",
            "Epoch 50: val_dice_coef did not improve from 0.98148\n",
            "249/249 [==============================] - 89s 359ms/step - loss: -0.9951 - accuracy: 0.9895 - dice_coef: 0.9951 - specificity: 0.9988 - sensitivity: 0.9972 - precision: 0.9972 - val_loss: -0.9815 - val_accuracy: 0.9834 - val_dice_coef: 0.9815 - val_specificity: 0.9939 - val_sensitivity: 0.9798 - val_precision: 0.9852 - lr: 2.0000e-05\n",
            "Epoch 51/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9951 - accuracy: 0.9895 - dice_coef: 0.9951 - specificity: 0.9988 - sensitivity: 0.9972 - precision: 0.9972\n",
            "Epoch 51: val_dice_coef improved from 0.98148 to 0.98152, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 367ms/step - loss: -0.9951 - accuracy: 0.9895 - dice_coef: 0.9951 - specificity: 0.9988 - sensitivity: 0.9972 - precision: 0.9972 - val_loss: -0.9815 - val_accuracy: 0.9834 - val_dice_coef: 0.9815 - val_specificity: 0.9940 - val_sensitivity: 0.9797 - val_precision: 0.9854 - lr: 2.0000e-05\n",
            "Epoch 52/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9951 - accuracy: 0.9895 - dice_coef: 0.9951 - specificity: 0.9988 - sensitivity: 0.9972 - precision: 0.9972\n",
            "Epoch 52: val_dice_coef did not improve from 0.98152\n",
            "249/249 [==============================] - 90s 360ms/step - loss: -0.9951 - accuracy: 0.9895 - dice_coef: 0.9951 - specificity: 0.9988 - sensitivity: 0.9972 - precision: 0.9972 - val_loss: -0.9815 - val_accuracy: 0.9834 - val_dice_coef: 0.9815 - val_specificity: 0.9941 - val_sensitivity: 0.9794 - val_precision: 0.9856 - lr: 2.0000e-05\n",
            "Epoch 53/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9951 - accuracy: 0.9895 - dice_coef: 0.9951 - specificity: 0.9988 - sensitivity: 0.9972 - precision: 0.9971\n",
            "Epoch 53: val_dice_coef improved from 0.98152 to 0.98155, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 92s 370ms/step - loss: -0.9951 - accuracy: 0.9895 - dice_coef: 0.9951 - specificity: 0.9988 - sensitivity: 0.9972 - precision: 0.9971 - val_loss: -0.9815 - val_accuracy: 0.9834 - val_dice_coef: 0.9815 - val_specificity: 0.9939 - val_sensitivity: 0.9798 - val_precision: 0.9852 - lr: 2.0000e-05\n",
            "Epoch 54/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9950 - accuracy: 0.9895 - dice_coef: 0.9950 - specificity: 0.9987 - sensitivity: 0.9970 - precision: 0.9970\n",
            "Epoch 54: val_dice_coef did not improve from 0.98155\n",
            "249/249 [==============================] - 90s 361ms/step - loss: -0.9950 - accuracy: 0.9895 - dice_coef: 0.9950 - specificity: 0.9987 - sensitivity: 0.9970 - precision: 0.9970 - val_loss: -0.9812 - val_accuracy: 0.9833 - val_dice_coef: 0.9812 - val_specificity: 0.9942 - val_sensitivity: 0.9784 - val_precision: 0.9858 - lr: 2.0000e-05\n",
            "Epoch 55/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9947 - accuracy: 0.9895 - dice_coef: 0.9947 - specificity: 0.9985 - sensitivity: 0.9965 - precision: 0.9965\n",
            "Epoch 55: val_dice_coef improved from 0.98155 to 0.98190, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 92s 370ms/step - loss: -0.9947 - accuracy: 0.9895 - dice_coef: 0.9947 - specificity: 0.9985 - sensitivity: 0.9965 - precision: 0.9965 - val_loss: -0.9819 - val_accuracy: 0.9836 - val_dice_coef: 0.9819 - val_specificity: 0.9934 - val_sensitivity: 0.9818 - val_precision: 0.9840 - lr: 4.0000e-06\n",
            "Epoch 56/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9950 - accuracy: 0.9895 - dice_coef: 0.9950 - specificity: 0.9986 - sensitivity: 0.9969 - precision: 0.9968\n",
            "Epoch 56: val_dice_coef improved from 0.98190 to 0.98196, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 366ms/step - loss: -0.9950 - accuracy: 0.9895 - dice_coef: 0.9950 - specificity: 0.9986 - sensitivity: 0.9969 - precision: 0.9968 - val_loss: -0.9820 - val_accuracy: 0.9836 - val_dice_coef: 0.9820 - val_specificity: 0.9935 - val_sensitivity: 0.9817 - val_precision: 0.9842 - lr: 4.0000e-06\n",
            "Epoch 57/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9951 - accuracy: 0.9895 - dice_coef: 0.9951 - specificity: 0.9987 - sensitivity: 0.9971 - precision: 0.9971\n",
            "Epoch 57: val_dice_coef improved from 0.98196 to 0.98199, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 93s 372ms/step - loss: -0.9951 - accuracy: 0.9895 - dice_coef: 0.9951 - specificity: 0.9987 - sensitivity: 0.9971 - precision: 0.9971 - val_loss: -0.9820 - val_accuracy: 0.9836 - val_dice_coef: 0.9820 - val_specificity: 0.9935 - val_sensitivity: 0.9816 - val_precision: 0.9843 - lr: 4.0000e-06\n",
            "Epoch 58/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9952 - accuracy: 0.9895 - dice_coef: 0.9952 - specificity: 0.9988 - sensitivity: 0.9973 - precision: 0.9972\n",
            "Epoch 58: val_dice_coef improved from 0.98199 to 0.98201, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 367ms/step - loss: -0.9952 - accuracy: 0.9895 - dice_coef: 0.9952 - specificity: 0.9988 - sensitivity: 0.9973 - precision: 0.9972 - val_loss: -0.9820 - val_accuracy: 0.9836 - val_dice_coef: 0.9820 - val_specificity: 0.9936 - val_sensitivity: 0.9815 - val_precision: 0.9844 - lr: 4.0000e-06\n",
            "Epoch 59/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9953 - accuracy: 0.9895 - dice_coef: 0.9953 - specificity: 0.9989 - sensitivity: 0.9974 - precision: 0.9973\n",
            "Epoch 59: val_dice_coef improved from 0.98201 to 0.98203, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 94s 378ms/step - loss: -0.9953 - accuracy: 0.9895 - dice_coef: 0.9953 - specificity: 0.9989 - sensitivity: 0.9974 - precision: 0.9973 - val_loss: -0.9820 - val_accuracy: 0.9836 - val_dice_coef: 0.9820 - val_specificity: 0.9936 - val_sensitivity: 0.9815 - val_precision: 0.9845 - lr: 4.0000e-06\n",
            "Epoch 60/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9954 - accuracy: 0.9895 - dice_coef: 0.9954 - specificity: 0.9989 - sensitivity: 0.9975 - precision: 0.9974\n",
            "Epoch 60: val_dice_coef improved from 0.98203 to 0.98204, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 366ms/step - loss: -0.9954 - accuracy: 0.9895 - dice_coef: 0.9954 - specificity: 0.9989 - sensitivity: 0.9975 - precision: 0.9974 - val_loss: -0.9820 - val_accuracy: 0.9836 - val_dice_coef: 0.9820 - val_specificity: 0.9936 - val_sensitivity: 0.9815 - val_precision: 0.9845 - lr: 4.0000e-06\n",
            "Epoch 61/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9954 - accuracy: 0.9895 - dice_coef: 0.9954 - specificity: 0.9989 - sensitivity: 0.9975 - precision: 0.9975\n",
            "Epoch 61: val_dice_coef improved from 0.98204 to 0.98205, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 365ms/step - loss: -0.9954 - accuracy: 0.9895 - dice_coef: 0.9954 - specificity: 0.9989 - sensitivity: 0.9975 - precision: 0.9975 - val_loss: -0.9821 - val_accuracy: 0.9836 - val_dice_coef: 0.9821 - val_specificity: 0.9937 - val_sensitivity: 0.9814 - val_precision: 0.9846 - lr: 4.0000e-06\n",
            "Epoch 62/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9954 - accuracy: 0.9895 - dice_coef: 0.9954 - specificity: 0.9990 - sensitivity: 0.9976 - precision: 0.9976\n",
            "Epoch 62: val_dice_coef improved from 0.98205 to 0.98206, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 92s 369ms/step - loss: -0.9954 - accuracy: 0.9895 - dice_coef: 0.9954 - specificity: 0.9990 - sensitivity: 0.9976 - precision: 0.9976 - val_loss: -0.9821 - val_accuracy: 0.9836 - val_dice_coef: 0.9821 - val_specificity: 0.9937 - val_sensitivity: 0.9814 - val_precision: 0.9846 - lr: 4.0000e-06\n",
            "Epoch 63/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9976\n",
            "Epoch 63: val_dice_coef improved from 0.98206 to 0.98207, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 92s 369ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9976 - val_loss: -0.9821 - val_accuracy: 0.9836 - val_dice_coef: 0.9821 - val_specificity: 0.9937 - val_sensitivity: 0.9813 - val_precision: 0.9847 - lr: 4.0000e-06\n",
            "Epoch 64/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9954 - accuracy: 0.9895 - dice_coef: 0.9954 - specificity: 0.9989 - sensitivity: 0.9976 - precision: 0.9975\n",
            "Epoch 64: val_dice_coef improved from 0.98207 to 0.98213, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 365ms/step - loss: -0.9954 - accuracy: 0.9895 - dice_coef: 0.9954 - specificity: 0.9989 - sensitivity: 0.9976 - precision: 0.9975 - val_loss: -0.9821 - val_accuracy: 0.9836 - val_dice_coef: 0.9821 - val_specificity: 0.9936 - val_sensitivity: 0.9818 - val_precision: 0.9844 - lr: 8.0000e-07\n",
            "Epoch 65/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9976 - precision: 0.9976\n",
            "Epoch 65: val_dice_coef improved from 0.98213 to 0.98213, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 92s 369ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9976 - precision: 0.9976 - val_loss: -0.9821 - val_accuracy: 0.9836 - val_dice_coef: 0.9821 - val_specificity: 0.9936 - val_sensitivity: 0.9818 - val_precision: 0.9844 - lr: 8.0000e-07\n",
            "Epoch 66/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9976 - precision: 0.9976\n",
            "Epoch 66: val_dice_coef improved from 0.98213 to 0.98213, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 92s 368ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9976 - precision: 0.9976 - val_loss: -0.9821 - val_accuracy: 0.9836 - val_dice_coef: 0.9821 - val_specificity: 0.9936 - val_sensitivity: 0.9818 - val_precision: 0.9843 - lr: 8.0000e-07\n",
            "Epoch 67/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9976\n",
            "Epoch 67: val_dice_coef improved from 0.98213 to 0.98213, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 367ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9976 - val_loss: -0.9821 - val_accuracy: 0.9836 - val_dice_coef: 0.9821 - val_specificity: 0.9936 - val_sensitivity: 0.9818 - val_precision: 0.9843 - lr: 8.0000e-07\n",
            "Epoch 68/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977\n",
            "Epoch 68: val_dice_coef improved from 0.98213 to 0.98213, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 92s 371ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977 - val_loss: -0.9821 - val_accuracy: 0.9836 - val_dice_coef: 0.9821 - val_specificity: 0.9935 - val_sensitivity: 0.9818 - val_precision: 0.9843 - lr: 8.0000e-07\n",
            "Epoch 69/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977\n",
            "Epoch 69: val_dice_coef improved from 0.98213 to 0.98214, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 365ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977 - val_loss: -0.9821 - val_accuracy: 0.9836 - val_dice_coef: 0.9821 - val_specificity: 0.9935 - val_sensitivity: 0.9818 - val_precision: 0.9843 - lr: 8.0000e-07\n",
            "Epoch 70/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9976 - precision: 0.9978\n",
            "Epoch 70: val_dice_coef improved from 0.98214 to 0.98215, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 92s 370ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9976 - precision: 0.9978 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9839 - lr: 1.6000e-07\n",
            "Epoch 71/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977\n",
            "Epoch 71: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 89s 357ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977 - val_loss: -0.9821 - val_accuracy: 0.9836 - val_dice_coef: 0.9821 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9839 - lr: 1.6000e-07\n",
            "Epoch 72/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977\n",
            "Epoch 72: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 90s 362ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9839 - lr: 1.6000e-07\n",
            "Epoch 73/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977\n",
            "Epoch 73: val_dice_coef improved from 0.98215 to 0.98215, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 366ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9839 - lr: 1.6000e-07\n",
            "Epoch 74/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977\n",
            "Epoch 74: val_dice_coef improved from 0.98215 to 0.98215, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 92s 370ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9839 - lr: 1.6000e-07\n",
            "Epoch 75/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 75: val_dice_coef improved from 0.98215 to 0.98215, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 91s 364ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9839 - lr: 3.2000e-08\n",
            "Epoch 76/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 76: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 91s 364ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9839 - lr: 3.2000e-08\n",
            "Epoch 77/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977\n",
            "Epoch 77: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 89s 359ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9839 - lr: 3.2000e-08\n",
            "Epoch 78/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977\n",
            "Epoch 78: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 92s 369ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9839 - lr: 3.2000e-08\n",
            "Epoch 79/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977\n",
            "Epoch 79: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 90s 361ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9977 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9839 - lr: 3.2000e-08\n",
            "Epoch 80/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 80: val_dice_coef improved from 0.98215 to 0.98215, saving model to best_model_224_res_reduce_lr.h5\n",
            "249/249 [==============================] - 92s 370ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 6.4000e-09\n",
            "Epoch 81/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 81: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 91s 367ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 6.4000e-09\n",
            "Epoch 82/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 82: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 90s 362ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 6.4000e-09\n",
            "Epoch 83/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 83: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 90s 361ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 6.4000e-09\n",
            "Epoch 84/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 84: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 89s 359ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 6.4000e-09\n",
            "Epoch 85/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 85: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 90s 363ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 1.2800e-09\n",
            "Epoch 86/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 86: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 89s 357ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 1.2800e-09\n",
            "Epoch 87/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 87: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 90s 362ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 1.2800e-09\n",
            "Epoch 88/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 88: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 90s 362ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 1.2800e-09\n",
            "Epoch 89/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 89: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 89s 359ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 1.2800e-09\n",
            "Epoch 90/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 90: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 91s 365ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 2.5600e-10\n",
            "Epoch 91/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 91: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 90s 363ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 2.5600e-10\n",
            "Epoch 92/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 92: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 92s 370ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 2.5600e-10\n",
            "Epoch 93/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 93: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 89s 357ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 2.5600e-10\n",
            "Epoch 94/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 94: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 90s 362ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 2.5600e-10\n",
            "Epoch 95/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 95: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 90s 363ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 5.1200e-11\n",
            "Epoch 96/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 96: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 89s 358ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 5.1200e-11\n",
            "Epoch 97/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 97: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 90s 360ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 5.1200e-11\n",
            "Epoch 98/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 98: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 89s 356ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 5.1200e-11\n",
            "Epoch 99/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 99: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 90s 362ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 5.1200e-11\n",
            "Epoch 100/100\n",
            "249/249 [==============================] - ETA: 0s - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977\n",
            "Epoch 100: val_dice_coef did not improve from 0.98215\n",
            "249/249 [==============================] - 88s 355ms/step - loss: -0.9955 - accuracy: 0.9895 - dice_coef: 0.9955 - specificity: 0.9990 - sensitivity: 0.9978 - precision: 0.9977 - val_loss: -0.9822 - val_accuracy: 0.9836 - val_dice_coef: 0.9822 - val_specificity: 0.9934 - val_sensitivity: 0.9823 - val_precision: 0.9840 - lr: 1.0240e-11\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "results = model.fit_generator(train_gen, steps_per_epoch=steps_per_epoch, epochs = epochs, validation_data = val_gen, validation_steps = validation_steps,callbacks=[checkpointer,reduce_lr])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VuFPbbzxEkl7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize training\n"
      ],
      "metadata": {
        "id": "fYFQKF1sEmk0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNAK0OopVIl5"
      },
      "outputs": [],
      "source": [
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(results.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(results.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(results.history['dice_coef'], 'b', label='train dice coef')\n",
        "acc_ax.plot(results.history['val_dice_coef'], 'g', label='val dice coef')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jar12-m7LYnW"
      },
      "outputs": [],
      "source": [
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(results.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(results.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(results.history['dice_coef'], 'b', label='train dice coef')\n",
        "acc_ax.plot(results.history['val_dice_coef'], 'g', label='val dice coef')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ri_PkVjmLaP7"
      },
      "outputs": [],
      "source": [
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(results.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(results.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(results.history['specificity'], 'b', label='train specificity')\n",
        "acc_ax.plot(results.history['val_specificity'], 'g', label='val specificity')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLMr5UEwLrpX"
      },
      "outputs": [],
      "source": [
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(results.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(results.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(results.history['sensitivity'], 'b', label='train sensitivity')\n",
        "acc_ax.plot(results.history['val_sensitivity'], 'g', label='val sensitivity')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2hrCr7wL09t"
      },
      "outputs": [],
      "source": [
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(results.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(results.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(results.history['precision'], 'b', label='train precision')\n",
        "acc_ax.plot(results.history['val_precision'], 'g', label='val precision')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy5XULlqLraJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6R39g2jM21i"
      },
      "outputs": [],
      "source": [
        "print(results.history['precision'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYu0Rn8OM5Sn"
      },
      "outputs": [],
      "source": [
        "print(results.history['dice_coef'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmsVyhIzMdG5"
      },
      "outputs": [],
      "source": [
        "print(results.history['specificity'][-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict\n",
        "\n"
      ],
      "metadata": {
        "id": "y66C4t1R6jZI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vc_vSm9762g4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ec725ba-b06d-4a1e-ba25-f2899ec9ea1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of test data :  335\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['001_HC.png', '000_HC.png', '003_HC.png', '004_HC.png', '002_HC.png']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "\n",
        "# import os\n",
        "test_list = os.listdir(\"test_set/\")\n",
        "print(\"The number of test data : \", len(test_list))\n",
        "test_list[:5]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SmVonmXy3oyE"
      },
      "outputs": [],
      "source": [
        "#used just for prediction, not as a checkpoint\n",
        "model = tf.keras.models.load_model('best_model_224_res_retraining_1e-4.h5', custom_objects={'dice_coef_loss': dice_coef_loss, 'dice_coef':dice_coef,'specificity':specificity,'sensitivity':sensitivity,'precision':precision})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smooth=1.\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection +smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CTpEAT1TSp7a"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    # convert to 2D before comparing results\n",
        "    # y_true = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "    # print(np.array(y_true).shape)\n",
        "    # print(np.array(y_pred).shape)\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "\n",
        "\n",
        "    # print((2. * intersection ) / (K.sum(y_true_f) + K.sum(y_pred_f) ))\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def jac_distance(y_true, y_pred ):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    # intersection = K.sum(y_true_f * y_pred_f)\n",
        "\n",
        "    intersection = K.sum(K.abs(y_true_f * y_pred_f), axis=-1)\n",
        "    sum_ = K.sum(K.abs(y_true_f) + K.abs(y_pred_f), axis=-1)\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "\n",
        "    # print(jac)\n",
        "    return jac\n",
        "\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    return true_positives / (predicted_positives + K.epsilon())\n",
        "\n",
        "def specificity(y_true, y_pred):\n",
        "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
        "    possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n",
        "    return true_negatives / (possible_negatives + K.epsilon())\n",
        "\n",
        "def sensitivity(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())"
      ],
      "metadata": {
        "id": "5v0qTri9-fgb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def getbound(binary_mask):\n",
        "\n",
        "  # draw = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
        "\n",
        "  # draw[img > 0.5] = (255,) * 3\n",
        "  kernelSize = (3,3)\n",
        "\n",
        "  # gray = cv2.cvtColor(draw, cv2.COLOR_BGR2GRAY)\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernelSize)\n",
        "  gradient = cv2.morphologyEx(binary_mask, cv2.MORPH_GRADIENT, kernel)\n",
        "  # plt.imshow()\n",
        "  # plt.show()\n",
        "  # gradient = cv2.cvtColor(gradient, cv2.COLOR_GRAY2RGB)\n",
        "  return gradient\n",
        "\n",
        "\n",
        "def fitEllipse(binary_mask, method=\"Direct\"):\n",
        "    assert binary_mask.min() >= 0.0 and binary_mask.max() <= 1.0\n",
        "\n",
        "    # print(binary_mask.shape)\n",
        "   \n",
        "    gradient  = getbound(binary_mask)\n",
        "\n",
        "    # print(gradient.shape)\n",
        "\n",
        "    points1 = np.argwhere(gradient > 0.5)  \n",
        "    points2 = np.argwhere(binary_mask > 0.5)  \n",
        "\n",
        "    points = points1\n",
        "    # print(points1.shape)\n",
        "    # print(points2.shape)\n",
        "\n",
        "    if method == \"AMS\":\n",
        "      #taubins method\n",
        "        (xx, yy), (MA, ma), angle = cv2.fitEllipseAMS(points)\n",
        "    elif method == \"Direct\":\n",
        "      #Fitzgibbon1999\n",
        "        (xx, yy), (MA, ma), angle = cv2.fitEllipseDirect(points)\n",
        "    elif method == \"Simple\":\n",
        "      #Fitzgibbon95]\n",
        "        (xx, yy), (MA, ma), angle = cv2.fitEllipse(points)\n",
        "\n",
        "    return (xx, yy), (MA, ma), angle\n"
      ],
      "metadata": {
        "id": "J8qIHWeO-jcW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0r0WZEox66A0"
      },
      "outputs": [],
      "source": [
        "X_50 = train_image[:]\n",
        "y_50  = train_mask[:]\n",
        "\n",
        "X_test = np.empty((len(X_50[:]), IMG_HEIGHT, IMG_WIDTH), dtype = 'float32')\n",
        "\n",
        "\n",
        "for i, item in enumerate(X_50[:]):\n",
        "    image = cv2.imread(\"training_set/\" + item, 0)\n",
        "    image = cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_AREA)\n",
        "    X_test[i] = image\n",
        "\n",
        "\n",
        "X_test = X_test[:,:,:,np.newaxis] / 255\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "87i67piQBi2B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f64eee-2682-40cc-f065-2e8bfab5d71a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(999, 224, 224, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "68wQd7zE_btm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad71fae4-c58b-4f22-e686-a659c20f82e1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 15s 166ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.shape"
      ],
      "metadata": {
        "id": "7xsC7Mt5Bk4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f177ce54-3215-400a-e4fa-54b6fe9c0786"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(999, 224, 224, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BcQpIpyO65sm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7fd5ebc-dc08-4c6d-d77c-872f9bd9ef90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(155.9849090576172, 114.13766479492188) (53.14309310913086, 89.11324310302734) 83.28296661376953\n",
            "(92.34103393554688, 111.98336029052734) (58.168052673339844, 79.30062103271484) 89.0343017578125\n",
            "(79.46143341064453, 79.19248962402344) (93.11982727050781, 154.26617431640625) 96.81340789794922\n",
            "(148.35711669921875, 116.27120208740234) (72.69397735595703, 90.3257064819336) 88.78465270996094\n",
            "(121.49918365478516, 94.51712036132812) (84.97398376464844, 130.33245849609375) 105.26300048828125\n",
            "(98.11151123046875, 90.5147933959961) (56.11433029174805, 75.11370849609375) 77.4620361328125\n",
            "(101.34178924560547, 119.51667785644531) (84.162109375, 147.57823181152344) 92.34976959228516\n",
            "(151.97596740722656, 125.401611328125) (54.44251251220703, 74.78959655761719) 80.57091522216797\n",
            "(145.75711059570312, 108.62500762939453) (69.77761840820312, 83.3984603881836) 79.45637512207031\n",
            "(88.1012191772461, 125.77745819091797) (53.74782943725586, 106.5197982788086) 65.19302368164062\n",
            "(105.72269439697266, 97.5567626953125) (75.03167724609375, 126.57633972167969) 87.00907897949219\n",
            "(99.98316192626953, 100.16895294189453) (81.24161529541016, 130.88861083984375) 83.43333435058594\n",
            "(117.97874450683594, 118.71289825439453) (106.23220825195312, 171.9087371826172) 82.91012573242188\n",
            "(89.33348083496094, 113.60508728027344) (63.637786865234375, 88.79391479492188) 81.27079772949219\n",
            "(111.34370422363281, 115.85017395019531) (90.9602279663086, 142.2480010986328) 103.59681701660156\n",
            "(107.77771759033203, 120.121337890625) (71.77686309814453, 102.3839111328125) 97.82681274414062\n",
            "(103.33805084228516, 124.40800476074219) (74.6540298461914, 92.008056640625) 96.52007293701172\n",
            "(105.38665008544922, 115.86644744873047) (69.01856994628906, 108.17813110351562) 94.46611022949219\n",
            "(122.60616302490234, 129.1083526611328) (96.10279846191406, 176.2411346435547) 81.95356750488281\n",
            "(121.43775939941406, 117.12340545654297) (98.28841400146484, 135.589599609375) 71.69400787353516\n",
            "(93.22331237792969, 114.7973403930664) (73.2929458618164, 122.61213684082031) 82.6214370727539\n",
            "(106.82850646972656, 118.46782684326172) (74.18953704833984, 120.19617462158203) 104.5271987915039\n",
            "(101.72535705566406, 105.58704376220703) (110.55184936523438, 121.03093719482422) 63.907684326171875\n",
            "(120.0755615234375, 107.9354476928711) (53.72480392456055, 84.00289154052734) 85.03585052490234\n",
            "(119.7733383178711, 128.73880004882812) (55.4932975769043, 87.91598510742188) 86.80877685546875\n",
            "(131.00350952148438, 108.713134765625) (119.60231018066406, 149.38575744628906) 117.81255340576172\n",
            "(105.93260955810547, 112.77071380615234) (109.28990173339844, 133.04908752441406) 79.48949432373047\n",
            "(130.52415466308594, 113.738037109375) (53.57980728149414, 99.1655044555664) 89.87425994873047\n",
            "(138.8095245361328, 95.99434661865234) (135.36062622070312, 151.0880126953125) 99.47681427001953\n",
            "(127.47337341308594, 135.1785430908203) (49.559566497802734, 75.526123046875) 82.42411804199219\n",
            "(125.70177459716797, 157.332763671875) (65.78938293457031, 80.8335952758789) 100.06356811523438\n",
            "(103.90868377685547, 112.12702178955078) (58.05337905883789, 96.32960510253906) 95.85862731933594\n",
            "(131.18130493164062, 147.5655059814453) (79.12413024902344, 126.8082275390625) 99.53685760498047\n",
            "(88.37451934814453, 76.32809448242188) (50.0158576965332, 74.61080932617188) 89.5824203491211\n",
            "(99.36470031738281, 86.21075439453125) (52.38527297973633, 94.4560775756836) 86.16313171386719\n",
            "(159.67935180664062, 108.35235595703125) (66.76244354248047, 91.81526184082031) 101.06497955322266\n",
            "(130.10560607910156, 148.465087890625) (59.236637115478516, 107.70167541503906) 84.78012084960938\n",
            "(132.41004943847656, 84.62991333007812) (87.84707641601562, 148.74667358398438) 94.41461181640625\n",
            "(88.19161224365234, 95.26264190673828) (100.92767333984375, 154.13853454589844) 79.7115478515625\n",
            "(148.87437438964844, 116.64208221435547) (75.29317474365234, 125.5073471069336) 82.4107437133789\n",
            "(137.8443145751953, 111.79418182373047) (53.919857025146484, 74.90363311767578) 93.48338317871094\n",
            "(124.66780090332031, 116.51258850097656) (59.61939239501953, 105.43614959716797) 90.84699249267578\n",
            "(107.63217163085938, 119.61554718017578) (70.35490417480469, 106.95536041259766) 74.8324203491211\n",
            "(99.25647735595703, 92.79962921142578) (73.69441986083984, 93.84246826171875) 76.16901397705078\n",
            "(101.28852081298828, 97.12957000732422) (63.485145568847656, 113.50572204589844) 88.84089660644531\n",
            "(119.2947998046875, 132.03822326660156) (67.0084228515625, 118.64295959472656) 96.13903045654297\n",
            "(111.23185729980469, 89.35335540771484) (78.38726043701172, 104.51756286621094) 70.78064727783203\n",
            "(94.10795593261719, 99.23011779785156) (69.77938842773438, 118.11656188964844) 80.7406234741211\n",
            "(96.36644744873047, 103.26560974121094) (113.95951843261719, 145.59449768066406) 102.18933868408203\n",
            "(103.43656158447266, 128.50802612304688) (97.72176361083984, 142.81173706054688) 73.60640716552734\n",
            "(71.54653930664062, 111.39898681640625) (73.53204345703125, 113.11767578125) 80.6073226928711\n",
            "(129.49691772460938, 84.70777130126953) (78.96223449707031, 127.8359375) 99.91561889648438\n",
            "(110.263427734375, 105.48214721679688) (117.71269226074219, 165.18106079101562) 81.0232925415039\n",
            "(128.40567016601562, 105.11351776123047) (101.35792541503906, 147.70651245117188) 97.72630310058594\n",
            "(166.70684814453125, 136.40724182128906) (57.93699264526367, 72.92875671386719) 72.56392669677734\n",
            "(117.15091705322266, 105.05580139160156) (110.14017486572266, 182.6686248779297) 80.54454803466797\n",
            "(91.10681915283203, 107.8969497680664) (81.0593032836914, 121.96772766113281) 105.23177337646484\n",
            "(134.8504638671875, 113.37519073486328) (69.07328033447266, 112.77955627441406) 78.69325256347656\n",
            "(105.71348571777344, 89.68008422851562) (100.04544067382812, 115.59812927246094) 96.67654418945312\n",
            "(66.74710083007812, 124.4754638671875) (53.794761657714844, 87.00353240966797) 89.77074432373047\n",
            "(102.78564453125, 94.52204132080078) (100.54548645019531, 150.45289611816406) 97.96544647216797\n",
            "(103.28269958496094, 100.06892395019531) (101.9527816772461, 147.92953491210938) 101.47756958007812\n",
            "(103.9525146484375, 112.30646514892578) (96.5341796875, 163.6508331298828) 92.82077026367188\n",
            "(154.29623413085938, 85.39793395996094) (83.112060546875, 93.07838439941406) 80.10607147216797\n",
            "(114.31047821044922, 123.93040466308594) (64.55281829833984, 92.64421081542969) 74.53311157226562\n",
            "(113.87747192382812, 123.07637023925781) (128.1302490234375, 150.8089599609375) 93.0052719116211\n",
            "(119.490234375, 141.648681640625) (89.20626831054688, 162.34454345703125) 82.16508483886719\n",
            "(135.48526000976562, 113.75630950927734) (101.763671875, 127.70038604736328) 79.38729858398438\n",
            "(116.52159881591797, 122.15132904052734) (143.74305725097656, 159.2928924560547) 102.4158935546875\n",
            "(109.92656707763672, 98.391357421875) (78.86862182617188, 116.8854751586914) 83.06255340576172\n",
            "(102.45314025878906, 112.89041137695312) (91.62521362304688, 118.49064636230469) 102.44426727294922\n",
            "(136.9298553466797, 92.52313232421875) (70.51213073730469, 109.34698486328125) 92.38026428222656\n",
            "(118.52564239501953, 118.27893829345703) (108.96295928955078, 154.0426025390625) 100.9170150756836\n",
            "(68.81206512451172, 103.1013412475586) (80.14869689941406, 102.89580535888672) 93.10670471191406\n",
            "(111.97838592529297, 95.41165924072266) (80.61587524414062, 144.8854217529297) 85.02750396728516\n",
            "(121.50446319580078, 90.65013885498047) (59.58134460449219, 77.0711441040039) 105.6722412109375\n",
            "(108.41157531738281, 103.34579467773438) (85.82638549804688, 111.50720977783203) 77.43653869628906\n",
            "(118.87081146240234, 151.19754028320312) (55.83739471435547, 72.59934997558594) 71.26395416259766\n",
            "(122.77692413330078, 124.94819641113281) (101.0335464477539, 156.29336547851562) 82.93627166748047\n",
            "(126.96326446533203, 96.3866195678711) (94.1235122680664, 150.5989990234375) 82.36901092529297\n",
            "(110.57799530029297, 74.4514389038086) (77.14398193359375, 119.65709686279297) 75.32323455810547\n",
            "(114.36734008789062, 107.87873077392578) (105.93328094482422, 151.23797607421875) 70.37663269042969\n",
            "(115.98233032226562, 95.29155731201172) (103.58319854736328, 141.1141357421875) 72.41244506835938\n",
            "(120.64161682128906, 132.86012268066406) (58.185882568359375, 102.64535522460938) 89.5085678100586\n",
            "(116.04861450195312, 93.44025421142578) (121.38998413085938, 179.2896728515625) 74.82451629638672\n",
            "(107.73219299316406, 127.32229614257812) (119.63504028320312, 183.68170166015625) 76.43489074707031\n",
            "(104.20816040039062, 81.05191802978516) (91.61752319335938, 157.51194763183594) 98.40450286865234\n",
            "(134.55874633789062, 145.5654296875) (61.603118896484375, 106.19157409667969) 86.37506103515625\n",
            "(141.73057556152344, 135.36968994140625) (46.45037841796875, 75.53045654296875) 92.54900360107422\n",
            "(122.66828155517578, 89.1217041015625) (91.95496368408203, 159.13816833496094) 90.52468872070312\n",
            "(118.5370864868164, 108.18327331542969) (119.0385971069336, 144.78463745117188) 79.3965072631836\n",
            "(93.83422088623047, 117.26152038574219) (98.81644439697266, 148.6597442626953) 100.02873229980469\n",
            "(118.5689926147461, 110.64960479736328) (79.83544921875, 114.4734115600586) 102.41551208496094\n",
            "(84.94701385498047, 112.49964141845703) (79.42047119140625, 107.64532470703125) 71.94882202148438\n",
            "(135.73654174804688, 134.40982055664062) (66.57600402832031, 117.77162170410156) 91.47377014160156\n",
            "(117.64131164550781, 130.33705139160156) (102.39427185058594, 175.2654571533203) 82.03985595703125\n",
            "(96.1714859008789, 116.64812469482422) (84.25907897949219, 100.77752685546875) 87.63282775878906\n",
            "(91.41448974609375, 116.96568298339844) (130.79161071777344, 166.93968200683594) 82.07552337646484\n",
            "(118.4703140258789, 141.24667358398438) (76.85519409179688, 111.81165313720703) 82.30764770507812\n",
            "(165.41705322265625, 99.87353515625) (52.4887809753418, 66.08325958251953) 87.68329620361328\n",
            "(155.6747283935547, 100.5469741821289) (58.99325942993164, 73.8344955444336) 89.92742919921875\n",
            "(113.31420135498047, 98.7821044921875) (123.9650650024414, 194.8087615966797) 100.21615600585938\n",
            "(103.43341827392578, 115.66631317138672) (114.75707244873047, 183.19741821289062) 102.03644561767578\n",
            "(90.00802612304688, 126.89627075195312) (91.20282745361328, 138.2747802734375) 96.0065689086914\n",
            "(76.50399017333984, 155.3042449951172) (60.647056579589844, 99.48494720458984) 82.71073150634766\n",
            "(143.57369995117188, 79.48221588134766) (65.3608169555664, 91.8089828491211) 71.13359832763672\n",
            "(99.88983917236328, 104.19876098632812) (117.70684814453125, 144.10049438476562) 89.61819458007812\n",
            "(135.5566864013672, 98.61864471435547) (65.87811279296875, 110.90658569335938) 90.5495376586914\n",
            "(90.42032623291016, 117.17005920410156) (89.44438934326172, 135.88377380371094) 101.63017272949219\n",
            "(147.7235565185547, 104.43453216552734) (89.6764144897461, 115.83256530761719) 78.7964859008789\n",
            "(90.44862365722656, 103.54278564453125) (98.89726257324219, 159.20533752441406) 97.9609603881836\n",
            "(111.53348541259766, 136.96360778808594) (115.78317260742188, 169.84918212890625) 106.27802276611328\n",
            "(100.03467559814453, 114.4405517578125) (99.60826110839844, 120.50930786132812) 98.85283660888672\n",
            "(92.8614273071289, 126.24984741210938) (107.95854949951172, 161.11102294921875) 82.42440032958984\n",
            "(127.47898864746094, 105.44365692138672) (114.90562438964844, 134.18890380859375) 87.05931091308594\n",
            "(152.80259704589844, 144.96176147460938) (47.87660217285156, 83.61705017089844) 91.22080993652344\n",
            "(88.27023315429688, 89.78286743164062) (111.79423522949219, 151.58468627929688) 102.53681945800781\n",
            "(111.37125396728516, 115.54203796386719) (55.32954025268555, 69.88563537597656) 69.07463836669922\n",
            "(107.25032806396484, 111.13140106201172) (88.12300872802734, 143.11961364746094) 106.43212127685547\n",
            "(103.33636474609375, 112.01866912841797) (95.61344146728516, 119.70220184326172) 91.30931854248047\n",
            "(133.43417358398438, 122.65274047851562) (72.59568786621094, 115.6116714477539) 91.83702087402344\n",
            "(142.61778259277344, 128.92848205566406) (60.758419036865234, 77.37411499023438) 85.12742614746094\n",
            "(101.6995849609375, 87.61063385009766) (99.77005004882812, 148.2731170654297) 103.93402099609375\n",
            "(134.29530334472656, 102.93524169921875) (127.2168960571289, 152.09519958496094) 100.8545150756836\n",
            "(87.15415954589844, 102.67113494873047) (119.81476593017578, 141.9055938720703) 77.03267669677734\n",
            "(116.00775146484375, 116.44720458984375) (112.0562973022461, 133.5258331298828) 98.69637298583984\n",
            "(109.49745178222656, 112.2320327758789) (75.31314086914062, 101.7914810180664) 64.44622802734375\n",
            "(112.01394653320312, 132.4139862060547) (130.4507293701172, 155.69908142089844) 100.72296142578125\n",
            "(95.3353271484375, 126.73934936523438) (91.5322494506836, 150.87916564941406) 89.5003433227539\n",
            "(132.00987243652344, 92.09101867675781) (85.52415466308594, 138.5581512451172) 96.44628143310547\n",
            "(107.00360870361328, 109.1476058959961) (130.27627563476562, 135.4295196533203) 96.93658447265625\n",
            "(114.21932983398438, 96.57085418701172) (114.82176208496094, 135.16038513183594) 115.72994232177734\n",
            "(84.63333892822266, 128.80667114257812) (80.49292755126953, 95.82569885253906) 79.29804229736328\n",
            "(91.09117126464844, 117.79075622558594) (82.38275909423828, 98.80340576171875) 94.75321197509766\n",
            "(112.46756744384766, 106.91608428955078) (81.410400390625, 95.00855255126953) 75.0252914428711\n",
            "(107.04967498779297, 126.81226348876953) (143.5624237060547, 161.65518188476562) 92.22293853759766\n",
            "(152.46543884277344, 136.301513671875) (48.807498931884766, 72.28333282470703) 72.24774169921875\n",
            "(114.6318130493164, 103.48026275634766) (121.90868377685547, 174.45883178710938) 74.96370697021484\n",
            "(145.55250549316406, 109.21542358398438) (84.23710632324219, 89.73661041259766) 63.56169891357422\n",
            "(140.3295135498047, 126.73838806152344) (70.5472183227539, 129.3877716064453) 85.38017272949219\n",
            "(126.07527923583984, 126.63002014160156) (54.512142181396484, 79.63737487792969) 85.27864837646484\n",
            "(83.648193359375, 130.5802764892578) (59.2938346862793, 100.20613098144531) 76.3329849243164\n",
            "(119.09874725341797, 137.09523010253906) (67.83598327636719, 105.64055633544922) 101.44820404052734\n",
            "(153.40335083007812, 138.0769805908203) (64.32282257080078, 97.98933410644531) 91.43952941894531\n",
            "(129.6687469482422, 114.92314910888672) (64.30634307861328, 101.20892333984375) 98.71952056884766\n",
            "(160.2379913330078, 92.343994140625) (69.17967987060547, 81.7723617553711) 81.1885757446289\n",
            "(108.2219009399414, 112.70247650146484) (113.9268798828125, 140.907958984375) 100.12969207763672\n",
            "(93.70275115966797, 96.885986328125) (115.57501983642578, 167.4646759033203) 74.179443359375\n",
            "(83.27377319335938, 88.00944519042969) (129.44992065429688, 153.39682006835938) 97.8714599609375\n",
            "(137.22299194335938, 115.89861297607422) (73.28165435791016, 101.12286376953125) 103.20806121826172\n",
            "(137.49867248535156, 98.95657348632812) (83.29505920410156, 117.6116943359375) 101.27144622802734\n",
            "(123.90989685058594, 118.27384185791016) (133.47731018066406, 164.3323516845703) 88.95724487304688\n",
            "(124.24195098876953, 125.19821166992188) (122.19307708740234, 151.93104553222656) 86.05149841308594\n",
            "(114.49447631835938, 119.71314239501953) (127.23970794677734, 149.6635284423828) 92.81468963623047\n",
            "(119.8740234375, 117.95403289794922) (129.68157958984375, 154.33168029785156) 84.3832015991211\n",
            "(120.6627426147461, 112.2313003540039) (133.10650634765625, 158.95584106445312) 97.14362335205078\n",
            "(97.29290008544922, 108.36538696289062) (135.49754333496094, 173.65036010742188) 66.96826171875\n",
            "(99.65232849121094, 109.27669525146484) (118.66355895996094, 187.11793518066406) 73.96635437011719\n",
            "(96.64398193359375, 94.35851287841797) (128.9500274658203, 160.15194702148438) 81.15872192382812\n",
            "(156.25738525390625, 127.47522735595703) (60.84300994873047, 100.03048706054688) 94.89046478271484\n",
            "(128.9243927001953, 125.409912109375) (85.06997680664062, 113.22222137451172) 81.95368194580078\n",
            "(106.64178466796875, 113.26011657714844) (63.7459831237793, 102.28074645996094) 100.0846939086914\n",
            "(98.41072845458984, 100.29010772705078) (75.44060516357422, 108.70042419433594) 101.06070709228516\n",
            "(104.31454467773438, 104.2317886352539) (99.47997283935547, 176.08644104003906) 89.02147674560547\n",
            "(126.73015594482422, 130.1942138671875) (60.211788177490234, 85.53742218017578) 113.44764709472656\n",
            "(105.74777221679688, 115.76881408691406) (100.86776733398438, 119.67124938964844) 66.63182067871094\n",
            "(125.13916015625, 116.4795913696289) (64.69873809814453, 88.68547821044922) 105.9864501953125\n",
            "(111.69078063964844, 101.5989761352539) (92.67523956298828, 134.0050506591797) 72.23697662353516\n",
            "(87.4664535522461, 86.35555267333984) (109.4193344116211, 124.00576782226562) 71.13616943359375\n",
            "(117.07521057128906, 101.50360107421875) (79.30316162109375, 130.95997619628906) 85.45474243164062\n",
            "(129.84149169921875, 99.02931213378906) (82.8746109008789, 132.4219512939453) 97.35735321044922\n",
            "(98.22372436523438, 89.79549407958984) (98.90394592285156, 152.01791381835938) 97.98307800292969\n",
            "(108.69926452636719, 106.11321258544922) (129.00711059570312, 171.27757263183594) 100.18038940429688\n",
            "(99.55854797363281, 119.25779724121094) (81.28945922851562, 104.5470962524414) 107.00335693359375\n",
            "(120.27690124511719, 104.21879577636719) (124.35313415527344, 158.78981018066406) 78.90300750732422\n",
            "(89.80606079101562, 96.88310241699219) (134.37120056152344, 151.00204467773438) 88.83621978759766\n",
            "(106.34616088867188, 106.47708129882812) (121.59130859375, 164.4090118408203) 102.25670623779297\n",
            "(159.54434204101562, 123.46650695800781) (49.756221771240234, 67.07111358642578) 109.22169494628906\n",
            "(107.11909484863281, 127.61719512939453) (107.32169342041016, 140.55862426757812) 82.43252563476562\n",
            "(89.14053344726562, 125.97730255126953) (127.10682678222656, 143.6744384765625) 82.8914566040039\n",
            "(97.19158172607422, 105.64388275146484) (96.24578094482422, 111.97388458251953) 83.9261474609375\n",
            "(118.60899353027344, 149.341064453125) (84.42716217041016, 116.48994445800781) 77.03826141357422\n",
            "(95.38143920898438, 130.66871643066406) (93.1907958984375, 105.44983673095703) 80.71695709228516\n",
            "(110.70844268798828, 116.19541931152344) (96.41802978515625, 131.84056091308594) 81.41692352294922\n",
            "(96.52238464355469, 102.30856323242188) (93.82026672363281, 137.8408203125) 78.80772399902344\n",
            "(114.65482330322266, 136.90951538085938) (79.17008209228516, 107.3963851928711) 109.28349304199219\n",
            "(125.80973815917969, 100.00761413574219) (120.3243637084961, 141.76138305664062) 91.7015609741211\n",
            "(101.81114196777344, 83.47433471679688) (97.68994140625, 129.32290649414062) 74.13923645019531\n",
            "(119.31166076660156, 117.0577163696289) (119.3912582397461, 146.55125427246094) 91.12190246582031\n",
            "(106.1597671508789, 94.43872833251953) (107.69453430175781, 122.17575073242188) 80.80570983886719\n",
            "(87.96128845214844, 100.88909912109375) (130.75001525878906, 152.0745391845703) 88.56661987304688\n",
            "(80.22784423828125, 106.25436401367188) (63.12147521972656, 82.08267974853516) 105.31745147705078\n",
            "(106.45060729980469, 105.62959289550781) (80.14044952392578, 93.6435775756836) 89.54179382324219\n",
            "(119.1364974975586, 114.68722534179688) (101.14535522460938, 141.36279296875) 73.73147583007812\n",
            "(103.71920776367188, 140.34860229492188) (115.97938537597656, 136.91714477539062) 93.3187026977539\n",
            "(116.949462890625, 105.79727935791016) (96.7588119506836, 158.65208435058594) 101.73738098144531\n",
            "(115.84144592285156, 117.7967300415039) (131.79815673828125, 150.23377990722656) 94.90065002441406\n",
            "(88.70630645751953, 110.2896728515625) (106.37444305419922, 150.55722045898438) 76.95462799072266\n",
            "(107.69352722167969, 120.65190124511719) (119.18285369873047, 150.8726348876953) 101.12791442871094\n",
            "(102.41680908203125, 111.85614776611328) (69.77677917480469, 96.95928192138672) 99.28253173828125\n",
            "(114.04910278320312, 139.7692413330078) (123.19400024414062, 143.07691955566406) 89.37586975097656\n",
            "(88.98233795166016, 118.97689819335938) (130.9999237060547, 154.454345703125) 67.47756958007812\n",
            "(124.4466323852539, 94.50548553466797) (76.98393249511719, 120.59176635742188) 81.71772766113281\n",
            "(104.68785858154297, 89.36567687988281) (112.66717529296875, 140.1609649658203) 86.86177062988281\n",
            "(97.83612823486328, 131.22265625) (114.48603820800781, 145.9256134033203) 81.7651138305664\n",
            "(142.32215881347656, 115.05398559570312) (78.37023162841797, 85.84159088134766) 61.52484130859375\n",
            "(106.46227264404297, 100.9468002319336) (120.46862030029297, 144.51931762695312) 83.83856964111328\n",
            "(103.7784194946289, 108.612060546875) (125.4554672241211, 142.45901489257812) 75.68002319335938\n",
            "(107.43624114990234, 102.99090576171875) (99.20167541503906, 170.560791015625) 88.72708892822266\n",
            "(119.53697967529297, 112.0863037109375) (56.08429718017578, 116.54682159423828) 100.71620178222656\n",
            "(121.17378997802734, 128.95217895507812) (115.8482666015625, 142.71578979492188) 93.22693634033203\n",
            "(101.6133804321289, 129.12457275390625) (119.99593353271484, 139.39202880859375) 98.79061126708984\n",
            "(109.27265167236328, 97.81230163574219) (108.91680145263672, 162.79757690429688) 82.95014953613281\n",
            "(108.10723876953125, 97.6861801147461) (107.03545379638672, 126.2557601928711) 83.8519287109375\n",
            "(121.10977935791016, 119.05764770507812) (115.15962982177734, 140.54115295410156) 90.82906341552734\n",
            "(103.98544311523438, 85.91728210449219) (89.60956573486328, 130.17393493652344) 100.8740463256836\n",
            "(119.23834991455078, 75.98956298828125) (48.887725830078125, 81.68228149414062) 84.19489288330078\n",
            "(100.1347885131836, 110.10108947753906) (93.09187316894531, 151.6132049560547) 93.26374816894531\n",
            "(118.32392883300781, 113.18943786621094) (139.2003631591797, 174.5956573486328) 81.71625518798828\n",
            "(113.86034393310547, 102.5118637084961) (132.0838623046875, 156.7518310546875) 87.93121337890625\n",
            "(92.95053100585938, 108.3412857055664) (107.56049346923828, 130.0136260986328) 79.0053939819336\n",
            "(106.45987701416016, 111.11425018310547) (128.3717041015625, 155.486328125) 88.51506805419922\n",
            "(102.14115142822266, 98.45008087158203) (90.01002502441406, 109.56896209716797) 93.96023559570312\n",
            "(113.2899169921875, 104.04425811767578) (145.42416381835938, 175.06866455078125) 97.95532989501953\n",
            "(82.67875671386719, 94.97167205810547) (107.7088394165039, 138.36959838867188) 91.0252914428711\n",
            "(106.49455261230469, 116.98139190673828) (101.95819091796875, 123.37775421142578) 89.29207611083984\n",
            "(104.71336364746094, 108.68771362304688) (61.88912582397461, 77.90174102783203) 85.1498794555664\n",
            "(127.76045989990234, 114.7374038696289) (113.20081329345703, 156.0247344970703) 82.75337982177734\n",
            "(136.6443634033203, 94.78365325927734) (61.232994079589844, 90.01725769042969) 76.498046875\n",
            "(113.08485412597656, 98.82485961914062) (129.14012145996094, 145.43812561035156) 96.76892852783203\n",
            "(124.29218292236328, 107.9683609008789) (138.01846313476562, 211.4398651123047) 81.47384643554688\n",
            "(131.9611358642578, 112.99878692626953) (64.24800109863281, 77.32893371582031) 110.15602111816406\n",
            "(125.72714233398438, 108.8612289428711) (80.67147064208984, 100.00839233398438) 73.4264907836914\n",
            "(94.34846496582031, 102.65998840332031) (107.55860900878906, 122.9722900390625) 91.63692474365234\n",
            "(106.15110778808594, 98.44071960449219) (151.96018981933594, 179.8688507080078) 95.43724060058594\n",
            "(117.38469696044922, 104.4996337890625) (160.75588989257812, 185.77462768554688) 80.99067687988281\n",
            "(112.41156768798828, 118.97493743896484) (91.35588073730469, 141.74855041503906) 106.9895248413086\n",
            "(126.75081634521484, 98.79813385009766) (88.7950210571289, 139.51510620117188) 100.91542053222656\n",
            "(102.15872955322266, 115.35308074951172) (72.02244567871094, 99.60205078125) 74.56531524658203\n",
            "(124.83870697021484, 110.72708129882812) (99.75279235839844, 105.06278991699219) 72.77967834472656\n",
            "(97.25241088867188, 109.91864776611328) (131.03868103027344, 153.06141662597656) 91.96255493164062\n",
            "(107.82582092285156, 112.81885528564453) (150.81398010253906, 177.73170471191406) 94.70283508300781\n",
            "(114.26856231689453, 108.05902099609375) (142.44131469726562, 169.75938415527344) 98.68513488769531\n",
            "(108.66077423095703, 127.15992736816406) (78.93793487548828, 101.58635711669922) 84.5176773071289\n",
            "(108.02690124511719, 111.86161804199219) (160.83444213867188, 171.07826232910156) 94.42386627197266\n",
            "(111.8197021484375, 108.69126892089844) (141.30279541015625, 160.46409606933594) 84.81195831298828\n",
            "(111.77592468261719, 108.69818878173828) (141.37139892578125, 160.336181640625) 84.59282684326172\n",
            "(106.53780364990234, 97.94673156738281) (138.30320739746094, 165.47232055664062) 89.12467956542969\n",
            "(119.65018463134766, 114.64900207519531) (127.59356689453125, 141.1593017578125) 111.34246063232422\n",
            "(112.40385437011719, 119.86869812011719) (160.93943786621094, 185.5127410888672) 108.37992095947266\n",
            "(83.0737533569336, 103.67545318603516) (132.30218505859375, 154.0579833984375) 100.1594009399414\n",
            "(134.06358337402344, 124.57427978515625) (110.04551696777344, 123.00724792480469) 90.5704116821289\n",
            "(103.62654113769531, 109.44247436523438) (119.80712890625, 145.7412109375) 96.65233612060547\n",
            "(118.77577209472656, 135.60720825195312) (118.93770599365234, 142.0558624267578) 72.94233703613281\n",
            "(143.70826721191406, 122.64299774169922) (87.95111083984375, 102.7287368774414) 71.4150390625\n",
            "(118.45116424560547, 106.22461700439453) (125.07577514648438, 158.54701232910156) 88.45193481445312\n",
            "(109.19068908691406, 111.18506622314453) (153.42227172851562, 160.38328552246094) 20.35845184326172\n",
            "(107.88842010498047, 106.00923919677734) (136.02728271484375, 158.21688842773438) 84.64398193359375\n",
            "(107.85872650146484, 128.38510131835938) (143.68313598632812, 164.36996459960938) 97.00115966796875\n",
            "(102.4383316040039, 131.25799560546875) (126.7556381225586, 135.78797912597656) 70.36050415039062\n",
            "(107.09727478027344, 100.92477416992188) (101.0101547241211, 120.41061401367188) 96.89630889892578\n",
            "(112.65201568603516, 106.9664535522461) (129.20138549804688, 159.6846923828125) 63.56935119628906\n",
            "(119.35616302490234, 112.63322448730469) (149.28611755371094, 172.7353057861328) 81.33717346191406\n",
            "(104.8566665649414, 93.47148132324219) (148.2802734375, 175.03346252441406) 79.11573791503906\n",
            "(104.03400421142578, 93.66609191894531) (165.77767944335938, 178.55337524414062) 106.19190216064453\n",
            "(122.4756088256836, 107.20921325683594) (135.5818328857422, 164.82687377929688) 92.20214080810547\n",
            "(104.53934478759766, 110.54219055175781) (137.3149871826172, 165.4819793701172) 85.15813446044922\n",
            "(115.95161437988281, 116.16226196289062) (160.07054138183594, 175.2866668701172) 81.89344787597656\n",
            "(108.39447784423828, 113.25010681152344) (113.66412353515625, 130.8976593017578) 94.17993927001953\n",
            "(142.46511840820312, 111.48844909667969) (85.50123596191406, 96.05130767822266) 93.66680145263672\n",
            "(96.91035461425781, 106.31037902832031) (141.3751220703125, 158.69444274902344) 89.02900695800781\n",
            "(102.59326171875, 120.46366882324219) (129.1460418701172, 146.63856506347656) 88.69332122802734\n",
            "(112.08889770507812, 117.51223754882812) (148.2333221435547, 150.48797607421875) 7.091928482055664\n",
            "(108.20742797851562, 109.44942474365234) (139.63194274902344, 157.97666931152344) 74.65771484375\n",
            "(108.27375793457031, 109.5045166015625) (139.8172607421875, 158.0121612548828) 74.95358276367188\n",
            "(99.03569030761719, 101.0654067993164) (131.40927124023438, 166.50567626953125) 81.38563537597656\n",
            "(101.39559936523438, 116.5410385131836) (172.18658447265625, 189.0252227783203) 100.05592346191406\n",
            "(129.57449340820312, 103.0153579711914) (106.82586669921875, 135.32577514648438) 85.89594268798828\n",
            "(108.44469451904297, 108.33621978759766) (129.1531524658203, 167.9552001953125) 87.54180908203125\n",
            "(115.9532699584961, 102.99779510498047) (140.0210723876953, 153.82412719726562) 91.98130798339844\n",
            "(120.26194763183594, 111.49813079833984) (151.31224060058594, 170.62161254882812) 106.96066284179688\n",
            "(118.79912567138672, 112.7808609008789) (154.84788513183594, 166.7989044189453) 93.58179473876953\n",
            "(122.02959442138672, 115.14926147460938) (126.59310150146484, 153.91725158691406) 82.0970687866211\n",
            "(104.7983627319336, 117.84153747558594) (140.8889617919922, 163.2157745361328) 84.1255111694336\n",
            "(109.81848907470703, 101.13095092773438) (131.42835998535156, 170.05996704101562) 81.3372573852539\n",
            "(109.15876770019531, 116.00527954101562) (121.44229125976562, 146.1560821533203) 87.15054321289062\n",
            "(112.57946014404297, 118.7423095703125) (141.4587860107422, 152.27218627929688) 80.10753631591797\n",
            "(116.43753814697266, 108.5097427368164) (106.32101440429688, 116.5846939086914) 99.01700592041016\n",
            "(111.3494644165039, 106.93206787109375) (180.20066833496094, 184.4328155517578) 93.23672485351562\n",
            "(111.57258605957031, 110.51099395751953) (174.32330322265625, 188.88885498046875) 126.50220489501953\n",
            "(112.67694854736328, 120.54338836669922) (162.7922821044922, 186.4904327392578) 89.02445983886719\n",
            "(106.37252044677734, 111.93848419189453) (156.25245666503906, 165.1157989501953) 94.64122772216797\n",
            "(113.7401123046875, 119.50303649902344) (89.05003356933594, 108.46965789794922) 91.97721099853516\n",
            "(133.9872283935547, 126.37995147705078) (77.34159088134766, 83.80927276611328) 66.44762420654297\n",
            "(115.78167724609375, 113.02666473388672) (124.27176666259766, 146.6891326904297) 86.83438873291016\n",
            "(117.74930572509766, 117.16118621826172) (126.04865264892578, 146.14833068847656) 94.54520416259766\n",
            "(109.02472686767578, 109.61714172363281) (120.61310577392578, 143.5939483642578) 88.99718475341797\n",
            "(118.74212646484375, 113.5506820678711) (140.77244567871094, 159.0336456298828) 84.05316162109375\n",
            "(107.14376068115234, 112.56076049804688) (128.04835510253906, 160.8223114013672) 78.33413696289062\n",
            "(121.02996063232422, 108.48027038574219) (138.6663818359375, 166.90625) 103.59272003173828\n",
            "(85.8265151977539, 112.92381286621094) (95.26245880126953, 118.71784210205078) 90.85083770751953\n",
            "(110.23631286621094, 115.42339324951172) (157.9949951171875, 183.16973876953125) 97.35572814941406\n",
            "(114.84998321533203, 127.89326477050781) (127.81663513183594, 151.6198272705078) 110.101318359375\n",
            "(121.95414733886719, 112.12141418457031) (122.0179443359375, 133.10531616210938) 95.55077362060547\n",
            "(99.5496826171875, 75.1870346069336) (110.67692565917969, 133.60154724121094) 89.96979522705078\n",
            "(117.3407974243164, 96.68351745605469) (119.36344146728516, 163.01148986816406) 73.15521240234375\n",
            "(132.43411254882812, 91.82041931152344) (81.44445037841797, 125.2308578491211) 81.27912139892578\n",
            "(132.44552612304688, 91.86502838134766) (81.56732177734375, 125.18563842773438) 81.28214263916016\n",
            "(89.70829772949219, 108.75495147705078) (114.07921600341797, 147.4305877685547) 81.14632415771484\n",
            "(94.1588363647461, 113.69564819335938) (159.75997924804688, 165.08822631835938) 94.96446228027344\n",
            "(117.91260528564453, 119.80609130859375) (157.7352752685547, 167.95941162109375) 83.51823425292969\n",
            "(109.66185760498047, 110.11420440673828) (160.43728637695312, 167.27198791503906) 40.82448196411133\n",
            "(92.47433471679688, 104.6488037109375) (105.09564971923828, 119.6900405883789) 87.82980346679688\n",
            "(103.0016860961914, 103.99507904052734) (145.97811889648438, 172.22369384765625) 96.1978759765625\n",
            "(119.10768127441406, 118.90748596191406) (154.7122039794922, 186.21331787109375) 92.55152130126953\n",
            "(112.0598373413086, 107.1699447631836) (156.54310607910156, 184.85324096679688) 91.51000213623047\n",
            "(108.37081146240234, 113.70609283447266) (102.88994598388672, 130.17672729492188) 71.82244873046875\n",
            "(108.9892349243164, 114.1799087524414) (145.902099609375, 165.52725219726562) 86.2659683227539\n",
            "(126.22769927978516, 125.03828430175781) (131.37783813476562, 167.5375518798828) 77.50956726074219\n",
            "(120.7217025756836, 113.67514038085938) (148.087646484375, 160.57101440429688) 97.32809448242188\n",
            "(109.97830200195312, 104.67546844482422) (129.79345703125, 161.35125732421875) 84.85877990722656\n",
            "(115.31260681152344, 109.42284393310547) (142.50405883789062, 160.1962432861328) 93.75381469726562\n",
            "(113.60616302490234, 120.2529525756836) (140.1880340576172, 163.71487426757812) 88.3736801147461\n",
            "(129.4591064453125, 101.77214813232422) (114.2320785522461, 132.11094665527344) 88.64861297607422\n",
            "(76.4295654296875, 115.16001892089844) (113.69541931152344, 146.79360961914062) 97.13619232177734\n",
            "(114.15026092529297, 105.99321746826172) (154.07565307617188, 165.38719177246094) 94.83021545410156\n",
            "(108.95765686035156, 117.4430923461914) (144.8935546875, 151.29710388183594) 88.26809692382812\n",
            "(131.6011505126953, 96.88316345214844) (144.66281127929688, 158.0133056640625) 92.97476959228516\n",
            "(123.81915283203125, 107.97067260742188) (135.2062530517578, 163.60008239746094) 90.67350769042969\n",
            "(104.71449279785156, 109.85832977294922) (168.77000427246094, 191.3561248779297) 84.24784851074219\n",
            "(118.6504898071289, 105.67899322509766) (141.6438751220703, 171.24954223632812) 95.49833679199219\n",
            "(115.10047912597656, 107.69050598144531) (153.40853881835938, 178.75155639648438) 83.89685821533203\n",
            "(110.31107330322266, 110.85625457763672) (152.72296142578125, 185.61671447753906) 87.87610626220703\n",
            "(131.39488220214844, 112.15242767333984) (136.3385772705078, 154.56719970703125) 96.45710754394531\n",
            "(78.90385437011719, 115.45353698730469) (116.5417709350586, 141.444580078125) 90.80529022216797\n",
            "(102.47880554199219, 110.64119720458984) (154.2536163330078, 182.35055541992188) 80.94844818115234\n",
            "(113.2349853515625, 102.29364776611328) (130.52288818359375, 157.60679626464844) 94.6236572265625\n",
            "(123.66722106933594, 124.115966796875) (110.76423645019531, 130.74713134765625) 81.23686981201172\n",
            "(101.84564971923828, 103.76469421386719) (123.0826416015625, 147.23471069335938) 85.79943084716797\n",
            "(109.57693481445312, 109.85028076171875) (129.28089904785156, 144.07022094726562) 87.77045440673828\n",
            "(123.28315734863281, 108.53304290771484) (107.37150573730469, 135.78073120117188) 101.28958892822266\n",
            "(90.71417236328125, 104.24050903320312) (106.18588256835938, 135.82798767089844) 77.37922668457031\n",
            "(125.62355041503906, 98.23251342773438) (126.93848419189453, 155.39016723632812) 88.02845764160156\n",
            "(112.71827697753906, 118.79847717285156) (143.40274047851562, 155.34127807617188) 91.4949951171875\n",
            "(113.12740325927734, 127.4203109741211) (147.28475952148438, 156.26055908203125) 68.07194519042969\n",
            "(95.3480453491211, 93.20829772949219) (137.99473571777344, 153.119384765625) 79.37792205810547\n",
            "(101.12380981445312, 93.6786880493164) (119.42459869384766, 147.86297607421875) 96.19281768798828\n",
            "(106.64566040039062, 101.45833587646484) (134.88099670410156, 159.1552276611328) 88.16898345947266\n",
            "(103.48615264892578, 107.1168212890625) (154.9444580078125, 169.3424072265625) 91.23330688476562\n",
            "(115.22314453125, 106.8865966796875) (166.89132690429688, 179.20956420898438) 106.49727630615234\n",
            "(99.5337142944336, 108.6259765625) (150.09217834472656, 183.84783935546875) 80.17737579345703\n",
            "(131.74916076660156, 110.9494400024414) (121.4188003540039, 149.14405822753906) 61.23615646362305\n",
            "(148.16555786132812, 94.99687194824219) (65.51504516601562, 97.49371337890625) 102.2062759399414\n",
            "(123.05533599853516, 105.92284393310547) (152.71417236328125, 185.56385803222656) 83.34937286376953\n",
            "(105.29532623291016, 121.87740325927734) (116.5252456665039, 161.47225952148438) 66.13685607910156\n",
            "(108.88109588623047, 119.61878204345703) (160.75157165527344, 188.87118530273438) 93.01866912841797\n",
            "(102.90316772460938, 125.9053955078125) (113.73357391357422, 138.00521850585938) 91.45330047607422\n",
            "(105.44296264648438, 110.70878601074219) (131.4432830810547, 160.56649780273438) 104.7194595336914\n",
            "(118.06884002685547, 117.17306518554688) (121.0467529296875, 141.84158325195312) 83.63905334472656\n",
            "(105.86210632324219, 131.4031524658203) (115.28362274169922, 133.79925537109375) 109.04452514648438\n",
            "(114.66563415527344, 94.36234283447266) (140.4737091064453, 160.68157958984375) 97.84700012207031\n",
            "(99.32717895507812, 103.14807891845703) (155.99334716796875, 161.31947326660156) 106.0635757446289\n",
            "(113.05020141601562, 119.37370300292969) (166.78590393066406, 190.01417541503906) 111.49104309082031\n",
            "(100.89913940429688, 117.1563720703125) (156.69854736328125, 183.54495239257812) 87.84526824951172\n",
            "(106.9939193725586, 117.6688003540039) (134.42445373535156, 155.5811004638672) 84.19152069091797\n",
            "(108.76436614990234, 112.8001480102539) (123.25027465820312, 142.87335205078125) 94.21710968017578\n",
            "(88.07861328125, 109.74606323242188) (115.62063598632812, 126.56177520751953) 84.59749603271484\n",
            "(108.10468292236328, 100.08647918701172) (156.3111572265625, 189.7091522216797) 89.0668716430664\n",
            "(113.43447875976562, 114.8833236694336) (154.63125610351562, 196.34800720214844) 85.00667572021484\n",
            "(126.02445220947266, 117.6044921875) (132.13169860839844, 137.98971557617188) 61.687828063964844\n",
            "(108.00020599365234, 111.0450210571289) (112.2803726196289, 136.92849731445312) 74.74610900878906\n",
            "(118.97642517089844, 127.8174057006836) (108.05923461914062, 134.86434936523438) 100.6746826171875\n",
            "(113.93704223632812, 120.05327606201172) (110.67413330078125, 139.76751708984375) 114.26495361328125\n",
            "(132.0706024169922, 116.0969467163086) (123.31922912597656, 150.26473999023438) 110.56287384033203\n",
            "(109.92329406738281, 104.06999206542969) (156.6180877685547, 169.4503936767578) 102.96739959716797\n",
            "(126.05110931396484, 107.5658950805664) (112.05403900146484, 136.66583251953125) 81.86534881591797\n",
            "(109.8580093383789, 115.74984741210938) (119.82611846923828, 140.52023315429688) 94.78507995605469\n",
            "(108.01093292236328, 114.45858001708984) (143.74623107910156, 166.2583770751953) 107.31621551513672\n",
            "(113.6745376586914, 129.1745147705078) (140.22195434570312, 159.2508544921875) 90.74781036376953\n",
            "(122.74189758300781, 114.80036926269531) (134.56138610839844, 146.8923797607422) 90.2617416381836\n",
            "(140.0100555419922, 127.36297607421875) (115.78297424316406, 142.5272216796875) 74.47396087646484\n",
            "(98.50080871582031, 95.46196746826172) (138.41587829589844, 164.0318145751953) 85.07227325439453\n",
            "(106.40865325927734, 122.61748504638672) (150.45947265625, 181.91030883789062) 99.73623657226562\n",
            "(103.6663818359375, 110.89183044433594) (149.7428741455078, 169.2408447265625) 98.846923828125\n",
            "(107.94408416748047, 115.09660339355469) (137.47286987304688, 165.4444580078125) 94.60173797607422\n",
            "(119.84123229980469, 116.8612289428711) (116.92936706542969, 139.03118896484375) 73.1951675415039\n",
            "(105.03271484375, 84.57080841064453) (135.5400390625, 148.2760772705078) 64.05109405517578\n",
            "(98.60404205322266, 102.79369354248047) (134.86000061035156, 149.943115234375) 122.09630584716797\n",
            "(127.5449447631836, 105.81739807128906) (142.64247131347656, 167.18804931640625) 91.20308685302734\n",
            "(110.21930694580078, 83.89139556884766) (130.92120361328125, 153.85946655273438) 96.19451141357422\n",
            "(112.82794952392578, 126.92277526855469) (92.7848892211914, 110.37840270996094) 97.50882720947266\n",
            "(108.38675689697266, 128.66082763671875) (83.38921356201172, 104.23744201660156) 104.4534683227539\n",
            "(118.85305786132812, 77.17765045166016) (127.19176483154297, 167.96104431152344) 80.65411376953125\n",
            "(117.19058990478516, 116.57893371582031) (159.35630798339844, 174.91331481933594) 93.28544616699219\n",
            "(110.53955841064453, 104.4303207397461) (154.1925506591797, 178.85479736328125) 90.7344970703125\n",
            "(114.45746612548828, 113.66117858886719) (120.3964614868164, 142.4830780029297) 102.11747741699219\n",
            "(106.57032775878906, 95.34736633300781) (155.52220153808594, 180.9121551513672) 87.92138671875\n",
            "(94.7721939086914, 104.67173767089844) (161.20571899414062, 178.67526245117188) 92.95779418945312\n",
            "(95.63825988769531, 115.00972747802734) (117.53524017333984, 141.58255004882812) 90.98477935791016\n",
            "(101.004638671875, 119.40515899658203) (148.72488403320312, 167.15826416015625) 87.2113037109375\n",
            "(100.03195190429688, 107.02708435058594) (168.17135620117188, 189.20469665527344) 85.51351928710938\n",
            "(121.64263916015625, 100.90469360351562) (121.75212860107422, 143.37754821777344) 86.86233520507812\n",
            "(111.42407989501953, 111.44232177734375) (162.2488555908203, 178.986572265625) 86.38664245605469\n",
            "(119.9176025390625, 93.85646057128906) (127.91204833984375, 140.3135986328125) 106.3429946899414\n",
            "(113.8980941772461, 114.78910827636719) (180.23516845703125, 189.4878387451172) 99.09236145019531\n",
            "(104.3648910522461, 115.18209838867188) (173.49322509765625, 192.3763427734375) 108.4423828125\n",
            "(121.61673736572266, 109.68409729003906) (161.0720977783203, 175.83285522460938) 83.28111267089844\n",
            "(126.28301239013672, 121.98023986816406) (123.01546478271484, 167.1272430419922) 99.81547546386719\n",
            "(110.65288543701172, 108.43402099609375) (125.49970245361328, 150.58920288085938) 80.56179809570312\n",
            "(113.27462768554688, 112.89157104492188) (124.25392150878906, 142.09356689453125) 83.6329574584961\n",
            "(100.17304992675781, 127.32418823242188) (139.653076171875, 153.40536499023438) 94.72698211669922\n",
            "(101.55060577392578, 114.32789611816406) (158.41339111328125, 176.23475646972656) 97.04402160644531\n",
            "(100.54789733886719, 92.02286529541016) (118.17488861083984, 138.80325317382812) 98.55679321289062\n",
            "(100.26580810546875, 117.16886138916016) (143.71627807617188, 159.4788818359375) 64.43378448486328\n",
            "(103.86308288574219, 105.48259735107422) (149.23179626464844, 161.57980346679688) 103.58161926269531\n",
            "(119.74420166015625, 130.7460479736328) (143.46856689453125, 171.32147216796875) 82.97172546386719\n",
            "(128.3546905517578, 110.36410522460938) (115.76412200927734, 138.21258544921875) 102.18577575683594\n",
            "(114.90866088867188, 107.73993682861328) (152.70053100585938, 171.82794189453125) 81.29338836669922\n",
            "(84.32666778564453, 89.01774597167969) (121.38245391845703, 160.10926818847656) 69.99822235107422\n",
            "(99.48735046386719, 131.1085662841797) (131.2852020263672, 150.50608825683594) 101.88949584960938\n",
            "(113.70001220703125, 125.01362609863281) (127.37104797363281, 148.6881866455078) 84.38270568847656\n",
            "(110.98560333251953, 112.50413513183594) (136.55419921875, 161.38877868652344) 91.24905395507812\n",
            "(103.97506713867188, 96.12812042236328) (147.84799194335938, 159.06149291992188) 79.36746215820312\n",
            "(94.8526840209961, 97.01044464111328) (136.6249237060547, 161.3659210205078) 95.31282043457031\n",
            "(91.18146514892578, 105.1710433959961) (158.68817138671875, 171.63075256347656) 94.96864318847656\n",
            "(98.88406372070312, 110.37946319580078) (129.2718505859375, 135.3482208251953) 131.2313232421875\n",
            "(90.72847747802734, 97.11568450927734) (163.9447021484375, 185.44970703125) 101.02681732177734\n",
            "(106.56122589111328, 95.3051528930664) (150.45785522460938, 168.97723388671875) 99.7685546875\n",
            "(116.2733383178711, 116.49555969238281) (183.14743041992188, 192.81332397460938) 104.94983673095703\n",
            "(114.06658935546875, 77.59591674804688) (117.09268951416016, 134.00051879882812) 83.8509750366211\n",
            "(108.4899673461914, 109.10446166992188) (142.94900512695312, 167.5045928955078) 92.31548309326172\n",
            "(119.07063293457031, 106.88751983642578) (118.68804168701172, 138.8439178466797) 82.38139343261719\n",
            "(128.04225158691406, 103.62731170654297) (152.63931274414062, 190.62826538085938) 76.32072448730469\n",
            "(112.30146789550781, 112.69210815429688) (154.0618133544922, 181.95558166503906) 94.7918701171875\n",
            "(117.16213989257812, 115.06047058105469) (122.00605773925781, 147.69625854492188) 97.2245101928711\n",
            "(121.2760238647461, 111.30659484863281) (150.37779235839844, 165.6699981689453) 77.97710418701172\n",
            "(98.36453247070312, 113.15191650390625) (109.86749267578125, 135.81967163085938) 102.5801010131836\n",
            "(123.94659423828125, 109.40370178222656) (117.17976379394531, 144.69515991210938) 87.16934204101562\n",
            "(116.42206573486328, 116.59428405761719) (143.54653930664062, 152.55921936035156) 94.2048568725586\n",
            "(109.48770904541016, 126.67713928222656) (122.77356719970703, 148.1186981201172) 80.11834716796875\n",
            "(118.59297180175781, 111.67414855957031) (149.81527709960938, 174.39414978027344) 92.2684326171875\n",
            "(120.7978515625, 107.62469482421875) (141.1600341796875, 161.53128051757812) 87.95690155029297\n",
            "(119.58673858642578, 103.65177917480469) (143.5834503173828, 170.18431091308594) 81.68704986572266\n",
            "(116.72917938232422, 70.30948638916016) (104.6410903930664, 138.7240753173828) 110.34207153320312\n",
            "(113.5503921508789, 101.36390686035156) (98.72985076904297, 140.09744262695312) 109.06172180175781\n",
            "(132.82984924316406, 115.20774841308594) (108.25342559814453, 125.59947204589844) 93.06209564208984\n",
            "(97.3828353881836, 108.09493255615234) (152.01344299316406, 175.46051025390625) 91.19690704345703\n",
            "(104.22978210449219, 103.32919311523438) (140.05589294433594, 160.9318389892578) 88.36412048339844\n",
            "(113.17376708984375, 111.68304443359375) (125.45074462890625, 139.78851318359375) 90.37757110595703\n",
            "(112.95684051513672, 89.63422393798828) (140.2556915283203, 152.1059112548828) 83.58370208740234\n",
            "(119.23284912109375, 107.1285171508789) (119.66763305664062, 137.8157196044922) 89.43601989746094\n",
            "(124.8930435180664, 110.8246078491211) (135.03163146972656, 147.19967651367188) 89.98455047607422\n",
            "(117.04861450195312, 107.98709106445312) (122.413818359375, 146.5205535888672) 95.4481430053711\n",
            "(87.46105194091797, 96.08091735839844) (116.12857818603516, 135.69354248046875) 47.64117431640625\n",
            "(111.30043029785156, 89.66094207763672) (127.87305450439453, 162.38536071777344) 95.43879699707031\n",
            "(117.84556579589844, 139.02423095703125) (127.9524917602539, 149.2521514892578) 82.04047393798828\n",
            "(112.1207504272461, 111.54942321777344) (128.1575164794922, 143.57763671875) 90.75201416015625\n",
            "(109.57489776611328, 106.18971252441406) (124.69479370117188, 147.2193145751953) 87.47972106933594\n",
            "(112.73646545410156, 114.74207305908203) (123.27700805664062, 149.49317932128906) 95.07376861572266\n",
            "(121.60718536376953, 110.65534210205078) (120.9906005859375, 145.48056030273438) 85.39347839355469\n",
            "(118.53120422363281, 106.21722412109375) (132.6962890625, 159.03074645996094) 98.01128387451172\n",
            "(102.89891052246094, 120.4688491821289) (124.37528228759766, 148.78436279296875) 94.66205596923828\n",
            "(125.86894989013672, 110.23762512207031) (110.2708511352539, 120.03065490722656) 80.30219268798828\n",
            "(108.02931213378906, 102.72937774658203) (159.94285583496094, 183.86949157714844) 88.86772155761719\n",
            "(118.99591064453125, 116.30036163330078) (163.40960693359375, 170.40516662597656) 88.31014251708984\n",
            "(118.43292236328125, 119.56682586669922) (151.1851348876953, 175.90643310546875) 93.21090698242188\n",
            "(113.61622619628906, 109.36217498779297) (138.06982421875, 160.57106018066406) 98.67420959472656\n",
            "(125.12245178222656, 78.50779724121094) (118.9051742553711, 137.5894775390625) 89.1662826538086\n",
            "(112.64630889892578, 108.53565979003906) (123.61260223388672, 137.49281311035156) 93.49755859375\n",
            "(102.65495300292969, 112.87944030761719) (145.49444580078125, 171.4892120361328) 112.81725311279297\n",
            "(120.63089752197266, 115.09971618652344) (147.1770782470703, 171.067626953125) 106.67742919921875\n",
            "(92.17759704589844, 102.78192138671875) (108.44506072998047, 156.41671752929688) 77.389404296875\n",
            "(99.76618957519531, 99.27332305908203) (135.7630615234375, 144.4904327392578) 86.07569885253906\n",
            "(94.38108825683594, 91.37802124023438) (140.6823272705078, 148.39952087402344) 113.84297180175781\n",
            "(108.87911987304688, 106.72222137451172) (125.43804931640625, 153.24249267578125) 90.13361358642578\n",
            "(95.23641967773438, 91.43382263183594) (127.87374114990234, 150.54736328125) 81.9757080078125\n",
            "(113.60104370117188, 119.6441879272461) (159.18988037109375, 184.93988037109375) 97.02748107910156\n",
            "(131.83091735839844, 106.3843994140625) (94.21002960205078, 101.05237579345703) 107.9098892211914\n",
            "(123.84960174560547, 121.27586364746094) (162.39768981933594, 185.9183807373047) 78.82251739501953\n",
            "(115.86091613769531, 112.31051635742188) (141.45082092285156, 168.9856719970703) 89.88949584960938\n",
            "(112.3354263305664, 110.41690063476562) (124.78167724609375, 144.7167205810547) 92.70011138916016\n",
            "(103.39925384521484, 98.05850219726562) (115.04054260253906, 145.20108032226562) 101.91291809082031\n",
            "(103.37952423095703, 98.04918670654297) (115.06364440917969, 145.11143493652344) 101.90030670166016\n",
            "(103.39925384521484, 98.05850219726562) (115.04054260253906, 145.20108032226562) 101.91291809082031\n",
            "(114.21114349365234, 109.04169464111328) (166.10321044921875, 195.65638732910156) 88.55702209472656\n",
            "(101.33226013183594, 124.19569396972656) (150.14202880859375, 189.28097534179688) 92.86811065673828\n",
            "(90.98686981201172, 93.29317474365234) (147.19947814941406, 178.03314208984375) 79.43663024902344\n",
            "(106.15576934814453, 107.28643035888672) (167.1332244873047, 189.68907165527344) 89.12755584716797\n",
            "(138.00164794921875, 87.81603240966797) (100.93301391601562, 122.51437377929688) 79.76968383789062\n",
            "(111.86500549316406, 83.45228576660156) (146.972412109375, 168.58432006835938) 73.01577758789062\n",
            "(112.26944732666016, 109.68464660644531) (115.7459716796875, 144.76168823242188) 84.69972229003906\n",
            "(107.42010498046875, 108.11349487304688) (133.62744140625, 164.08779907226562) 84.50001525878906\n",
            "(111.96453857421875, 115.51747131347656) (119.11709594726562, 152.83001708984375) 93.27978515625\n",
            "(102.92376708984375, 100.55216217041016) (134.0074005126953, 154.10855102539062) 90.65453338623047\n",
            "(112.01459503173828, 103.36233520507812) (137.2807159423828, 177.75216674804688) 104.19009399414062\n",
            "(122.22193145751953, 115.59976196289062) (137.73687744140625, 155.58770751953125) 79.35075378417969\n",
            "(94.30252075195312, 115.52931213378906) (129.1116485595703, 155.32015991210938) 95.94514465332031\n",
            "(122.29644012451172, 100.41934204101562) (129.19015502929688, 155.12094116210938) 91.0440673828125\n",
            "(109.17025756835938, 99.89163208007812) (136.10276794433594, 159.49656677246094) 76.9603042602539\n",
            "(110.88667297363281, 106.19229888916016) (79.89458465576172, 92.6755599975586) 81.19874572753906\n",
            "(111.19815063476562, 128.7028045654297) (101.90760040283203, 115.0632095336914) 96.69950103759766\n",
            "(137.96397399902344, 102.59455871582031) (123.6485824584961, 147.62139892578125) 79.44619750976562\n",
            "(118.5204849243164, 104.32931518554688) (152.00936889648438, 177.33621215820312) 95.39534759521484\n",
            "(114.04647827148438, 120.94046020507812) (165.9067840576172, 193.14031982421875) 114.83354187011719\n",
            "(117.00364685058594, 102.63910675048828) (161.32345581054688, 178.5048370361328) 76.73604583740234\n",
            "(117.00729370117188, 111.2584457397461) (130.72515869140625, 144.9060821533203) 90.31101989746094\n",
            "(84.39185333251953, 106.07785034179688) (114.050537109375, 132.82354736328125) 93.19525146484375\n",
            "(110.65727233886719, 121.07528686523438) (160.16055297851562, 193.6340789794922) 95.47343444824219\n",
            "(106.24189758300781, 117.59646606445312) (141.69354248046875, 166.15847778320312) 88.35004425048828\n",
            "(112.35133361816406, 98.08277130126953) (150.74490356445312, 171.75991821289062) 101.36846923828125\n",
            "(104.81450653076172, 115.54806518554688) (118.87870025634766, 145.87118530273438) 88.69126892089844\n",
            "(109.6035385131836, 108.76302337646484) (120.33193969726562, 149.3461456298828) 89.0597915649414\n",
            "(116.08934783935547, 103.1248550415039) (140.40765380859375, 147.80946350097656) 110.7672119140625\n",
            "(116.22122192382812, 121.65428924560547) (138.54513549804688, 156.82127380371094) 86.41082763671875\n",
            "(120.48906707763672, 85.56045532226562) (128.3517608642578, 150.09014892578125) 85.92049407958984\n",
            "(104.00477600097656, 90.88648986816406) (113.94352722167969, 147.34054565429688) 84.04512786865234\n",
            "(121.62615203857422, 100.46985626220703) (148.71859741210938, 168.10623168945312) 96.41455078125\n",
            "(123.00115203857422, 103.1904067993164) (149.69081115722656, 172.88340759277344) 90.79438018798828\n",
            "(93.07455444335938, 115.26466369628906) (134.19715881347656, 154.61972045898438) 88.5508041381836\n",
            "(119.28751373291016, 101.26576232910156) (148.5364990234375, 182.47799682617188) 76.67958068847656\n",
            "(91.20540618896484, 134.0417022705078) (122.47429656982422, 148.6667022705078) 104.91512298583984\n",
            "(106.24156951904297, 104.94235229492188) (137.15541076660156, 161.0708465576172) 96.16888427734375\n",
            "(106.89665985107422, 113.4433822631836) (137.4908905029297, 160.88546752929688) 91.94915008544922\n",
            "(119.8017349243164, 122.57980346679688) (135.94349670410156, 164.4871063232422) 80.84339141845703\n",
            "(116.704345703125, 107.66053771972656) (143.06593322753906, 160.83346557617188) 87.4289321899414\n",
            "(132.52880859375, 91.00830078125) (121.42772674560547, 145.38966369628906) 73.25652313232422\n",
            "(126.00057983398438, 108.48719787597656) (140.99871826171875, 166.94798278808594) 87.7238540649414\n",
            "(114.78755187988281, 115.78103637695312) (158.0835723876953, 185.78738403320312) 88.49637603759766\n",
            "(122.42694854736328, 121.84774780273438) (156.1344451904297, 173.24794006347656) 77.46060943603516\n",
            "(104.853759765625, 116.2484359741211) (134.68539428710938, 159.69444274902344) 93.3724594116211\n",
            "(119.98587036132812, 109.02645874023438) (147.60043334960938, 158.65052795410156) 98.80609893798828\n",
            "(113.61585998535156, 120.52310943603516) (155.17697143554688, 164.5115203857422) 80.31857299804688\n",
            "(119.19122314453125, 112.24683380126953) (154.1673583984375, 169.96270751953125) 100.02056121826172\n",
            "(114.53821563720703, 102.58078002929688) (153.11192321777344, 171.52828979492188) 90.60189056396484\n",
            "(119.90426635742188, 106.02112579345703) (91.28602600097656, 104.84971618652344) 88.82670593261719\n",
            "(104.69866943359375, 128.424560546875) (145.2122802734375, 186.06927490234375) 106.20702362060547\n",
            "(106.29045104980469, 123.95446014404297) (145.05088806152344, 185.32107543945312) 103.46180725097656\n",
            "(97.74749755859375, 117.31170654296875) (123.34545135498047, 155.0592041015625) 101.37720489501953\n",
            "(119.20215606689453, 107.50796508789062) (171.55906677246094, 189.73126220703125) 101.76810455322266\n",
            "(111.36727905273438, 87.84397888183594) (125.48294830322266, 153.91976928710938) 90.28987884521484\n",
            "(116.75247192382812, 100.1667251586914) (163.37728881835938, 177.4729461669922) 96.64550018310547\n",
            "(107.98761749267578, 115.2940902709961) (130.90101623535156, 148.99256896972656) 78.64057922363281\n",
            "(102.95911407470703, 115.61921691894531) (136.24754333496094, 152.76173400878906) 107.20319366455078\n",
            "(92.73506164550781, 109.93717956542969) (83.2413101196289, 102.28959655761719) 93.39823150634766\n",
            "(79.42587280273438, 124.04280090332031) (74.82804107666016, 112.53604125976562) 77.49246978759766\n",
            "(122.85151672363281, 119.58606719970703) (152.71926879882812, 165.2710418701172) 104.27670288085938\n",
            "(117.87612915039062, 108.66333770751953) (138.10841369628906, 159.7478790283203) 83.81393432617188\n",
            "(114.4873275756836, 121.96351623535156) (111.50668334960938, 122.82269287109375) 94.93287658691406\n",
            "(111.3272476196289, 108.94070434570312) (128.9705047607422, 158.06243896484375) 89.88350677490234\n",
            "(117.97071075439453, 100.37625122070312) (129.2906951904297, 151.40553283691406) 92.15736389160156\n",
            "(111.5396499633789, 112.98230743408203) (159.89215087890625, 170.82350158691406) 91.99443817138672\n",
            "(122.9628677368164, 113.46147918701172) (147.9777069091797, 161.38414001464844) 96.77741241455078\n",
            "(117.83418273925781, 108.47461700439453) (110.32080841064453, 164.41233825683594) 102.70674133300781\n",
            "(107.9201431274414, 119.83519744873047) (159.20547485351562, 186.6711883544922) 91.51943969726562\n",
            "(97.94052124023438, 113.02741241455078) (119.24555969238281, 141.18797302246094) 93.87683868408203\n",
            "(110.2502670288086, 114.76838684082031) (153.09104919433594, 171.6302032470703) 108.43505859375\n",
            "(117.32316589355469, 106.89942169189453) (121.93946075439453, 135.0675048828125) 85.27272033691406\n",
            "(111.31581115722656, 116.41288757324219) (145.8960418701172, 167.82200622558594) 99.78015899658203\n",
            "(120.1681900024414, 110.99242401123047) (128.68466186523438, 151.38917541503906) 66.8595962524414\n",
            "(123.31842803955078, 113.06004333496094) (160.15716552734375, 165.42724609375) 84.44233703613281\n",
            "(126.41275787353516, 110.14466094970703) (136.71063232421875, 166.66238403320312) 87.63267517089844\n",
            "(120.2361068725586, 105.1243896484375) (130.05099487304688, 142.1689910888672) 97.36222839355469\n",
            "(129.79791259765625, 97.50650024414062) (122.15621185302734, 132.79505920410156) 71.33837890625\n",
            "(94.70586395263672, 117.93400573730469) (100.20893096923828, 123.88964080810547) 87.68484497070312\n",
            "(117.8062515258789, 94.45074462890625) (132.85675048828125, 161.29815673828125) 91.21621704101562\n",
            "(101.02753448486328, 98.60614013671875) (157.5900421142578, 172.88783264160156) 78.2659912109375\n",
            "(109.43126678466797, 92.37390899658203) (127.4033203125, 133.2890625) 91.74542999267578\n",
            "(89.93561553955078, 105.97342681884766) (126.18113708496094, 153.9895782470703) 95.2982406616211\n",
            "(104.99962615966797, 115.32228088378906) (152.06723022460938, 172.87037658691406) 90.11312103271484\n",
            "(104.93529510498047, 109.41910552978516) (146.2678680419922, 183.11367797851562) 82.04642486572266\n",
            "(113.0859146118164, 115.79959869384766) (142.14439392089844, 167.08534240722656) 83.16960144042969\n",
            "(113.53668975830078, 100.81359100341797) (124.2424545288086, 144.54815673828125) 79.6191635131836\n",
            "(115.08348846435547, 113.23139953613281) (144.83810424804688, 163.8152618408203) 94.75112915039062\n",
            "(89.69145202636719, 123.26778411865234) (104.7656478881836, 132.4631805419922) 84.49497985839844\n",
            "(98.37284088134766, 112.69585418701172) (134.1353759765625, 159.02658081054688) 66.2956314086914\n",
            "(100.81222534179688, 140.91360473632812) (88.74606323242188, 94.2304458618164) 80.89198303222656\n",
            "(113.47077941894531, 95.95626831054688) (135.4685821533203, 180.94692993164062) 72.51785278320312\n",
            "(120.13375091552734, 119.76651000976562) (151.50714111328125, 180.86695861816406) 96.13607788085938\n",
            "(107.41883087158203, 75.42880249023438) (121.88581848144531, 156.33180236816406) 73.3691177368164\n",
            "(102.87649536132812, 126.71858215332031) (122.77581024169922, 152.43333435058594) 91.86392211914062\n",
            "(100.93428802490234, 120.39181518554688) (144.7130584716797, 166.0418243408203) 91.4599838256836\n",
            "(132.26834106445312, 112.98078918457031) (129.43798828125, 158.08885192871094) 87.29864501953125\n",
            "(119.80194854736328, 104.2723617553711) (160.9587860107422, 185.56333923339844) 75.6330337524414\n",
            "(114.91622161865234, 114.82156372070312) (123.63672637939453, 138.00599670410156) 80.586181640625\n",
            "(101.00189208984375, 113.00450897216797) (133.2594451904297, 157.79876708984375) 91.70578002929688\n",
            "(110.14767456054688, 103.8548355102539) (125.49248504638672, 148.03651428222656) 97.29446411132812\n",
            "(125.32521057128906, 87.52474212646484) (127.26644897460938, 147.9031219482422) 91.60747528076172\n",
            "(117.94436645507812, 107.37940979003906) (140.76904296875, 176.10240173339844) 87.14790344238281\n",
            "(100.6786880493164, 98.65205383300781) (165.8253631591797, 187.7969512939453) 85.28776550292969\n",
            "(117.18064880371094, 115.4614486694336) (163.5947723388672, 189.07513427734375) 92.83624267578125\n",
            "(113.08875274658203, 102.72645568847656) (152.48675537109375, 178.4270477294922) 96.52799987792969\n",
            "(111.11814880371094, 94.59947204589844) (155.59193420410156, 180.13385009765625) 107.49407958984375\n",
            "(125.27809143066406, 112.54082489013672) (140.6162872314453, 170.59255981445312) 93.87779235839844\n",
            "(111.63919067382812, 109.32718658447266) (144.552734375, 167.60423278808594) 89.96709442138672\n",
            "(107.54197692871094, 97.70442962646484) (125.6598892211914, 148.1897430419922) 81.91210174560547\n",
            "(113.95571899414062, 106.30231475830078) (146.35568237304688, 177.77354431152344) 91.51042938232422\n",
            "(119.4321060180664, 105.62369537353516) (131.12013244628906, 156.10292053222656) 70.68221282958984\n",
            "(121.3487548828125, 107.87538146972656) (138.35629272460938, 155.82562255859375) 88.92562866210938\n",
            "(130.7154541015625, 103.19074249267578) (144.98419189453125, 158.2646484375) 87.85584259033203\n",
            "(112.8740234375, 113.24884033203125) (153.23583984375, 167.23477172851562) 87.01426696777344\n",
            "(112.3659439086914, 132.03575134277344) (152.4690399169922, 177.01556396484375) 87.36788177490234\n",
            "(123.74064636230469, 101.50895690917969) (147.1459503173828, 163.34341430664062) 94.62508392333984\n",
            "(122.87134552001953, 91.09991455078125) (141.4035186767578, 162.2782440185547) 109.44792175292969\n",
            "(106.96220397949219, 124.51731872558594) (141.3213348388672, 170.68812561035156) 91.32582092285156\n",
            "(85.66000366210938, 111.89322662353516) (69.26121520996094, 93.22129821777344) 78.38273620605469\n",
            "(127.60184478759766, 106.92342376708984) (131.71836853027344, 157.0426025390625) 91.58679962158203\n",
            "(98.61771392822266, 98.37503814697266) (154.74574279785156, 175.25950622558594) 78.8402099609375\n",
            "(93.50282287597656, 109.3614273071289) (152.5547637939453, 173.7611541748047) 85.52726745605469\n",
            "(102.64179229736328, 127.09263610839844) (137.52960205078125, 163.8795166015625) 101.2977523803711\n",
            "(111.86458587646484, 102.83404541015625) (142.33627319335938, 164.13494873046875) 79.9008560180664\n",
            "(111.88109588623047, 103.03142547607422) (144.8647918701172, 157.9499053955078) 93.37610626220703\n",
            "(116.71864318847656, 99.44271087646484) (138.8734893798828, 153.85122680664062) 107.57190704345703\n",
            "(114.09171295166016, 107.86434936523438) (101.5271987915039, 118.86418151855469) 97.48377990722656\n",
            "(115.474609375, 114.42626953125) (141.40567016601562, 155.91848754882812) 65.14513397216797\n",
            "(104.98194122314453, 107.70447540283203) (101.72096252441406, 120.5892105102539) 85.0489730834961\n",
            "(105.84854888916016, 109.27620697021484) (89.13956451416016, 103.06422424316406) 88.10719299316406\n",
            "(114.68975830078125, 103.28681945800781) (115.46121978759766, 138.76760864257812) 90.11785125732422\n",
            "(103.4029312133789, 111.6229019165039) (120.17221069335938, 142.69393920898438) 74.58709716796875\n",
            "(112.52833557128906, 112.76864624023438) (153.6266326904297, 162.1809539794922) 101.17682647705078\n",
            "(120.96532440185547, 116.25861358642578) (125.9391860961914, 160.1074981689453) 90.81497192382812\n",
            "(127.44429779052734, 104.57118225097656) (131.79864501953125, 156.77577209472656) 82.752685546875\n",
            "(93.86817169189453, 123.76123809814453) (113.18131256103516, 135.86062622070312) 82.75899505615234\n",
            "(130.51202392578125, 90.84087371826172) (109.73746490478516, 143.11920166015625) 78.59180450439453\n",
            "(124.59200286865234, 113.13111114501953) (158.71908569335938, 182.0504608154297) 88.38301849365234\n",
            "(84.46278381347656, 98.68242645263672) (133.82188415527344, 143.08258056640625) 91.13300323486328\n",
            "(102.20936584472656, 114.98684692382812) (139.302001953125, 149.1974334716797) 110.04167938232422\n",
            "(102.92686462402344, 109.76471710205078) (169.6184844970703, 183.92221069335938) 95.702880859375\n",
            "(114.13008880615234, 109.08104705810547) (129.25746154785156, 164.19647216796875) 108.02745056152344\n",
            "(116.82942962646484, 127.1706314086914) (126.70082092285156, 148.38841247558594) 87.89497375488281\n",
            "(116.74706268310547, 127.12405395507812) (126.67527770996094, 148.1324462890625) 87.5087661743164\n",
            "(98.9482421875, 103.84120178222656) (121.15340423583984, 154.10592651367188) 90.20523834228516\n",
            "(116.93423461914062, 135.26333618164062) (144.39559936523438, 175.4049072265625) 99.73761749267578\n",
            "(116.48904418945312, 97.84468841552734) (168.24021911621094, 176.66148376464844) 105.2070541381836\n",
            "(99.4551010131836, 103.18378448486328) (145.142333984375, 167.85630798339844) 71.42134094238281\n",
            "(102.7950439453125, 114.9239501953125) (167.93124389648438, 192.61317443847656) 93.50897216796875\n",
            "(112.49549865722656, 100.12474060058594) (166.0765380859375, 193.86143493652344) 93.61542510986328\n",
            "(112.57060241699219, 106.85691833496094) (130.9368896484375, 156.4853515625) 89.01539611816406\n",
            "(116.69596099853516, 106.3353271484375) (125.49471282958984, 162.03509521484375) 111.3345947265625\n",
            "(114.1263198852539, 110.29634857177734) (133.81813049316406, 149.6152801513672) 85.91797637939453\n",
            "(106.63548278808594, 116.57611846923828) (147.43064880371094, 168.51194763183594) 84.9439697265625\n",
            "(120.05870056152344, 115.73348236083984) (104.69976043701172, 123.71688079833984) 72.24116516113281\n",
            "(105.84867095947266, 113.68989562988281) (121.0830307006836, 137.1035614013672) 85.20249938964844\n",
            "(106.90105438232422, 113.80030822753906) (152.01731872558594, 174.68804931640625) 96.53659057617188\n",
            "(105.59542846679688, 97.36914825439453) (163.27462768554688, 177.26162719726562) 102.89771270751953\n",
            "(112.2398910522461, 128.41651916503906) (151.8551025390625, 169.53009033203125) 94.8692626953125\n",
            "(119.30927276611328, 123.9770278930664) (105.7291259765625, 115.83525848388672) 76.44306945800781\n",
            "(89.6092300415039, 114.54147338867188) (131.65829467773438, 149.07313537597656) 96.22674560546875\n",
            "(118.87066650390625, 109.45931243896484) (133.60250854492188, 161.29148864746094) 81.06717681884766\n",
            "(122.11451721191406, 111.14098358154297) (123.02700805664062, 154.02963256835938) 75.22566223144531\n",
            "(123.630126953125, 93.40990447998047) (122.2481918334961, 145.85472106933594) 91.1924819946289\n",
            "(111.27738952636719, 102.91915893554688) (148.7266082763672, 176.8026580810547) 88.76290130615234\n",
            "(122.62126922607422, 127.20512390136719) (138.51052856445312, 168.39747619628906) 103.97163391113281\n",
            "(114.49681854248047, 117.23812866210938) (152.61767578125, 159.87281799316406) 96.6889419555664\n",
            "(121.37284088134766, 107.09541320800781) (138.05221557617188, 151.40187072753906) 81.15714263916016\n",
            "(117.79183959960938, 91.9951400756836) (127.38754272460938, 140.4771728515625) 91.47122955322266\n",
            "(115.92108917236328, 93.17854309082031) (127.78877258300781, 143.89016723632812) 96.88336181640625\n",
            "(90.06814575195312, 92.262939453125) (117.79976654052734, 146.63189697265625) 85.97996520996094\n",
            "(86.28053283691406, 117.62329864501953) (127.08103942871094, 145.763671875) 91.0140151977539\n",
            "(122.55135345458984, 87.44701385498047) (125.51451110839844, 146.69139099121094) 95.70006561279297\n",
            "(119.26329040527344, 108.95685577392578) (155.86839294433594, 178.56396484375) 85.02481079101562\n",
            "(108.86156463623047, 107.6732406616211) (133.3987274169922, 164.88710021972656) 98.26277160644531\n",
            "(113.77033996582031, 104.4860610961914) (170.89923095703125, 192.67861938476562) 93.12554931640625\n",
            "(113.56333923339844, 114.0336685180664) (117.70941162109375, 134.45916748046875) 90.41388702392578\n",
            "(95.6646499633789, 105.34795379638672) (154.5574493408203, 180.08132934570312) 97.92655181884766\n",
            "(82.92801666259766, 81.9571762084961) (114.06023406982422, 141.76690673828125) 90.2237777709961\n",
            "(117.35130310058594, 110.67958068847656) (148.78543090820312, 179.35546875) 86.27709197998047\n",
            "(101.39134979248047, 108.52676391601562) (146.73703002929688, 168.7364501953125) 89.93953704833984\n",
            "(105.37024688720703, 105.2684097290039) (170.66847229003906, 193.2184600830078) 88.72127532958984\n",
            "(120.18038177490234, 107.31483459472656) (132.87344360351562, 151.1308135986328) 88.1703109741211\n",
            "(116.92566680908203, 95.61354064941406) (147.3619842529297, 162.82774353027344) 90.97847747802734\n",
            "(109.37680053710938, 99.86136627197266) (127.61042022705078, 165.9877471923828) 105.47319030761719\n",
            "(112.81867980957031, 112.00394439697266) (141.798095703125, 170.60012817382812) 87.694580078125\n",
            "(122.13776397705078, 101.52369689941406) (133.8004150390625, 156.02098083496094) 97.90332794189453\n",
            "(110.02000427246094, 99.44349670410156) (129.33297729492188, 149.04913330078125) 85.1269760131836\n",
            "(110.40299224853516, 115.5380859375) (171.83596801757812, 179.889892578125) 70.00643157958984\n",
            "(117.66548919677734, 88.96258544921875) (118.78931427001953, 143.22088623046875) 88.1524887084961\n",
            "(102.70207977294922, 90.54986572265625) (119.89204406738281, 139.74729919433594) 88.02809143066406\n",
            "(115.4341049194336, 100.59376525878906) (162.91148376464844, 184.91583251953125) 91.71024322509766\n",
            "(117.00587463378906, 134.9387664794922) (141.0089111328125, 161.1958770751953) 83.52075958251953\n",
            "(95.00692749023438, 126.99162292480469) (125.04850006103516, 148.93707275390625) 95.92394256591797\n",
            "(108.17236328125, 126.01378631591797) (164.25425720214844, 195.05491638183594) 100.05084991455078\n",
            "(110.66927337646484, 106.79822540283203) (148.4071502685547, 197.263671875) 106.89198303222656\n",
            "(119.404296875, 108.70409393310547) (137.4276885986328, 159.2700958251953) 89.35990905761719\n",
            "(106.35029602050781, 116.58058166503906) (153.6574249267578, 188.0256805419922) 96.24552154541016\n",
            "(121.60013580322266, 104.9766845703125) (155.53465270996094, 184.48269653320312) 84.99036407470703\n",
            "(103.91839599609375, 95.20541381835938) (125.97810363769531, 150.68194580078125) 108.20062255859375\n",
            "(100.4234390258789, 102.4056167602539) (124.61486053466797, 144.6728057861328) 88.68256378173828\n",
            "(107.04338836669922, 117.2376480102539) (134.42413330078125, 162.36907958984375) 86.06632232666016\n",
            "(118.26806640625, 89.77166748046875) (139.10031127929688, 146.21267700195312) 59.454261779785156\n",
            "(109.38939666748047, 102.3960952758789) (161.29222106933594, 193.35845947265625) 87.73499298095703\n",
            "(130.50430297851562, 116.29116821289062) (142.9916534423828, 175.3797607421875) 100.0033187866211\n",
            "(126.628662109375, 99.6742935180664) (149.9116668701172, 168.6517791748047) 96.50770568847656\n",
            "(97.36056518554688, 111.9886703491211) (119.2668228149414, 137.3731231689453) 99.61605834960938\n",
            "(87.34022521972656, 101.272216796875) (129.9918670654297, 148.1806640625) 91.83627319335938\n",
            "(94.38925170898438, 122.1683349609375) (107.99266815185547, 132.5294189453125) 100.03343963623047\n",
            "(119.94096374511719, 115.1438217163086) (143.40476989746094, 163.80654907226562) 92.47698211669922\n",
            "(114.328857421875, 102.72200775146484) (144.04913330078125, 168.7561798095703) 81.83660125732422\n",
            "(102.28421020507812, 106.96836853027344) (156.7454833984375, 163.8845672607422) 87.10240936279297\n",
            "(98.75032806396484, 109.85720825195312) (152.61424255371094, 179.34088134765625) 84.20812225341797\n",
            "(97.33200073242188, 94.58308410644531) (152.82183837890625, 173.43109130859375) 79.7431869506836\n",
            "(110.57243347167969, 120.6973876953125) (150.8417510986328, 179.20193481445312) 89.10844421386719\n",
            "(95.19171905517578, 127.5836181640625) (155.68214416503906, 177.8925018310547) 89.09652709960938\n",
            "(125.61630249023438, 107.77806091308594) (130.17710876464844, 155.89413452148438) 90.39179992675781\n",
            "(115.02015686035156, 106.56216430664062) (172.48756408691406, 187.25440979003906) 136.2616729736328\n",
            "(114.51757049560547, 118.87799835205078) (143.64013671875, 165.98648071289062) 85.97071075439453\n",
            "(108.86005401611328, 106.16688537597656) (141.03907775878906, 159.73463439941406) 91.71573638916016\n",
            "(105.18914794921875, 105.5530776977539) (142.08905029296875, 158.54006958007812) 88.17666625976562\n",
            "(104.26183319091797, 110.72071838378906) (133.5081329345703, 153.3761444091797) 106.0091323852539\n",
            "(109.29280853271484, 106.14547729492188) (149.34153747558594, 171.93841552734375) 92.04003143310547\n",
            "(135.79605102539062, 118.1812515258789) (110.18794250488281, 133.6533966064453) 83.49057006835938\n",
            "(132.1420135498047, 118.9599838256836) (139.18106079101562, 170.08203125) 103.91958618164062\n",
            "(111.28211212158203, 101.8763427734375) (131.20326232910156, 153.80230712890625) 92.04462432861328\n",
            "(115.37773132324219, 90.88992309570312) (85.70480346679688, 107.5273666381836) 79.76537322998047\n",
            "(101.36396789550781, 121.15145874023438) (122.6071548461914, 175.42225646972656) 109.34492492675781\n",
            "(109.43980407714844, 91.17476654052734) (138.8339080810547, 163.78558349609375) 77.04649353027344\n",
            "(106.29988098144531, 104.7425765991211) (161.67689514160156, 195.91146850585938) 93.99919128417969\n",
            "(107.4311752319336, 106.26091003417969) (136.8817138671875, 161.39138793945312) 91.5335693359375\n",
            "(93.17427062988281, 102.98271942138672) (119.55271911621094, 138.0508575439453) 89.82061004638672\n",
            "(116.04073333740234, 112.44072723388672) (140.3705291748047, 156.7264862060547) 92.4740982055664\n",
            "(116.909423828125, 100.42682647705078) (147.8389129638672, 169.3877716064453) 77.08631896972656\n",
            "(136.15211486816406, 88.83837127685547) (119.49655151367188, 135.81565856933594) 76.65805053710938\n",
            "(139.05014038085938, 108.22520446777344) (122.98316192626953, 136.11370849609375) 114.06389617919922\n",
            "(116.83779907226562, 105.06796264648438) (86.30169677734375, 108.83922576904297) 102.62873840332031\n",
            "(109.1817398071289, 105.89141082763672) (165.37982177734375, 184.1212921142578) 80.5746078491211\n",
            "(130.10848999023438, 113.67376708984375) (121.470947265625, 151.3865509033203) 89.9981918334961\n",
            "(114.86467742919922, 119.46601104736328) (113.30111694335938, 130.81039428710938) 94.08513641357422\n",
            "(137.98861694335938, 118.98162078857422) (108.53326416015625, 118.55633544921875) 76.81306457519531\n",
            "(123.88790893554688, 114.87164306640625) (153.5744171142578, 173.06565856933594) 92.34136199951172\n",
            "(115.48867797851562, 100.84506225585938) (114.15827941894531, 125.96941375732422) 91.0525131225586\n",
            "(112.8343734741211, 112.62788391113281) (132.87107849121094, 170.5308837890625) 99.953369140625\n",
            "(135.07615661621094, 106.00712585449219) (108.30543518066406, 123.66439819335938) 87.79885864257812\n",
            "(120.51140594482422, 101.18289947509766) (157.6243896484375, 168.41201782226562) 102.43757629394531\n",
            "(115.14961242675781, 106.18987274169922) (136.66661071777344, 169.84934997558594) 68.31017303466797\n",
            "(123.7640380859375, 106.31568908691406) (168.80877685546875, 178.45806884765625) 99.40179443359375\n",
            "(86.70232391357422, 101.18385314941406) (122.84493255615234, 145.93310546875) 85.0520248413086\n",
            "(113.20423126220703, 85.34813690185547) (127.65425109863281, 160.57594299316406) 67.20069885253906\n",
            "(117.6171875, 124.9837417602539) (131.30543518066406, 157.20411682128906) 96.90984344482422\n",
            "(111.3591079711914, 111.91354370117188) (131.39747619628906, 157.9177703857422) 90.36092376708984\n",
            "(98.2077407836914, 110.76084899902344) (158.06341552734375, 176.2859649658203) 103.24835205078125\n",
            "(123.23233795166016, 104.06063079833984) (145.81942749023438, 169.56716918945312) 90.8736343383789\n",
            "(100.72332000732422, 108.33956146240234) (134.69151306152344, 153.87896728515625) 81.9367446899414\n",
            "(117.1725845336914, 111.56649780273438) (153.87625122070312, 170.86676025390625) 104.09163665771484\n",
            "(106.86380004882812, 115.0604248046875) (169.71835327148438, 200.14952087402344) 89.22560119628906\n",
            "(94.79468536376953, 101.31529235839844) (123.32252502441406, 141.30270385742188) 90.36994934082031\n",
            "(111.22884368896484, 93.55793762207031) (131.9834747314453, 148.7503204345703) 86.98495483398438\n",
            "(110.43724060058594, 120.44021606445312) (105.27106475830078, 127.18527221679688) 87.24931335449219\n",
            "(111.46044921875, 106.97798919677734) (96.0009994506836, 112.63526916503906) 77.37063598632812\n",
            "(130.4503936767578, 107.23982238769531) (74.79413604736328, 91.3052749633789) 91.13980865478516\n",
            "(94.58291625976562, 86.9327621459961) (133.80479431152344, 160.1400909423828) 102.75548553466797\n",
            "(97.74414825439453, 113.9300537109375) (138.3804473876953, 164.92715454101562) 78.6681137084961\n",
            "(120.78981018066406, 112.62786102294922) (154.7943878173828, 174.30859375) 90.83885955810547\n",
            "(111.02946472167969, 120.22351837158203) (155.4120635986328, 168.75997924804688) 110.92012023925781\n",
            "(127.1341323852539, 112.64671325683594) (78.44498443603516, 99.00260925292969) 73.63850402832031\n",
            "(111.80171203613281, 116.8790054321289) (157.46640014648438, 196.9083709716797) 90.05950164794922\n",
            "(118.91573333740234, 131.16677856445312) (130.4677276611328, 149.78492736816406) 70.3478012084961\n",
            "(116.12313079833984, 111.62124633789062) (135.53749084472656, 149.72109985351562) 86.61701965332031\n",
            "(129.58860778808594, 126.17803955078125) (86.8503646850586, 103.18827056884766) 96.56478118896484\n",
            "(114.15032196044922, 136.0149688720703) (128.5382537841797, 149.1992950439453) 86.90840911865234\n",
            "(122.22096252441406, 117.17229461669922) (139.94566345214844, 178.50999450683594) 77.43472290039062\n",
            "(107.67224884033203, 122.09839630126953) (161.82989501953125, 177.74916076660156) 93.59907531738281\n",
            "(104.04045104980469, 100.57740783691406) (146.63267517089844, 164.6240997314453) 83.88624572753906\n",
            "(117.97867584228516, 104.77255249023438) (135.34356689453125, 158.05018615722656) 91.94849395751953\n",
            "(109.16476440429688, 127.78492736816406) (130.21250915527344, 154.6028289794922) 94.39472961425781\n",
            "(107.77204895019531, 107.46434783935547) (104.9023666381836, 119.75792694091797) 100.25457000732422\n",
            "(97.54546356201172, 119.43920135498047) (123.8458480834961, 146.70155334472656) 89.16222381591797\n",
            "(111.78202056884766, 107.88890075683594) (166.8505401611328, 199.14291381835938) 91.12245178222656\n",
            "(121.36127471923828, 120.0627670288086) (159.23463439941406, 170.09864807128906) 83.99046325683594\n",
            "(105.5777816772461, 117.37738037109375) (161.03977966308594, 179.07249450683594) 98.5102767944336\n",
            "(123.06295776367188, 111.65859985351562) (146.66342163085938, 155.9951171875) 64.34410858154297\n",
            "(96.29608154296875, 126.21688842773438) (130.73989868164062, 161.80130004882812) 95.29774475097656\n",
            "(127.81233978271484, 97.08589935302734) (119.25192260742188, 134.41046142578125) 89.35135650634766\n",
            "(122.32179260253906, 105.37102508544922) (122.76669311523438, 139.08831787109375) 90.29306030273438\n",
            "(104.9133071899414, 121.15718078613281) (115.4975814819336, 142.4764404296875) 76.01191711425781\n",
            "(124.74758911132812, 113.95769500732422) (74.6837158203125, 113.00614929199219) 74.73970794677734\n",
            "(95.51201629638672, 103.30232238769531) (145.86550903320312, 193.23858642578125) 76.46871185302734\n",
            "(104.04228210449219, 106.21544647216797) (164.94468688964844, 187.32098388671875) 92.34022521972656\n",
            "(101.1548843383789, 106.42195129394531) (158.06544494628906, 167.6709442138672) 96.2186279296875\n",
            "(129.15318298339844, 91.39771270751953) (93.48969268798828, 123.20655059814453) 74.88587188720703\n",
            "(107.98497772216797, 101.86180114746094) (137.80038452148438, 165.39578247070312) 96.815673828125\n",
            "(107.30403137207031, 108.55968475341797) (85.89469909667969, 105.87216186523438) 89.44055938720703\n",
            "(106.4677734375, 107.16529083251953) (144.8728790283203, 182.20359802246094) 82.18017578125\n",
            "(113.36456298828125, 96.60880279541016) (167.7493896484375, 198.86245727539062) 88.65396881103516\n",
            "(94.34285736083984, 91.1434097290039) (145.85086059570312, 158.07518005371094) 92.62004089355469\n",
            "(143.87945556640625, 101.73906707763672) (99.1795654296875, 112.80292510986328) 61.8326530456543\n",
            "(114.10147857666016, 114.37370300292969) (123.70890808105469, 147.47154235839844) 91.7107925415039\n",
            "(99.60559844970703, 120.87372589111328) (105.58409118652344, 120.75653076171875) 61.026973724365234\n",
            "(121.36507415771484, 114.00061798095703) (43.08599090576172, 54.16927719116211) 102.14681243896484\n",
            "(135.32101440429688, 103.80602264404297) (86.02574920654297, 98.76192474365234) 91.88414764404297\n",
            "(99.88328552246094, 94.41960906982422) (70.26789855957031, 105.67835235595703) 101.36329650878906\n",
            "(101.63440704345703, 119.54237365722656) (73.75135040283203, 104.6224594116211) 103.99522399902344\n",
            "(127.5341567993164, 98.28278350830078) (134.71949768066406, 152.52825927734375) 90.74160766601562\n",
            "(102.91260528564453, 114.11908721923828) (133.32293701171875, 150.9754180908203) 97.64987182617188\n",
            "(109.006591796875, 107.76350402832031) (144.86915588378906, 165.04953002929688) 82.99097442626953\n",
            "(111.25875854492188, 103.21438598632812) (175.7454833984375, 206.7574005126953) 95.20829010009766\n",
            "(116.37227630615234, 108.56665802001953) (145.3694305419922, 165.5830535888672) 77.46955871582031\n",
            "(104.61347961425781, 108.5525131225586) (91.04914093017578, 115.14604187011719) 72.84211730957031\n",
            "(115.98113250732422, 116.52973175048828) (136.92628479003906, 158.77113342285156) 89.89137268066406\n",
            "(130.5394744873047, 112.64502716064453) (105.33390808105469, 127.01595306396484) 76.51337432861328\n",
            "(113.06885528564453, 108.44178009033203) (144.8092041015625, 167.90318298339844) 98.12926483154297\n",
            "(86.48877716064453, 112.87586975097656) (151.20904541015625, 162.74667358398438) 105.32830047607422\n",
            "(104.72004699707031, 96.77607727050781) (162.56234741210938, 177.23802185058594) 97.40068054199219\n",
            "(121.6299819946289, 104.2335433959961) (80.50537872314453, 127.35498809814453) 105.96273803710938\n",
            "(100.43360137939453, 101.38666534423828) (143.3655548095703, 165.0880889892578) 93.10578918457031\n",
            "(99.4316177368164, 105.09408569335938) (130.14553833007812, 165.3250274658203) 76.18894958496094\n",
            "(126.57917022705078, 88.94127655029297) (136.83172607421875, 150.14869689941406) 97.8133544921875\n",
            "(114.6392593383789, 115.02037811279297) (99.49453735351562, 110.20865631103516) 78.42803955078125\n",
            "(99.60296630859375, 129.70889282226562) (154.61679077148438, 183.2410888671875) 54.52103805541992\n",
            "(115.48114013671875, 89.71553802490234) (119.01885223388672, 146.08738708496094) 98.78601837158203\n",
            "(123.54452514648438, 113.1938247680664) (158.31707763671875, 173.54139709472656) 83.83528900146484\n",
            "(106.36909484863281, 107.14612579345703) (151.24029541015625, 182.08775329589844) 83.5849838256836\n",
            "(96.6630859375, 120.12812805175781) (140.50445556640625, 154.1396942138672) 61.86164855957031\n",
            "(112.78914642333984, 88.92892456054688) (73.22395324707031, 107.85020446777344) 106.03995513916016\n",
            "(92.2481918334961, 91.83480834960938) (105.61656188964844, 131.22695922851562) 91.700927734375\n",
            "(113.8173599243164, 104.14702606201172) (154.99618530273438, 192.5609893798828) 74.90922546386719\n",
            "(110.43331146240234, 114.08071899414062) (156.36953735351562, 178.56436157226562) 93.90702056884766\n",
            "(98.10042572021484, 112.99661254882812) (141.6366729736328, 167.88232421875) 89.09799194335938\n",
            "(119.1175537109375, 111.09304809570312) (110.04315185546875, 124.5804443359375) 78.09561920166016\n",
            "(109.20420837402344, 117.07178497314453) (166.73304748535156, 197.763916015625) 82.48091125488281\n",
            "(111.36601257324219, 103.90047454833984) (132.81195068359375, 154.4950714111328) 86.90982818603516\n",
            "(114.1462173461914, 120.4622573852539) (111.94403839111328, 130.96824645996094) 91.14164733886719\n",
            "(116.28353881835938, 104.77854919433594) (172.36856079101562, 187.0863037109375) 94.02333068847656\n",
            "(82.9358139038086, 101.87986755371094) (64.04356384277344, 81.08049011230469) 83.70594787597656\n",
            "(105.60015106201172, 111.52413940429688) (141.42543029785156, 168.87506103515625) 65.5987319946289\n",
            "(140.08987426757812, 116.71778106689453) (117.5408706665039, 148.97837829589844) 100.49602508544922\n",
            "(96.58271789550781, 106.04936981201172) (134.87313842773438, 167.53988647460938) 79.77928924560547\n",
            "(102.57745361328125, 109.2076416015625) (100.7427749633789, 121.06053161621094) 88.71308135986328\n",
            "(116.8433837890625, 105.35800170898438) (151.76307678222656, 183.6813507080078) 81.40882873535156\n",
            "(112.18502044677734, 118.84404754638672) (138.3462371826172, 167.46841430664062) 92.30873107910156\n",
            "(106.26232147216797, 121.08001708984375) (68.60467529296875, 93.05120086669922) 102.4533920288086\n",
            "(75.09793853759766, 111.58879852294922) (69.90613555908203, 82.58892059326172) 91.37077331542969\n",
            "(132.44705200195312, 120.9791030883789) (116.59747314453125, 136.19139099121094) 73.81591796875\n",
            "(109.77393341064453, 101.6736068725586) (97.5733871459961, 137.71920776367188) 98.28521728515625\n",
            "(103.48654174804688, 85.49636840820312) (95.46769714355469, 140.40887451171875) 100.7540054321289\n",
            "(125.43537139892578, 106.00221252441406) (141.0581512451172, 163.9459991455078) 86.77388763427734\n",
            "(108.65164947509766, 109.10384368896484) (93.96806335449219, 126.53325653076172) 72.75557708740234\n",
            "(112.32870483398438, 126.13793182373047) (70.47053527832031, 91.66661834716797) 82.95679473876953\n",
            "(102.25108337402344, 110.08100891113281) (145.99737548828125, 156.49342346191406) 96.05767822265625\n",
            "(88.28913116455078, 126.4437026977539) (132.9007110595703, 172.11825561523438) 101.48698425292969\n",
            "(135.34181213378906, 110.72520446777344) (97.4876480102539, 122.49359893798828) 75.73200988769531\n",
            "(111.75358581542969, 106.83085632324219) (141.058349609375, 186.15078735351562) 60.3428955078125\n",
            "(122.95128631591797, 115.11912536621094) (136.94833374023438, 151.9915008544922) 81.03182983398438\n",
            "(121.92202758789062, 98.52652740478516) (132.84255981445312, 149.47747802734375) 89.49610900878906\n",
            "(103.06228637695312, 119.89776611328125) (113.8408203125, 155.24264526367188) 106.96788787841797\n",
            "(108.75386810302734, 117.96902465820312) (108.57665252685547, 124.9647216796875) 80.65029907226562\n",
            "(90.2496109008789, 125.11864471435547) (81.16251373291016, 134.00616455078125) 96.95046997070312\n",
            "(109.32186889648438, 107.11048889160156) (105.98855590820312, 129.0107879638672) 72.79167175292969\n",
            "(110.87194061279297, 107.18448638916016) (180.06271362304688, 188.0855255126953) 80.68859100341797\n",
            "(127.7731704711914, 115.74099731445312) (88.4930419921875, 107.01378631591797) 78.49793243408203\n",
            "(108.1505126953125, 117.90754699707031) (130.78079223632812, 155.44879150390625) 79.52896118164062\n",
            "(109.1438980102539, 107.997802734375) (153.2422332763672, 163.3813934326172) 86.24662017822266\n",
            "(111.67144775390625, 107.34618377685547) (149.38009643554688, 167.7886199951172) 75.70834350585938\n",
            "(116.70225524902344, 90.82049560546875) (109.4730224609375, 140.2650909423828) 99.59648132324219\n",
            "(81.9212875366211, 110.28163146972656) (103.42530822753906, 131.4651641845703) 72.6605224609375\n",
            "(106.81404113769531, 105.77934265136719) (104.16532135009766, 138.66238403320312) 76.05369567871094\n",
            "(112.8265609741211, 106.79777526855469) (163.8624267578125, 198.39222717285156) 90.7431640625\n",
            "(128.38650512695312, 105.18885040283203) (115.8055191040039, 138.809814453125) 89.3533935546875\n",
            "(110.77320861816406, 116.26237487792969) (171.17298889160156, 195.52415466308594) 85.8927993774414\n",
            "(101.56140899658203, 117.90420532226562) (103.83024597167969, 148.811767578125) 74.28262329101562\n",
            "(96.22293090820312, 106.29389953613281) (82.68386840820312, 107.77716827392578) 78.18667602539062\n",
            "(127.63771057128906, 103.83995056152344) (117.14155578613281, 130.92135620117188) 97.33633422851562\n",
            "(117.07939910888672, 91.8466796875) (164.46571350097656, 196.1417694091797) 85.62260437011719\n",
            "(92.2928695678711, 99.74690246582031) (145.53501892089844, 167.39476013183594) 100.25808715820312\n",
            "(117.90908813476562, 127.77132415771484) (85.7560043334961, 101.52487182617188) 82.87126922607422\n",
            "(101.59251403808594, 117.32971954345703) (136.73268127441406, 164.61526489257812) 85.99530029296875\n",
            "(109.98063659667969, 102.81035614013672) (170.2937774658203, 194.60556030273438) 85.8309326171875\n",
            "(98.42723083496094, 123.21317291259766) (98.05765533447266, 114.83309173583984) 79.92864227294922\n",
            "(117.29872131347656, 112.31951904296875) (105.02522277832031, 116.6614990234375) 85.84516906738281\n",
            "(107.16307830810547, 105.94001770019531) (169.8712921142578, 186.2393035888672) 81.1075668334961\n",
            "(74.93913269042969, 109.21147155761719) (105.07205963134766, 131.38668823242188) 105.5646743774414\n",
            "(109.37744903564453, 101.77517700195312) (171.88697814941406, 192.29547119140625) 103.87744140625\n",
            "(98.92528533935547, 109.8714599609375) (93.51898193359375, 125.42936706542969) 70.4373550415039\n",
            "(99.07853698730469, 122.84053802490234) (93.36477661132812, 107.93987274169922) 99.93864440917969\n",
            "(128.42665100097656, 95.50228118896484) (106.05937194824219, 125.3609619140625) 84.37491607666016\n",
            "(102.44558715820312, 117.66371154785156) (142.2931671142578, 168.30052185058594) 76.63719177246094\n",
            "(108.07251739501953, 116.77249908447266) (144.37742614746094, 167.4505615234375) 84.89664459228516\n",
            "(106.15787506103516, 108.0978012084961) (166.3600311279297, 187.61911010742188) 89.41465759277344\n",
            "(96.08170318603516, 96.38448333740234) (102.04185485839844, 118.63085174560547) 87.61607360839844\n",
            "(99.40626525878906, 129.9927978515625) (136.3582305908203, 167.6370391845703) 94.91740417480469\n",
            "(102.10853576660156, 123.01921081542969) (141.74270629882812, 168.50994873046875) 95.78601837158203\n",
            "(86.37059783935547, 114.8895034790039) (144.5738067626953, 168.25662231445312) 79.61417388916016\n",
            "(120.4542007446289, 125.32217407226562) (136.66940307617188, 155.25502014160156) 87.0025634765625\n",
            "(122.15792083740234, 110.33929443359375) (125.35750579833984, 139.2910919189453) 93.69979858398438\n",
            "(135.37799072265625, 101.88825988769531) (123.22299194335938, 141.2342071533203) 88.69710540771484\n",
            "(98.2514877319336, 124.02621459960938) (150.76046752929688, 178.45025634765625) 93.9825439453125\n",
            "(112.90277099609375, 111.15174102783203) (157.8780975341797, 178.56838989257812) 105.83916473388672\n",
            "(119.33537292480469, 103.91324615478516) (96.82733154296875, 137.5033416748047) 106.19233703613281\n",
            "(105.440673828125, 104.98089599609375) (101.17475891113281, 153.0923309326172) 102.6658935546875\n",
            "(109.64022064208984, 99.41342163085938) (118.15989685058594, 141.938720703125) 109.11312103271484\n",
            "(113.39147186279297, 106.52123260498047) (142.21421813964844, 168.06155395507812) 96.27948760986328\n",
            "(113.38365936279297, 106.55608367919922) (142.28318786621094, 168.00765991210938) 96.40968322753906\n",
            "(107.204345703125, 102.27569580078125) (145.07032775878906, 170.6350860595703) 100.90864562988281\n",
            "(116.7812728881836, 115.11521911621094) (120.05274963378906, 140.45806884765625) 86.2385025024414\n",
            "(112.72126007080078, 117.31275177001953) (160.5415802001953, 178.99783325195312) 94.30828094482422\n",
            "(115.35253143310547, 116.8137435913086) (140.8344268798828, 159.70034790039062) 105.3897476196289\n",
            "(110.60877990722656, 103.80215454101562) (146.64271545410156, 175.31668090820312) 81.56385803222656\n",
            "(119.99567413330078, 97.86444854736328) (123.75367736816406, 162.62901306152344) 70.5277328491211\n",
            "(118.01451110839844, 117.47760009765625) (168.6020965576172, 179.44955444335938) 115.79605865478516\n",
            "(106.14527893066406, 110.68275451660156) (149.5365447998047, 169.37120056152344) 87.3208999633789\n",
            "(116.61200714111328, 108.76490783691406) (132.24542236328125, 151.72764587402344) 91.8086929321289\n",
            "(92.83428955078125, 106.8717269897461) (102.03778839111328, 131.25796508789062) 89.59709930419922\n",
            "(90.97714233398438, 114.52436828613281) (133.9646453857422, 158.84786987304688) 98.11280059814453\n",
            "(109.32536315917969, 120.16926574707031) (146.07777404785156, 174.50039672851562) 95.94966125488281\n",
            "(96.39362335205078, 104.4538345336914) (141.3810272216797, 165.0109405517578) 93.2204360961914\n",
            "(123.96361541748047, 118.9917221069336) (114.3971939086914, 136.87086486816406) 89.56854248046875\n",
            "(98.24791717529297, 107.43079376220703) (148.0101776123047, 164.4774627685547) 89.04332733154297\n",
            "(115.3116455078125, 100.63673400878906) (165.95114135742188, 192.564208984375) 75.17312622070312\n",
            "(120.11251831054688, 110.45557403564453) (101.22549438476562, 153.17333984375) 105.96772766113281\n",
            "(113.48064422607422, 101.592529296875) (113.67326354980469, 139.60287475585938) 88.87963104248047\n",
            "(92.7061767578125, 119.1446762084961) (118.0609359741211, 134.1700897216797) 63.752994537353516\n",
            "(94.9879379272461, 118.3403091430664) (148.06130981445312, 173.88427734375) 95.82469177246094\n",
            "(96.86888885498047, 110.28054809570312) (151.6453857421875, 169.79678344726562) 91.30662536621094\n",
            "(120.16376495361328, 116.61587524414062) (127.16120910644531, 157.65542602539062) 93.35633087158203\n",
            "(123.704345703125, 102.00731658935547) (130.39382934570312, 174.8328857421875) 103.91569519042969\n",
            "(109.03031158447266, 105.24905395507812) (160.61643981933594, 194.26329040527344) 108.33262634277344\n",
            "(105.63105010986328, 112.72476196289062) (128.91790771484375, 153.49615478515625) 86.97330474853516\n",
            "(104.83647918701172, 109.16075134277344) (149.47679138183594, 177.9625701904297) 83.04495239257812\n",
            "(116.0340347290039, 104.4671630859375) (148.47434997558594, 192.70989990234375) 102.33123016357422\n",
            "(124.534912109375, 97.41470336914062) (97.55636596679688, 129.34169006347656) 73.8614501953125\n",
            "(125.14546203613281, 107.323486328125) (130.386474609375, 161.94544982910156) 96.02778625488281\n",
            "(104.47960662841797, 102.20814514160156) (148.16653442382812, 194.7714080810547) 100.96245574951172\n",
            "(140.8210906982422, 102.64700317382812) (131.51101684570312, 163.93357849121094) 112.48113250732422\n",
            "(115.6999740600586, 112.8569564819336) (115.73648834228516, 154.60446166992188) 116.0801773071289\n",
            "(91.54067993164062, 112.17235565185547) (95.33129119873047, 121.0702133178711) 105.70189666748047\n",
            "(98.82475280761719, 119.04603576660156) (106.10997772216797, 126.01332092285156) 102.73819732666016\n",
            "(113.94630432128906, 107.51364135742188) (118.62279510498047, 146.3791961669922) 66.99002838134766\n",
            "(113.87520599365234, 116.17916107177734) (137.1500701904297, 168.73318481445312) 90.4651107788086\n",
            "(113.6874771118164, 102.021240234375) (121.12755584716797, 143.69346618652344) 74.60050964355469\n",
            "(95.30309295654297, 102.18456268310547) (136.1790313720703, 174.61000061035156) 81.19625091552734\n",
            "(119.23844909667969, 117.40646362304688) (84.44776916503906, 141.1848602294922) 90.65987396240234\n",
            "(95.46642303466797, 106.50289154052734) (146.6079559326172, 172.3575897216797) 82.32318878173828\n",
            "(128.1446075439453, 103.96992492675781) (123.32616424560547, 139.0717315673828) 95.02581787109375\n",
            "(138.56793212890625, 100.17142486572266) (99.10820007324219, 147.90103149414062) 84.46040344238281\n",
            "(107.53119659423828, 110.47154235839844) (83.7132339477539, 94.50125122070312) 75.03044891357422\n",
            "(100.04436492919922, 106.66986083984375) (140.35842895507812, 176.84771728515625) 75.70535278320312\n",
            "(121.02482604980469, 92.3564453125) (128.36795043945312, 156.0360565185547) 90.63990020751953\n",
            "(112.1556396484375, 100.27954864501953) (131.14578247070312, 157.4401092529297) 91.08283996582031\n",
            "(102.29466247558594, 106.908447265625) (149.31942749023438, 185.19761657714844) 90.47843933105469\n",
            "(126.85841369628906, 105.45013427734375) (111.92532348632812, 133.07473754882812) 88.04991912841797\n",
            "(125.0888442993164, 113.32080841064453) (145.47048950195312, 166.09242248535156) 92.04644012451172\n",
            "(122.34491729736328, 106.52739715576172) (120.16777038574219, 143.95445251464844) 82.42782592773438\n",
            "(118.61878967285156, 111.30050659179688) (140.2074737548828, 172.06787109375) 74.34736633300781\n",
            "(121.04373931884766, 109.75922393798828) (106.15955352783203, 123.6216812133789) 81.45852661132812\n",
            "(105.84278869628906, 112.59762573242188) (103.06487274169922, 129.9364013671875) 76.16666412353516\n",
            "(105.14000701904297, 107.99250030517578) (135.3056640625, 177.53463745117188) 99.32457733154297\n",
            "(107.99019622802734, 110.67033386230469) (134.7544403076172, 174.70753479003906) 97.81431579589844\n",
            "(126.93843078613281, 115.49791717529297) (136.06695556640625, 152.04586791992188) 84.62102508544922\n",
            "(123.58486938476562, 121.48274230957031) (153.81459045410156, 183.29702758789062) 103.36585235595703\n",
            "(108.47183227539062, 111.34133911132812) (129.23863220214844, 162.0033721923828) 80.9142837524414\n",
            "(118.8722152709961, 112.36067962646484) (153.85772705078125, 168.12559509277344) 90.2627182006836\n",
            "(118.06206512451172, 104.67389678955078) (149.67239379882812, 166.52471923828125) 89.25289916992188\n",
            "(106.05148315429688, 97.81331634521484) (133.72903442382812, 158.10116577148438) 84.28545379638672\n",
            "(90.8511962890625, 107.12979888916016) (105.10868072509766, 123.80473327636719) 98.35697174072266\n",
            "(110.16499328613281, 106.07105255126953) (117.95819091796875, 140.8094024658203) 84.85743713378906\n",
            "(123.995361328125, 110.24636840820312) (139.97084045410156, 167.90130615234375) 86.5597152709961\n",
            "(105.32618713378906, 114.54534149169922) (129.46127319335938, 154.2057342529297) 98.78206634521484\n",
            "(110.35155487060547, 99.24747467041016) (123.47750854492188, 151.00115966796875) 93.18455505371094\n",
            "(106.31621551513672, 110.90513610839844) (121.60870361328125, 152.86842346191406) 91.31689453125\n",
            "(114.7481918334961, 107.15296173095703) (131.31227111816406, 156.23394775390625) 87.20999145507812\n",
            "(101.49231719970703, 106.12786102294922) (144.72267150878906, 173.1607666015625) 94.42811584472656\n",
            "(126.68750762939453, 112.47804260253906) (117.12723541259766, 149.7390899658203) 87.97701263427734\n",
            "(117.176025390625, 99.26492309570312) (148.4207305908203, 176.1697235107422) 83.63186645507812\n",
            "(112.3996810913086, 107.24309539794922) (122.26839447021484, 149.4932098388672) 87.0259780883789\n",
            "(92.44781494140625, 119.09979248046875) (81.69921112060547, 106.73551940917969) 68.3913803100586\n",
            "(87.87802124023438, 103.617431640625) (82.36204528808594, 113.50323486328125) 73.34822082519531\n",
            "(111.55272674560547, 111.01353454589844) (128.53636169433594, 164.7974853515625) 82.1054916381836\n",
            "(111.15160369873047, 111.08695983886719) (129.9459228515625, 170.71543884277344) 77.66243743896484\n",
            "(118.29435729980469, 97.51377868652344) (115.26408386230469, 142.8587646484375) 93.11954498291016\n",
            "(106.06190490722656, 105.51817321777344) (137.5685272216797, 188.35247802734375) 85.59898376464844\n",
            "(131.442626953125, 115.88754272460938) (104.87617492675781, 112.60531616210938) 102.72724151611328\n",
            "(128.86068725585938, 111.27426147460938) (100.17866516113281, 116.56997680664062) 111.90039825439453\n",
            "(110.45867919921875, 114.01561737060547) (127.711181640625, 149.0352020263672) 75.45215606689453\n",
            "(107.58580017089844, 114.79878997802734) (127.77600860595703, 146.29638671875) 77.41895294189453\n",
            "(104.4738998413086, 101.12085723876953) (136.76763916015625, 152.90113830566406) 82.00800323486328\n",
            "(108.3184814453125, 120.00239562988281) (136.80108642578125, 182.28810119628906) 90.10697937011719\n",
            "(104.49932098388672, 120.4541244506836) (137.05149841308594, 178.0052490234375) 86.752685546875\n",
            "(100.45002746582031, 100.83113098144531) (147.56275939941406, 171.8759765625) 86.56635284423828\n",
            "(89.52359008789062, 105.2498779296875) (158.85491943359375, 182.13075256347656) 74.81067657470703\n",
            "(99.28126525878906, 108.31941986083984) (114.1584701538086, 145.70303344726562) 75.64530944824219\n",
            "(99.31086730957031, 108.32109832763672) (114.19518280029297, 145.65042114257812) 75.7313003540039\n",
            "(97.19003295898438, 108.74781799316406) (103.78923034667969, 122.59862518310547) 106.63592529296875\n",
            "(123.91459655761719, 109.05615234375) (113.39742279052734, 133.15399169921875) 93.72547912597656\n",
            "(115.3428955078125, 101.18782043457031) (111.90911865234375, 161.0601806640625) 75.95523071289062\n",
            "(116.09362030029297, 95.49146270751953) (133.30136108398438, 175.83531188964844) 75.05216217041016\n",
            "(108.04212951660156, 111.76240539550781) (158.98291015625, 162.8199005126953) 170.05133056640625\n",
            "(112.91845703125, 118.34757995605469) (169.72731018066406, 186.18710327148438) 105.8533706665039\n",
            "(106.54228973388672, 98.89883422851562) (164.48599243164062, 204.67782592773438) 93.73641204833984\n",
            "(122.12830352783203, 113.17423248291016) (142.51023864746094, 170.93228149414062) 89.2503662109375\n",
            "(122.0694580078125, 110.67151641845703) (141.96856689453125, 170.43504333496094) 89.23236846923828\n",
            "(104.9030532836914, 111.33550262451172) (130.67413330078125, 168.9759521484375) 77.0978775024414\n",
            "(105.76546478271484, 112.54247283935547) (122.58522033691406, 159.4246368408203) 103.43827819824219\n",
            "(133.77134704589844, 120.14392852783203) (113.69446563720703, 144.56076049804688) 75.73543548583984\n",
            "(118.72227478027344, 111.16622924804688) (143.83389282226562, 183.8250732421875) 77.21198272705078\n",
            "(105.75435638427734, 104.32701873779297) (117.75019836425781, 149.61944580078125) 72.79481506347656\n",
            "(123.06031036376953, 114.07727813720703) (135.08287048339844, 159.0452117919922) 92.18895721435547\n",
            "(93.57765197753906, 114.07444763183594) (111.43418884277344, 130.9181671142578) 89.73237609863281\n",
            "(101.3658447265625, 95.42112731933594) (153.52772521972656, 183.71206665039062) 95.35726165771484\n",
            "(116.04462432861328, 108.11420440673828) (164.49697875976562, 188.2221221923828) 84.77147674560547\n",
            "(124.28156280517578, 113.2715835571289) (111.18492126464844, 130.28187561035156) 97.04854583740234\n",
            "(111.7553939819336, 112.89067840576172) (127.431640625, 169.43692016601562) 85.33319091796875\n"
          ]
        }
      ],
      "source": [
        "i=0\n",
        "\n",
        "dice_val = []\n",
        "jac_val = []\n",
        "ellipse_val = []\n",
        "precision_val = []\n",
        "specificity_val = []\n",
        "sensitivity_val  = []\n",
        "\n",
        "for test, pred in zip(X_test[:],y_pred[:]):\n",
        "\n",
        "    y_true = cv2.imread(\"training_set/\" + y_50[i], 0)\n",
        "    # y_true = cv2.cvtColor(y_50[i], cv2.COLOR_BGR2GRAY)\n",
        "    y_true = cv2.resize(y_true, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_AREA)\n",
        "    y_true = np.array(y_true).astype(float) / 255.0\n",
        "    y_p = np.array(pred).astype(float)\n",
        "\n",
        "\n",
        "    dice = dice_coef( y_true, y_p)\n",
        "    jac = jac_distance(y_true, y_p)\n",
        "    pr = precision( y_true, y_p)\n",
        "    sp = specificity( y_true, y_p)\n",
        "    se = sensitivity( y_true, y_p)\n",
        "\n",
        "    dice_val.append(dice)\n",
        "    jac_val.append(jac)\n",
        "    precision_val.append(pr)\n",
        "    specificity_val.append(sp)\n",
        "    sensitivity_val.append(se)\n",
        "\n",
        "    i=i+1\n",
        "\n",
        "\n",
        "\n",
        "    # fig, ax = plt.subplots(1,4,figsize = (16,16))\n",
        "    # test = test.reshape((IMG_HEIGHT,IMG_WIDTH))\n",
        "    # pred = pred.reshape((IMG_HEIGHT,IMG_WIDTH))\n",
        "\n",
        "\n",
        "    img = pred.copy()\n",
        "    (xx, yy), (MA, ma), angle = fitEllipse(img)\n",
        "    print((xx, yy), (MA, ma), angle)\n",
        "    ellipse_val.append([(xx, yy), (MA, ma), angle])\n",
        "\n",
        "    # draw = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
        "\n",
        "    # draw[img < 0.5] = (255,) * 3\n",
        "\n",
        "    # cv2.ellipse(\n",
        "    #     draw,\n",
        "    #     (int(yy), int(xx)),\n",
        "    #     (int(ma / 2), int(MA / 2)),\n",
        "    #     -angle,\n",
        "    #     0,\n",
        "    #     360,\n",
        "    #     color=(255, 0, 0),\n",
        "    #     thickness=2,\n",
        "    # )\n",
        "    \n",
        "    # pred = pred>0.5\n",
        "    # pred = np.ma.masked_where(pred == 0, pred)\n",
        "\n",
        "    # ax[0].imshow(test, cmap = 'gray')\n",
        "\n",
        "    # ax[1].imshow(pred, cmap = 'gray')\n",
        "\n",
        "    # ax[2].imshow(test, cmap = 'gray', interpolation = 'none')\n",
        "    # ax[2].imshow(pred, cmap = 'jet', interpolation = 'none', alpha = 0.7)\n",
        "    # ax[3].text(3, 7, 'dice ' + str(round(float(dice),4)) + '\\njacc ' + str(round(float(jac),4)), fontsize = 15, color = 'g')\n",
        "\n",
        "    # ax[3].imshow(draw,cmap='jet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a63rfWlWB46J"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LcY0iZ929JWZ"
      },
      "outputs": [],
      "source": [
        "#ellipse fitting is performed after applying morphological transforms. the result of those is visualised below\n",
        "\n",
        "\n",
        "# def getbound(img):\n",
        "#   draw = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
        "\n",
        "#   draw[img > 0.5] = (255,) * 3\n",
        "\n",
        "#   kernelSize = (3,3)\n",
        "#   gray = cv2.cvtColor(draw, cv2.COLOR_BGR2GRAY)\n",
        "#   kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernelSize)\n",
        "#   gradient = cv2.morphologyEx(draw, cv2.MORPH_GRADIENT, kernel)\n",
        "#   # plt.imshow()\n",
        "#   # plt.show()\n",
        "#   return gradient\n",
        "\n",
        "# img = pred.copy()\n",
        "\n",
        "# draw = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
        "\n",
        "# draw[img > 0.5] = (255,) * 3\n",
        "\n",
        "# gradient = getbound(img)\n",
        "# plt.imshow(gradient)\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# statistical analysis"
      ],
      "metadata": {
        "id": "sx7PfwTKE3rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "5SdQELa4YLeR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2Sct2WmzJ8Bo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "1ce9c5b3-2a64-406f-cf04-745aa12638df"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "n, bins, patches = plt.hist(dice_val,bins=np.arange(0,1,0.01))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_describe = pd.DataFrame(dice_val)\n",
        "df_describe.describe()"
      ],
      "metadata": {
        "id": "b206nnMhYTao",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "d7d2c6a2-a3e0-470e-db87-c1090d5c8f8f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                0\n",
              "count  999.000000\n",
              "mean     0.986624\n",
              "std      0.012217\n",
              "min      0.834905\n",
              "25%      0.985440\n",
              "50%      0.990104\n",
              "75%      0.992112\n",
              "max      0.995822"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40c068a0-68d3-47fd-aed8-8dc49847dba3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>999.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.986624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.012217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.834905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.985440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.990104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.992112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.995822</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40c068a0-68d3-47fd-aed8-8dc49847dba3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40c068a0-68d3-47fd-aed8-8dc49847dba3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40c068a0-68d3-47fd-aed8-8dc49847dba3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KJJvUdD1YTE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n, bins, patches = plt.hist(jac_val,bins=np.arange(0,1,0.01))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DP54qdHD6et9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "94cb5c22-4003-48d3-a5e2-51ff01f41f20"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAO3UlEQVR4nO3da4ycV33H8e+PmEAvgEO8WJHtsCBM24gKiFbBiKoFXFBiKhypIQoqxEVuLWioqKhU3PKi1xfhRUmJhGgtgnBQgaS0NBaklzQXRUV1wGlCrqUsadLYNbEJidsqgpLy74s5iSbu2ju7OzubPf5+pNWc5zxn5vkfz+7Pz555ZjZVhSSpL89Z6QIkSeNnuEtShwx3SeqQ4S5JHTLcJalDa1a6AIB169bV9PT0SpchSavK7bff/p2qmppr37Mi3Kenpzlw4MBKlyFJq0qSh060z2UZSeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUodGCvckDya5O8mdSQ60vhcnuSHJN9vtGa0/Sa5MMpvkriTnLucEJEn/30LeofqmqvrO0PZu4MaqujzJ7rb9IeACYHP7eh3wiXYrSQKmd3/56faDl79tWY6xlGWZ7cDe1t4LXDjUf3UN7AfWJjlrCceRJC3QqOFewN8nuT3Jrta3vqoOt/a3gfWtvQF4eOi+B1vfMyTZleRAkgNHjx5dROmSpBMZdVnmZ6rqUJKXADck+ZfhnVVVSRb0x1irag+wB2BmZsY/5CpJYzTSmXtVHWq3R4AvAucBjzy13NJuj7Thh4BNQ3ff2PokSRMyb7gn+bEkL3iqDbwVuAfYB+xow3YA17X2PuDSdtXMFuDY0PKNJGkCRlmWWQ98MclT4z9bVX+b5GvAtUl2Ag8BF7fx1wPbgFngCeA9Y69aknRS84Z7VT0AvHqO/keBrXP0F3DZWKqTJC2K71CVpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdWjkcE9yWpI7knypbb8syW1JZpNck+T01v+8tj3b9k8vT+mSpBNZyJn7B4D7h7Y/AlxRVa8AHgN2tv6dwGOt/4o2TpI0QSOFe5KNwNuAT7btAG8GvtCG7AUubO3tbZu2f2sbL0makFHP3P8E+C3gh237TODxqnqybR8ENrT2BuBhgLb/WBv/DEl2JTmQ5MDRo0cXWb4kaS7zhnuSXwCOVNXt4zxwVe2pqpmqmpmamhrnQ0vSKW/NCGPeALw9yTbg+cALgY8Ba5OsaWfnG4FDbfwhYBNwMMka4EXAo2OvXJJ0QvOeuVfVb1fVxqqaBi4BbqqqXwJuBi5qw3YA17X2vrZN239TVdVYq5YkndRSrnP/EPDBJLMM1tSvav1XAWe2/g8Cu5dWoiRpoUZZlnlaVd0C3NLaDwDnzTHme8A7xlCbJGmRfIeqJHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUPzhnuS5yf5apKvJ7k3ye+3/pcluS3JbJJrkpze+p/Xtmfb/unlnYIk6XijnLl/H3hzVb0aeA1wfpItwEeAK6rqFcBjwM42fifwWOu/oo2TJE3QvOFeA//dNp/bvgp4M/CF1r8XuLC1t7dt2v6tSTK2iiVJ8xppzT3JaUnuBI4ANwDfAh6vqifbkIPAhtbeADwM0PYfA86c4zF3JTmQ5MDRo0eXNgtJ0jOMFO5V9b9V9RpgI3Ae8JNLPXBV7amqmaqamZqaWurDSZKGLOhqmap6HLgZeD2wNsmatmsjcKi1DwGbANr+FwGPjqVaSdJIRrlaZirJ2tb+EeAtwP0MQv6iNmwHcF1r72vbtP03VVWNs2hJ0smtmX8IZwF7k5zG4D+Da6vqS0nuAz6f5I+AO4Cr2virgM8kmQW+C1yyDHVLkk5i3nCvqruA187R/wCD9ffj+78HvGMs1UmSFsV3qEpShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0a5YPDJElLNL37yxM9nmfuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq0LzhnmRTkpuT3Jfk3iQfaP0vTnJDkm+22zNaf5JcmWQ2yV1Jzl3uSUiSnmmUM/cngd+sqnOALcBlSc4BdgM3VtVm4Ma2DXABsLl97QI+MfaqJUknNW+4V9Xhqvrn1v4v4H5gA7Ad2NuG7QUubO3twNU1sB9Ym+SssVcuSTqhBa25J5kGXgvcBqyvqsNt17eB9a29AXh46G4HW9/xj7UryYEkB44ePbrAsiVJJzNyuCf5ceAvgd+oqv8c3ldVBdRCDlxVe6pqpqpmpqamFnJXSdI8Rgr3JM9lEOx/XlV/1bofeWq5pd0eaf2HgE1Dd9/Y+iRJEzLK1TIBrgLur6qPDu3aB+xo7R3AdUP9l7arZrYAx4aWbyRJE7BmhDFvAN4N3J3kztb3O8DlwLVJdgIPARe3fdcD24BZ4AngPWOtWJI0r3nDvar+EcgJdm+dY3wBly2xLknSEvgOVUnqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KH5g33JJ9KciTJPUN9L05yQ5JvttszWn+SXJlkNsldSc5dzuIlSXMb5cz908D5x/XtBm6sqs3AjW0b4AJgc/vaBXxiPGVKkhZi3nCvqluB7x7XvR3Y29p7gQuH+q+ugf3A2iRnjatYSdJo1izyfuur6nBrfxtY39obgIeHxh1sfYc5TpJdDM7uOfvssxdZhiQ9O03v/vKKHn/JL6hWVQG1iPvtqaqZqpqZmppaahmSpCGLDfdHnlpuabdHWv8hYNPQuI2tT5I0QYsN933AjtbeAVw31H9pu2pmC3BsaPlGkjQh8665J/kc8EZgXZKDwO8ClwPXJtkJPARc3IZfD2wDZoEngPcsQ82SpHnMG+5V9c4T7No6x9gCLltqUZKkpfEdqpLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocW+8c6JEnHWek/0DHMM3dJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QO+amQkrQEz6ZPghzmmbskdchwl6QOGe6S1CHX3CVpgZ6t6+zDPHOXpA4Z7pLUoWVZlklyPvAx4DTgk1V1+XIcR5ImZTUsxQwbe7gnOQ34OPAW4CDwtST7quq+cR9LkhZrOKwfvPxtc/avZstx5n4eMFtVDwAk+TywHTDcpVXsRGG40DFLGb/UxzpRcPcS6MNSVeN9wOQi4Pyq+pW2/W7gdVX1/uPG7QJ2tc2fAL6xyEOuA76zyPuuZqfivE/FOcOpOe9Tcc6w8Hm/tKqm5tqxYpdCVtUeYM9SHyfJgaqaGUNJq8qpOO9Tcc5was77VJwzjHfey3G1zCFg09D2xtYnSZqQ5Qj3rwGbk7wsyenAJcC+ZTiOJOkExr4sU1VPJnk/8HcMLoX8VFXdO+7jDFny0s4qdSrO+1ScM5ya8z4V5wxjnPfYX1CVJK0836EqSR0y3CWpQ6sm3JOcn+QbSWaT7J5j//OSXNP235ZkevJVjtcIc/5gkvuS3JXkxiQvXYk6x22+eQ+N+8UklWTVXzI3ypyTXNye73uTfHbSNS6HEb7Hz05yc5I72vf5tpWoc5ySfCrJkST3nGB/klzZ/k3uSnLuog5UVc/6LwYvzH4LeDlwOvB14Jzjxvwa8KetfQlwzUrXPYE5vwn40dZ+32qf86jzbuNeANwK7AdmVrruCTzXm4E7gDPa9ktWuu4JzXsP8L7WPgd4cKXrHsO8fxY4F7jnBPu3AX8DBNgC3LaY46yWM/enP9Kgqv4HeOojDYZtB/a29heArUkywRrHbd45V9XNVfVE29zP4D0Fq90ozzXAHwIfAb43yeKWyShz/lXg41X1GEBVHZlwjcthlHkX8MLWfhHwHxOsb1lU1a3Ad08yZDtwdQ3sB9YmOWuhx1kt4b4BeHho+2Drm3NMVT0JHAPOnEh1y2OUOQ/byeB/+9Vu3nm3X1M3VVUvHwgyynP9SuCVSb6SZH/75NXVbpR5/x7wriQHgeuBX59MaStqoT/7c/IvMXUgybuAGeDnVrqW5ZbkOcBHgV9e4VImbQ2DpZk3MvgN7dYkP11Vj69oVcvvncCnq+qPk7we+EySV1XVD1e6sGe71XLmPspHGjw9JskaBr/CPTqR6pbHSB/jkOTngQ8Db6+q70+otuU037xfALwKuCXJgwzWJPet8hdVR3muDwL7quoHVfVvwL8yCPvVbJR57wSuBaiqfwKez+DDtXo2lo9wWS3hPspHGuwDdrT2RcBN1V6dWKXmnXOS1wJ/xiDYe1iDhXnmXVXHqmpdVU1X1TSD1xreXlUHVqbcsRjl+/uvGZy1k2Qdg2WaByZZ5DIYZd7/DmwFSPJTDML96ESrnLx9wKXtqpktwLGqOrzgR1npV44X8ArzNgZnK98CPtz6/oDBDzYMnvS/AGaBrwIvX+maJzDnfwAeAe5sX/tWuuZJzPu4sbewyq+WGfG5DoPlqPuAu4FLVrrmCc37HOArDK6kuRN460rXPIY5fw44DPyAwW9kO4H3Au8deq4/3v5N7l7s97cfPyBJHVotyzKSpAUw3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KH/g/WyCgAiOSMSgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_describe = pd.DataFrame(jac_val)\n",
        "df_describe.describe()"
      ],
      "metadata": {
        "id": "nmniv23EZg6h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "b9a63e7b-5614-4145-9db0-1183f6b7ea27"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                0\n",
              "count  999.000000\n",
              "mean     0.973869\n",
              "std      0.022188\n",
              "min      0.716626\n",
              "25%      0.971300\n",
              "50%      0.980403\n",
              "75%      0.984348\n",
              "max      0.991678"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-768cd4b1-d451-44ff-a0e8-df274f331eec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>999.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.973869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.022188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.716626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.971300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.980403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.984348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.991678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-768cd4b1-d451-44ff-a0e8-df274f331eec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-768cd4b1-d451-44ff-a0e8-df274f331eec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-768cd4b1-d451-44ff-a0e8-df274f331eec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n, bins, patches = plt.hist(precision_val,bins=np.arange(0,100,1))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YYlOqy1BELHs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "d8bc601b-2e66-41da-f589-25598108a416"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n, bins, patches = plt.hist(sensitivity_val,bins=np.arange(0,100,1))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VuzHw3HrWsKu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "d2715efc-deba-4c19-f790-698735db8d37"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n, bins, patches = plt.hist(specificity_val)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-Wfc1cITW4u5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f70b633e-424d-4a3e-a8ac-66e7f173b9ad"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASiklEQVR4nO3df6zddX3H8edroCSbc4C9Ng3UXSTFjC1bYXdIMlEn2+SHsbJFBlkUJ1l1kwV/bK7qombLkvoDzRY3TB0NsCHChkw22CYjTrJkoLesFhDQ4kpoLe31R9RNgxbe++N8bzjrbtt77znnniOf5yM5ud/v5/v93u+r396+eu73fM/5pqqQJLXhR8YdQJK0cix9SWqIpS9JDbH0Jakhlr4kNeTocQcAWLVqVU1PT487hiT9UNm2bdvXqmpqKdtMROlPT08zOzs77hiS9EMlySNL3cbTO5LUEEtfkhpi6UtSQyx9SWqIpS9JDbH0Jakhlr4kNcTSl6SGWPqS1JCJeEeudCTTm24d2753bT5/bPuWhs1n+pLUEEtfkhpi6UtSQyx9SWqIpS9JDbH0Jakhlr4kNcTSl6SGWPqS1JAjln6StUk+k+SLSe5Pcnk3fnyS25N8uft6XDeeJH+eZGeSHUlOH/UfQpK0OIt5pn8AeFtVnQqcCbwpyanAJuCOqloH3NHNA5wLrOseG4Erh55akrQsRyz9qtpbVfd0098BHgBOADYA13SrXQO8qpveAFxbPXcBxyZZM/TkkqQlW9I5/STTwGnA3cDqqtrbLXoMWN1NnwA82rfZ7m7s4O+1Mclsktm5ubklxpYkLceiSz/Js4CbgDdX1bf7l1VVAbWUHVfVlqqaqaqZqamppWwqSVqmRZV+kmfQK/zrquqT3fC++dM23df93fgeYG3f5id2Y5KkMVvM1TsBrgIeqKoP9S26Bbikm74E+FTf+Gu7q3jOBL7VdxpIkjRGi7mJyi8CrwHuTbK9G3snsBm4McmlwCPAhd2y24DzgJ3Ad4HfGmpiSdKyHbH0q+rfgRxi8dkLrF/AmwbMJUkaAd+RK0kNsfQlqSGWviQ1xNKXpIZY+pLUEEtfkhpi6UtSQyx9SWqIpS9JDbH0Jakhlr4kNcTSl6SGWPqS1BBLX5IaYulLUkMWc+esrUn2J7mvb+yGJNu7x675m6skmU7yvb5lHx1leEnS0izmzllXAx8Brp0fqKrfmJ9OcgXwrb71H66q9cMKqMkyvenWcUeQNIDF3DnrziTTCy3r7p97IfCy4caSJse4/qPbtfn8sexXT2+DntM/C9hXVV/uGzspyX8m+WySsw61YZKNSWaTzM7NzQ0YQ5K0GIOW/sXA9X3ze4HnVdVpwFuBjyd59kIbVtWWqpqpqpmpqakBY0iSFmPZpZ/kaODXgBvmx6rq8ar6eje9DXgYOGXQkJKk4Rjkmf4vAw9W1e75gSRTSY7qpp8PrAO+MlhESdKwLOaSzeuB/wBekGR3kku7RRfxf0/tALwY2NFdwvl3wBur6hvDDCxJWr7FXL1z8SHGX7fA2E3ATYPHkiSNgu/IlaSGWPqS1BBLX5IaYulLUkMsfUlqiKUvSQ2x9CWpIZa+JDXE0pekhlj6ktQQS1+SGmLpS1JDLH1JaoilL0kNsfQlqSGLuYnK1iT7k9zXN/beJHuSbO8e5/Ute0eSnUkeSvLyUQWXJC3dYp7pXw2cs8D4h6tqffe4DSDJqfTuqPXT3TZ/OX/7REnS+B2x9KvqTmCxtzzcAHyiu0H6fwE7gTMGyCdJGqJBzulflmRHd/rnuG7sBODRvnV2d2OSpAmw3NK/EjgZWA/sBa5Y6jdIsjHJbJLZubm5ZcaQJC3Fskq/qvZV1RNV9STwMZ46hbMHWNu36ond2ELfY0tVzVTVzNTU1HJiSJKWaFmln2RN3+wFwPyVPbcAFyU5JslJwDrgc4NFlCQNy9FHWiHJ9cBLgVVJdgPvAV6aZD1QwC7gDQBVdX+SG4EvAgeAN1XVE6OJLklaqiOWflVdvMDwVYdZ/0+BPx0klCRpNHxHriQ1xNKXpIZY+pLUEEtfkhpi6UtSQyx9SWqIpS9JDbH0Jakhlr4kNcTSl6SGWPqS1BBLX5IaYulLUkMsfUlqiKUvSQ2x9CWpIUcs/SRbk+xPcl/f2AeSPJhkR5KbkxzbjU8n+V6S7d3jo6MML0lamsU8078aOOegsduBn6mqnwW+BLyjb9nDVbW+e7xxODElScNwxNKvqjuBbxw09umqOtDN3gWcOIJskqQhG8Y5/dcD/9Q3f1KS/0zy2SRnHWqjJBuTzCaZnZubG0IMSdKRDFT6Sd4FHACu64b2As+rqtOAtwIfT/Lshbatqi1VNVNVM1NTU4PEkCQt0rJLP8nrgFcAv1lVBVBVj1fV17vpbcDDwClDyClJGoJllX6Sc4C3A6+squ/2jU8lOaqbfj6wDvjKMIJKkgZ39JFWSHI98FJgVZLdwHvoXa1zDHB7EoC7uit1Xgz8cZIfAE8Cb6yqbyz4jSVJK+6IpV9VFy8wfNUh1r0JuGnQUJKk0fAduZLUEEtfkhpi6UtSQyx9SWqIpS9JDbH0Jakhlr4kNcTSl6SGWPqS1BBLX5IaYulLUkMsfUlqiKUvSQ2x9CWpIZa+JDXkiJ+nD5BkK71bI+6vqp/pxo4HbgCmgV3AhVX1zfTuqvJnwHnAd4HXVdU9w48uPb1Nb7p1bPvetfn8se1bo7Wo0geuBj4CXNs3tgm4o6o2J9nUzf8hcC692ySuA14IXNl91ZCMswwk/XBb1OmdqroTOPi2hxuAa7rpa4BX9Y1fWz13AccmWTOMsJKkwQxyTn91Ve3tph8DVnfTJwCP9q23uxv7P5JsTDKbZHZubm6AGJKkxRrKC7lVVUAtcZstVTVTVTNTU1PDiCFJOoJBSn/f/Gmb7uv+bnwPsLZvvRO7MUnSmA1S+rcAl3TTlwCf6ht/bXrOBL7VdxpIkjRGi71k83rgpcCqJLuB9wCbgRuTXAo8AlzYrX4bvcs1d9K7ZPO3hpxZkrRMiyr9qrr4EIvOXmDdAt40SChJ0mj4jlxJaoilL0kNsfQlqSGWviQ1xNKXpIZY+pLUEEtfkhpi6UtSQyx9SWqIpS9JDbH0Jakhlr4kNcTSl6SGWPqS1BBLX5IasqjP019IkhcAN/QNPR94N3As8NvA/N3O31lVty07oSRpaJZd+lX1ELAeIMlR9O6DezO9O2V9uKo+OJSEkqShGdbpnbOBh6vqkSF9P0nSCAyr9C8Cru+bvyzJjiRbkxy30AZJNiaZTTI7Nze30CqSpCEbuPSTPBN4JfC33dCVwMn0Tv3sBa5YaLuq2lJVM1U1MzU1NWgMSdIiDOOZ/rnAPVW1D6Cq9lXVE1X1JPAx4Iwh7EOSNATLfiG3z8X0ndpJsqaq9nazFwD3DWEfklbQ9KZbx7LfXZvPH8t+WzJQ6Sf5MeBXgDf0Db8/yXqggF0HLZMkjdFApV9V/wM856Cx1wyUSJI0Mr4jV5IaYulLUkMsfUlqiKUvSQ2x9CWpIZa+JDXE0pekhlj6ktQQS1+SGmLpS1JDhvGBa80a14dSSU9XftDb6PlMX5IaYulLUkMsfUlqiKUvSQ0Z+IXcJLuA7wBPAAeqaibJ8cANwDS9G6lcWFXfHHRfkqTBDOuZ/i9V1fqqmunmNwF3VNU64I5uXpI0ZqM6vbMBuKabvgZ41Yj2I0lagmGUfgGfTrItycZubHXfzdEfA1YfvFGSjUlmk8zOzc0NIYYk6UiG8easF1XVniTPBW5P8mD/wqqqJHXwRlW1BdgCMDMz8/+WS5KGb+Bn+lW1p/u6H7gZOAPYl2QNQPd1/6D7kSQNbqDST/JjSX58fhr4VeA+4Bbgkm61S4BPDbIfSdJwDHp6ZzVwc5L57/XxqvrnJJ8HbkxyKfAIcOGA+5EkDcFApV9VXwF+boHxrwNnD/K9JUnD5ztyJakhlr4kNcTSl6SGWPqS1BBLX5IaYulLUkMsfUlqiKUvSQ2x9CWpIZa+JDXE0pekhlj6ktQQS1+SGmLpS1JDLH1JasiySz/J2iSfSfLFJPcnubwbf2+SPUm2d4/zhhdXkjSIQW6icgB4W1Xd090ycVuS27tlH66qDw4eT5I0TMsu/araC+ztpr+T5AHghGEFk6SVMr3p1rHte9fm81d0f0M5p59kGjgNuLsbuizJjiRbkxw3jH1IkgY3cOkneRZwE/Dmqvo2cCVwMrCe3m8CVxxiu41JZpPMzs3NDRpDkrQIA5V+kmfQK/zrquqTAFW1r6qeqKongY8BZyy0bVVtqaqZqpqZmpoaJIYkaZEGuXonwFXAA1X1ob7xNX2rXQDct/x4kqRhGuTqnV8EXgPcm2R7N/ZO4OIk64ECdgFvGCihJGloBrl659+BLLDotuXHkSSNku/IlaSGWPqS1BBLX5IaYulLUkMsfUlqiKUvSQ2x9CWpIZa+JDXE0pekhlj6ktQQS1+SGjLIB65NjHHe9UaSfpj4TF+SGmLpS1JDLH1JaoilL0kNGVnpJzknyUNJdibZNKr9SJIWbySln+Qo4C+Ac4FT6d1C8dRR7EuStHijeqZ/BrCzqr5SVd8HPgFsGNG+JEmLNKrr9E8AHu2b3w28sH+FJBuBjd3sfyd5aERZFmMV8LUx7n8hk5gJJjPXJGaCycw1iZlgMnOtSKa8b8mb9Of6yaVuPLY3Z1XVFmDLuPbfL8lsVc2MO0e/ScwEk5lrEjPBZOaaxEwwmbkmMRMMnmtUp3f2AGv75k/sxiRJYzSq0v88sC7JSUmeCVwE3DKifUmSFmkkp3eq6kCSy4B/AY4CtlbV/aPY15BMxGmmg0xiJpjMXJOYCSYz1yRmgsnMNYmZYMBcqaphBZEkTTjfkStJDbH0JakhT/vST7I1yf4k9y2w7G1JKsmqbj5J/rz76IgdSU5fyVxJ3ptkT5Lt3eO8vmXv6HI9lOTlK5WpG/+9JA8muT/J+1cy06FyJbmh7zjtSrJ9JXMdItP6JHd1mWaTnNGNj/vn6ueS/EeSe5P8Q5Jn9y1biWO1Nslnknyx+xm6vBs/PsntSb7cfT2uGx/58TpMpld3808mmTlom3Eeqw90/wZ3JLk5ybHLzlVVT+sH8GLgdOC+g8bX0nuh+RFgVTd2HvBPQIAzgbtXMhfwXuD3F1j3VOALwDHAScDDwFErlOmXgH8Fjunmn7uSmQ73d9i3/Arg3RNwrD4NnNv3s/RvE/Jz9XngJd3064E/WeFjtQY4vZv+ceBL3b7fD2zqxjcB71up43WYTD8FvAD4N2Cmb/1xH6tfBY7uxt/Xd6yWnOtp/0y/qu4EvrHAog8Dbwf6X8neAFxbPXcBxyZZs8K5FrIB+ERVPV5V/wXspPdRFyuR6XeAzVX1eLfO/pXMdJhcQO9ZIXAhcP1K5jpEpgLmn0X/BPDVvkzj/Lk6Bbizm74d+PW+XCtxrPZW1T3d9HeAB+i9a38DcE232jXAq/pyjfR4HSpTVT1QVQt9OsBYj1VVfbqqDnSr3UXvvU/LyvW0L/2FJNkA7KmqLxy0aKGPjzhhxYL1XNb9Crd1/tfdMec6BTgryd1JPpvkFyYgU7+zgH1V9eVufpy53gx8IMmjwAeBd0xAJoD7eeqzr17NU2+cXPFcSaaB04C7gdVVtbdb9Biwehy5Dsp0KOM+Vv1eT+83oWXlaq70k/wo8E7g3ePOsoArgZOB9cBeeqctxu1o4Hh6v2b/AXBj9+x6UlzMU8/yx+13gLdU1VrgLcBVY84z7/XA7ybZRu+UwffHESLJs4CbgDdX1bf7l1XvXMWKXz9+uEzjdKhcSd4FHACuW+73flrcGH2JTqZ37usLXXedCNzTveg21o+PqKp989NJPgb8Yzc7zly7gU92/yg/l+RJeh/4NPaP2khyNPBrwM/3DY8z1yXA5d303wJ/NQGZqKoH6Z0TJskpwPkrnSvJM+iV2HVV9clueF+SNVW1tzt9M3/qcEVyHSLToYz7WJHkdcArgLO7f4/LytXcM/2qureqnltV01U1Ta/UTq+qx+h9VMRru6sHzgS+1ffr58gddN7yAmD+CoxbgIuSHJPkJGAd8LkVivX39F7MnS+MZ9L7hL9xZpr3y8CDVbW7b2ycub4KvKSbfhkwf8pp3D9Xz+2+/gjwR8BH+3KN/Fh1vxleBTxQVR/qW3QLvf8o6b5+qm98pMfrMJkOZazHKsk59F6DfGVVfXegXMN+9XnSHvR+9d8L/IBewV960PJdPHX1Tujd/OVh4F76Xr1fiVzAX3f73dH9Za7pW/9dXa6H6K4QWaFMzwT+ht5/QPcAL1vJTIf7OwSuBt64wPrjOlYvArbRu5ribuDnJ+Tn6nJ6V4F8CdhM9078FTxWL6J36mYHsL17nAc8B7iD3n+O/wocv1LH6zCZLuiO2+PAPuBfJuRY7aR37n5+7KPLzeXHMEhSQ5o7vSNJLbP0Jakhlr4kNcTSl6SGWPqS1BBLX5IaYulLUkP+F1ej/1VaX//JAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W9UdNQz6W88G"
      },
      "execution_count": 33,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1rEWgBaPKo4Chkbg+X3Hy",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}